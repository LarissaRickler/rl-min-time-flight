{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649b76a",
   "metadata": {},
   "source": [
    "# Init Bionic VTOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96751412",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position\n",
    "\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;\n",
    "using Distributions;\n",
    "\n",
    "using Plots;\n",
    "using Statistics;\n",
    "\n",
    "using BSON: @save, @load # save mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e4ee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: MeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "│ http://127.0.0.1:8700\n",
      "└ @ MeshCat /home/larissa/.julia/packages/MeshCat/Ax8pH/src/visualizer.jl:73\n"
     ]
    }
   ],
   "source": [
    "create_visualization();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9557df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indicates how many threads Julia was started with. This is important for the multi-threaded environment\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea451ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eth_vtol_param[\"gravity\"] = 9.81; # set gravity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411db62",
   "metadata": {},
   "source": [
    "# Create Reinforcement Learning Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96af6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv # Parametric Constructor for a subtype of AbstractEnv\n",
    "    action_space::A # action space\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}} # observation space\n",
    "    state::Vector{T} # current state space\n",
    "    action::ACT # action space\n",
    "    done::Bool # done\n",
    "    t::T # time\n",
    "    rng::R # random number generator\n",
    "\n",
    "    name::String # for multible environoments\n",
    "    visualization::Bool # visualization\n",
    "    realtime::Bool # realtime\n",
    "    \n",
    "    # Everything you need aditionaly can also go in here.\n",
    "    x_W::Vector{T} # current position\n",
    "    v_B::Vector{T} # velocity\n",
    "    R_W::Matrix{T} # current rotation\n",
    "    ω_B::Vector{T} # rotation velocitiy\n",
    "    wind_W::Vector{T} # wind\n",
    "    Δt::T # Δ time\n",
    "    \n",
    "    # Current Bonus / Target\n",
    "    num_waypoints::Int # includig start point\n",
    "    waypoints::Vector{Vector{T}}\n",
    "    reached_goal::Vector{Bool}\n",
    "    \n",
    "    progress::T\n",
    "    progress_prev::T\n",
    "    reached_goal_in_step::Bool\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a6873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a keyword-based constructor for the type declared in the mutable struct typedef. \n",
    "# It could also be done with the macro Base.@kwdef.\n",
    "function VtolEnv(;\n",
    "    rng = Random.GLOBAL_RNG, # Random number generation\n",
    "    name = \"vtol\",\n",
    "    visualization = false,\n",
    "    realtime = false,\n",
    "    kwargs... # let the function take an arbitrary number of keyword arguments \n",
    ")\n",
    "    \n",
    "    T = Float64; # explicit type which is used e.g. in state. Cannot be altered due to the poor matrix defininon.\n",
    "\n",
    "    \n",
    "    action_space = Space(\n",
    "        ClosedInterval{T}[\n",
    "            0.0..2.0, # propeller 1\n",
    "            0.0..2.0, # propeller 2\n",
    "            ], \n",
    "    )\n",
    "\n",
    "    \n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            # orientate yourself on the state space from the paper\n",
    "            typemin(T)..typemax(T), # position along x\n",
    "            typemin(T)..typemax(T), # position along z\n",
    "            \n",
    "            typemin(T)..typemax(T), # orientation along x\n",
    "            typemin(T)..typemax(T), # orientation along z\n",
    "            \n",
    "            typemin(T)..typemax(T), # velocity along x BODY coordinates\n",
    "            typemin(T)..typemax(T), # velocity along y BODY coordinates\n",
    "            \n",
    "            typemin(T)..typemax(T), # rotational velocity along z BODY coordinates\n",
    "            \n",
    "            typemin(T)..typemax(T), # position error along x\n",
    "            typemin(T)..typemax(T), # position error along z\n",
    "            # TODO: nore points?\n",
    "            ], \n",
    "    )\n",
    "    \n",
    "    num_waypoints = 3 # number of waypoints, includig start point\n",
    "    waypoints = generate_trajectory(num_waypoints) # trajectory with num_waypoints waypoints (+ start point) \n",
    "    reached_goal = Vector{Bool}(undef, num_waypoints)\n",
    "    \n",
    "    if visualization #visualizes VTOL and waypoints\n",
    "        create_VTOL(name, actuators = true, color_vec=[1.0; 1.0; 0.6; 1.0]);\n",
    "        visualize_waypoints(waypoints, 1.0)\n",
    "    end\n",
    "\n",
    "    environment = VtolEnv(\n",
    "        action_space,\n",
    "        state_space, \n",
    "        zeros(T, length(state_space)), # current state, needs to be extended\n",
    "        rand(action_space), #initialization action\n",
    "        false, # episode done \n",
    "        0.0, # time\n",
    "        rng, # random number generator  \n",
    "        \n",
    "        name,\n",
    "        visualization,\n",
    "        realtime,\n",
    "        \n",
    "        zeros(T, 3), # x_W, current position\n",
    "        zeros(T, 3), # v_B, velocity\n",
    "        [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0], # R_W, current rotation, Float64... so T needs to be Float64\n",
    "        zeros(T, 3), # ω_B\n",
    "        zeros(T, 3), # wind_W\n",
    "        T(0.025), # Δt \n",
    "        \n",
    "        num_waypoints, # includig start point\n",
    "        waypoints,\n",
    "        reached_goal,\n",
    "        \n",
    "        0.0, # progress\n",
    "        0.0, # progress_prev\n",
    "        false, # reached_goal_in_step\n",
    "    )\n",
    "    \n",
    "    \n",
    "    reset!(environment)\n",
    "    \n",
    "    return environment\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec660d5e",
   "metadata": {},
   "source": [
    "Just for explanation:\n",
    "\n",
    "1. A mutable Struct is created. A struct is a constructor and a constructor is a function that creates new objects.\n",
    "2. A outer keyword-based constructor method is added for the type declared in the mutable struct typedef before.\n",
    "\n",
    "So now we have a function with two methods. Julia will decide which method to call by multiple dispatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3c4bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "# 2 methods for type constructor:<ul><li> VtolEnv(; <i>rng, name, visualization, realtime, kwargs...</i>) in Main at In[6]:3</li> <li> VtolEnv(action_space::<b>A</b>, observation_space::<b>Space{Array{ClosedInterval{T}, 1}}</b>, state::<b>Vector{T}</b>, action::<b>ACT</b>, done::<b>Bool</b>, t::<b>T</b>, rng::<b>R</b>, name::<b>String</b>, visualization::<b>Bool</b>, realtime::<b>Bool</b>, x_W::<b>Vector{T}</b>, v_B::<b>Vector{T}</b>, R_W::<b>Matrix{T}</b>, ω_B::<b>Vector{T}</b>, wind_W::<b>Vector{T}</b>, Δt::<b>T</b>, num_waypoints::<b>Int64</b>, waypoints::<b>Array{Vector{T}, 1}</b>, reached_goal::<b>Vector{Bool}</b>, progress::<b>T</b>, progress_prev::<b>T</b>, reached_goal_in_step::<b>Bool</b>)<i> where {A, T, ACT, R<:AbstractRNG}</i> in Main at In[5]:2</li> </ul>"
      ],
      "text/plain": [
       "# 2 methods for type constructor:\n",
       "[1] VtolEnv(; rng, name, visualization, realtime, kwargs...) in Main at In[6]:3\n",
       "[2] VtolEnv(action_space::A, observation_space::Space{Array{ClosedInterval{T}, 1}}, state::Vector{T}, action::ACT, done::Bool, t::T, rng::R, name::String, visualization::Bool, realtime::Bool, x_W::Vector{T}, v_B::Vector{T}, R_W::Matrix{T}, ω_B::Vector{T}, wind_W::Vector{T}, Δt::T, num_waypoints::Int64, waypoints::Array{Vector{T}, 1}, reached_goal::Vector{Bool}, progress::T, progress_prev::T, reached_goal_in_step::Bool) where {A, T, ACT, R<:AbstractRNG} in Main at In[5]:2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(VtolEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806413d1",
   "metadata": {},
   "source": [
    "# Define the RL interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f822029",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7fb89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function computeReward(env::VtolEnv{A,T}) where {A,T}\n",
    "    \n",
    "    r_tol = 0.10 # tolerance distance to gate\n",
    "    \n",
    "    k_wp = 5.0 # factor for reached gate reward\n",
    "    r_wp = 0.0 # reward for reached gate, TODO: change to gates later (when gates != waypoints)\n",
    "    for i in eachindex(env.waypoints) # TODO: put in step (needs modification) but how to treat r_tol\n",
    "        if (norm(env.x_W - env.waypoints[i])< r_tol) && !(env.reached_goal[i])\n",
    "            r_wp = exp(-norm(env.x_W - env.waypoints[i])/r_tol)\n",
    "            env.reached_goal[i] = true\n",
    "        end\n",
    "    end    \n",
    "    \n",
    "    k_ω = 0.01 # factor for too high body rate\n",
    "    norm_ω = norm(env.ω_B[3]) # reward for body rate (penalty)\n",
    "\n",
    "    k_s = 2.0 # factor for reached distance (overall) reward, TODO later add factor as in paper (p. 4)\n",
    "    r_s = env.progress # reward for reached distance (overall)\n",
    "    \n",
    "    \n",
    "    \n",
    "    k_p = 5.0 # factor for progress (between current position and last position) reward \n",
    "    r_p = env.progress - env.progress_prev # reward for progress (between current position and last position)\n",
    "\n",
    "    return k_p * r_p + k_s * k_s + k_wp * r_wp - k_ω * norm_ω\n",
    "end\n",
    "\n",
    "\n",
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = computeReward(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae45ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    # Visualize initial state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, [0.0; 0.0; 0.0; 0.0]);\n",
    "    end\n",
    "    \n",
    "    env.x_W = [0.0; 0.0; 0.0];\n",
    "    env.v_B = [0.0; 0.0; 0.0];\n",
    "    env.R_W = Matrix(UnitQuaternion(RotZ(-pi/2.0)*RotY(-pi/2.0)*RotX(pi)));\n",
    "\n",
    "    env.ω_B = [0.0; 0.0; 0.0];\n",
    "    env.wind_W = [0.0; 0.0; 0.0];\n",
    "    \n",
    "    env.num_waypoints = 3; # includig start point\n",
    "    env.waypoints = generate_trajectory(env.num_waypoints);\n",
    "    env.reached_goal = Vector{Bool}(undef, env.num_waypoints);\n",
    "    env.reached_goal[1] = true; # set first point to reached (start point)\n",
    "    \n",
    "    if env.visualization\n",
    "        visualize_waypoints(env.waypoints, 1.0); # debug: other radius?\n",
    "    end\n",
    "    \n",
    "\n",
    "    env.progress = 0.0;\n",
    "    env.progress_prev = 0.0;\n",
    "    env.reached_goal_in_step = false;\n",
    "    \n",
    "    \n",
    "    env.state = [env.x_W[1]; # position along x\n",
    "                 env.x_W[3]; # position along z\n",
    "        \n",
    "                 env.R_W[1,1]; # orientation along x\n",
    "                 env.R_W[3,1]; # orientation along z\n",
    "        \n",
    "                 env.v_B[1]; # velocity along x BODY coordinates\n",
    "                 env.v_B[2]; # velocity along y BODY coordinates  \n",
    "        \n",
    "                 env.ω_B[3]; # rotational velocity along z BODY coordinates\n",
    "        \n",
    "                 env.x_W[1] - env.waypoints[2][1]; # position error along x\n",
    "                 env.x_W[3] - env.waypoints[2][3]] # position error along z\n",
    "    \n",
    "    env.t = 0.0;\n",
    "    env.action = [0.0, 0.0];\n",
    "    env.done = false;\n",
    "    \n",
    "    nothing\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf1a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a methods for a callable object.\n",
    "# So when a VtolEnv object is created, it has this method that can be called\n",
    "function (env::VtolEnv)(a)\n",
    "    # TODO: set flaps later in 3D\n",
    "    # set the propeller trust and the two flaps 2D case\n",
    "    next_action = [a[1], a[2], 0.0, 0.0]\n",
    "   \n",
    "    _step!(env, next_action)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e9eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VtolEnv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a116cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "# 3 methods for callable object:<ul><li> (env::<b>VtolEnv</b>)(a) in Main at In[11]:3</li> <li> (env::<b>AbstractEnv</b>)(action) in ReinforcementLearningBase</li> <li> (env::<b>AbstractEnv</b>)(action, player) in ReinforcementLearningBase</li> </ul>"
      ],
      "text/plain": [
       "# 3 methods for callable object:\n",
       "[1] (env::VtolEnv)(a) in Main at In[11]:3\n",
       "[2] (env::AbstractEnv)(action) in ReinforcementLearningBase\n",
       "[3] (env::AbstractEnv)(action, player) in ReinforcementLearningBase"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(env) # Just to explain which methods the object has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7d4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "function _step!(env::VtolEnv, next_action)\n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(env.v_B, env.R_W, env.wind_W)\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = vtol_model(v_in_wind_B, next_action, eth_vtol_param);\n",
    "    # Limit to 2D\n",
    "    force_B[3] = 0.0; # Body Z\n",
    "    env.v_B[3] = 0.0;\n",
    "    torque_B[1] = 0.0; torque_B[2] = 0.0;  # Body X and Y\n",
    "    env.ω_B[1] = 0.0; env.ω_B[2] = 0.0;\n",
    "    # integrate rigid body dynamics for Δt\n",
    "    env.x_W, env.v_B, env.R_W, env.ω_B, time = rigid_body_simple(torque_B, force_B, env.x_W, env.v_B, env.R_W, env.ω_B, env.t, env.Δt, eth_vtol_param)\n",
    "    \n",
    "    \n",
    "    # calculate progress on trajectory\n",
    "    env.progress_prev = env.progress\n",
    "    \n",
    "    current_progress = 0.0\n",
    "    line_segment, progress = calculate_progress(env.waypoints, env.x_W)\n",
    "    for i in 2:(line_segment)\n",
    "       current_progress +=  norm(env.waypoints[i] - env.waypoints[i - 1])  \n",
    "    end\n",
    "    current_progress += norm(env.waypoints[line_segment] - progress)\n",
    "    \n",
    "    env.progress = current_progress\n",
    "    \n",
    "    \n",
    "\n",
    "    if env.realtime\n",
    "        sleep(env.Δt) # TODO: just a dirty hack. this is of course slower than real time.\n",
    "    end\n",
    "\n",
    "    # Visualize the new state \n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, next_action)\n",
    "    end\n",
    " \n",
    "    env.t += env.Δt\n",
    "        \n",
    "    \n",
    "    current_point = 1\n",
    "    while current_point <= env.num_waypoints && env.reached_goal[current_point]  \n",
    "        current_point += 1\n",
    "    end\n",
    "    \n",
    "    \n",
    "    env.state[1] = env.x_W[1]; # position along x\n",
    "    env.state[2] = env.x_W[3]; # position along z\n",
    "    \n",
    "    env.state[3] = env.R_W[1,1]; # orientation along x\n",
    "    env.state[4] = env.R_W[3,1]; # orientation along z\n",
    "    \n",
    "    env.state[5] = env.v_B[1]; # velocity along x BODY coordinates\n",
    "    env.state[6] = env.v_B[2]; # velocity along y BODY coordinates\n",
    "    \n",
    "    env.state[7] = env.ω_B[3];  # rotational velocity along z BODY coordinates\n",
    "    \n",
    "    if current_point <= env.num_waypoints\n",
    "        env.state[8] = env.x_W[1] - env.waypoints[current_point][1]; # position error along x\n",
    "        env.state[9] = env.x_W[3] - env.waypoints[current_point][3]; # position error along z\n",
    "    else\n",
    "        env.state[8] = 0.0; # position error along x\n",
    "        env.state[9] = 0.0; # position error along z\n",
    "    end\n",
    "        \n",
    "    \n",
    "    # Termination criteria\n",
    "    # TODO: Use many termination criteria so that you do not train unnecessarily in wrong areas\n",
    "    env.done = #true\n",
    "        # After time... How fast is drone+Range of desired point\n",
    "        # After reaching position (circle of r_tol)\n",
    "        norm(env.ω_B) > 100.0 || \n",
    "        norm(env.v_B) > 100.0 || # stop if body is too fast\n",
    "        env.x_W[3] < -5.0 || # stop if body is below -5m\n",
    "        env.t > env.num_waypoints * 5.0 ||# stop after 5s per point\n",
    "        current_point > env.num_waypoints\n",
    "    nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e1cd988",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:              | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "random policy with VtolEnv | \u001b[32m2000  \u001b[39m\u001b[36m 2000  \u001b[39m\u001b[0m2.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"random policy with VtolEnv\", Any[], 2000, false, false, true, 1.670274433782845e9, 1.670274436304702e9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RLBase.test_runnable!(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223a31f",
   "metadata": {},
   "source": [
    "Show an overview of the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6de74",
   "metadata": {},
   "source": [
    "# Setup of a reinforcement learning experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5683fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "MultiThreadEnv(8 x VtolEnv)"
      ],
      "text/plain": [
       "MultiThreadEnv(8 x VtolEnv)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123    \n",
    "rng = StableRNG(seed)\n",
    "    N_ENV = 8\n",
    "    UPDATE_FREQ = 1024\n",
    "    \n",
    "    \n",
    "    # define multiple environments for parallel training\n",
    "    env = MultiThreadEnv([\n",
    "        # use different names for the visualization\n",
    "        VtolEnv(; rng = StableRNG(hash(seed+i)), name = \"vtol$i\") for i in 1:N_ENV\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1f128b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function approximator\n",
    "# TODO: change architecture eventually \n",
    "    ns, na = length(state(env[1])), length(action_space(env[1]))\n",
    "    approximator = ActorCritic(\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                    Dense(ns, 128, relu; initW = glorot_uniform(rng)),#\n",
    "                    Dense(128, 128, relu; initW = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(Dense(128, na; initW = glorot_uniform(rng))),\n",
    "                    logσ = Chain(Dense(128, na; initW = glorot_uniform(rng))),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 128, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(128, 128, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(128, 1; initW = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(1e-3),\n",
    "            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ea4c37c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: The GPU function is being called but the GPU is not accessible. \n",
      "│ Defaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "└ @ Flux /home/larissa/.julia/packages/Flux/7nTyc/src/functor.jl:187\n"
     ]
    }
   ],
   "source": [
    "    agent = Agent( # A wrapper of an AbstractPolicy\n",
    "        # AbstractPolicy: the policy to use\n",
    "        # TODO: change eventually\n",
    "        policy = PPOPolicy(;\n",
    "                    approximator = approximator |> gpu,\n",
    "                    update_freq=UPDATE_FREQ,\n",
    "                    dist = Normal,\n",
    "                    # For parameters visit the docu: https://juliareinforcementlearning.org/docs/rlzoo/#ReinforcementLearningZoo.PPOPolicy\n",
    "                    ),\n",
    "        \n",
    "        # AbstractTrajectory: used to store transitions between an agent and an environment source\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float64} => (ns, N_ENV),\n",
    "            action = Matrix{Float64} => (na, N_ENV),\n",
    "            action_log_prob = Vector{Float64} => (N_ENV,),\n",
    "            reward = Vector{Float64} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f158a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "function saveModel(t, agent, env)\n",
    "    model = cpu(agent.policy.approximator)   \n",
    "    f = joinpath(\"./RL_models_l/\", \"vtol_2D_ppo_$t.bson\") # TODO: evtl anpassen\n",
    "    @save f model\n",
    "    println(\"parameters at step $t saved to $f\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07c5ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "function loadModel()\n",
    "    f = joinpath(\"./RL_models_l/\", \"vtol_2D_ppo_1300000.bson\") # TODO: evtl anpassen\n",
    "    @load f model\n",
    "    return model\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3c1858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validate_policy(t, agent, env)\n",
    "    run(agent.policy, test_env, StopAfterEpisode(1), episode_test_reward_hook)\n",
    "    # the result of the hook\n",
    "    println(\"test reward at step $t: $(episode_test_reward_hook.rewards[end])\")\n",
    "    \n",
    "end;\n",
    "\n",
    "episode_test_reward_hook = TotalRewardPerEpisode(;is_display_on_exit=false)\n",
    "# create a env only for reward test\n",
    "test_env = VtolEnv(;name = \"testVTOL\", visualization = true, realtime = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdc71a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.policy.approximator = loadModel();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb737010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▎                                        |  ETA: 0:23:21\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 10000: 3.979487689812767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▌                                        |  ETA: 0:21:47\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 20000: 154.44106442577032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|▊                                        |  ETA: 0:22:02\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 30000: 234.31799056464698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▏                                       |  ETA: 0:22:39\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 40000: 3.979487689812767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▍                                       |  ETA: 0:38:05\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 50000: 4824.405169686453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▋                                       |  ETA: 0:36:07\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 60000: 3.979487689812767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|█▉                                       |  ETA: 0:33:50\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 70000: 3.979487689812767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██▏                                      |  ETA: 0:31:57\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 80000: 4820.375620020765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▍                                      |  ETA: 0:39:23\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 90000: 3.979487689812767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   7%|██▊                                      |  ETA: 0:37:18\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 100000 saved to ./RL_models_l/vtol_2D_ppo_100000.bson\n",
      "test reward at step 100000: 4.018466906222623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   7%|███                                      |  ETA: 0:35:47\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 110000: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   8%|███▎                                     |  ETA: 0:34:35\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 120000: 4842.551294001686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   9%|███▌                                     |  ETA: 0:38:55\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 130000: 4.017192271590074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   9%|███▊                                     |  ETA: 0:37:17\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 140000: 3.979487689812767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  10%|████▏                                    |  ETA: 0:36:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 150000: 216.16419799498746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  11%|████▍                                    |  ETA: 0:35:05\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 160000: 217.16940070765148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  11%|████▋                                    |  ETA: 0:34:20\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 170000: 4831.469626001106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  12%|████▊                                    |  ETA: 0:37:54\u001b[39m"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: Normal: the condition σ >= zero(σ) is not satisfied.",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Normal: the condition σ >= zero(σ) is not satisfied.",
      "",
      "Stacktrace:",
      "  [1] macro expansion",
      "    @ ~/.julia/packages/Distributions/Xrm9e/src/utils.jl:6 [inlined]",
      "  [2] #Normal#120",
      "    @ ~/.julia/packages/Distributions/Xrm9e/src/univariate/continuous/normal.jl:37 [inlined]",
      "  [3] Normal",
      "    @ ~/.julia/packages/Distributions/Xrm9e/src/univariate/continuous/normal.jl:36 [inlined]",
      "  [4] createinstance",
      "    @ ~/.julia/packages/StructArrays/w2GaP/src/interface.jl:49 [inlined]",
      "  [5] getindex",
      "    @ ~/.julia/packages/StructArrays/w2GaP/src/structarray.jl:365 [inlined]",
      "  [6] _getindex",
      "    @ ./abstractarray.jl:1274 [inlined]",
      "  [7] getindex",
      "    @ ./abstractarray.jl:1241 [inlined]",
      "  [8] _broadcast_getindex",
      "    @ ./broadcast.jl:636 [inlined]",
      "  [9] _getindex",
      "    @ ./broadcast.jl:667 [inlined]",
      " [10] _getindex",
      "    @ ./broadcast.jl:666 [inlined]",
      " [11] _broadcast_getindex",
      "    @ ./broadcast.jl:642 [inlined]",
      " [12] getindex",
      "    @ ./broadcast.jl:597 [inlined]",
      " [13] copy(bc::Base.Broadcast.Broadcasted{StructArrays.StructArrayStyle{Base.Broadcast.DefaultArrayStyle{2}, 2}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, typeof(rand), Tuple{Base.RefValue{Random._GLOBAL_RNG}, StructArrays.StructArray{Normal, 2, NamedTuple{(:μ, :σ), Tuple{Matrix{Float64}, Matrix{Float64}}}, Int64}}})",
      "    @ Base.Broadcast ./broadcast.jl:899",
      " [14] materialize",
      "    @ ./broadcast.jl:860 [inlined]",
      " [15] (::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}})(env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing})",
      "    @ ReinforcementLearningZoo ~/.julia/packages/ReinforcementLearningZoo/tvfq9/src/algorithms/policy_gradient/ppo.jl:192",
      " [16] _run(policy::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing}, stop_condition::StopAfterStep{ProgressMeter.Progress}, hook::ComposedHook{Tuple{DoEveryNStep{typeof(saveModel)}, DoEveryNStep{typeof(validate_policy)}}})",
      "    @ ReinforcementLearningZoo ~/.julia/packages/ReinforcementLearningZoo/tvfq9/src/algorithms/policy_gradient/run.jl:17",
      " [17] run(policy::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing}, stop_condition::StopAfterStep{ProgressMeter.Progress}, hook::ComposedHook{Tuple{DoEveryNStep{typeof(saveModel)}, DoEveryNStep{typeof(validate_policy)}}})",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/yeRLW/src/core/run.jl:10",
      " [18] top-level scope",
      "    @ In[29]:1",
      " [19] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [20] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(1_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000), \n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2114ed8f",
   "metadata": {},
   "source": [
    "ArgumentError: Normal: the condition σ >= zero(σ) is not satisfied.\n",
    "\n",
    "Stacktrace:\n",
    "  [1] macro expansion\n",
    "    @ ~/.julia/packages/Distributions/Xrm9e/src/utils.jl:6 [inlined]\n",
    "  [2] #Normal#120\n",
    "    @ ~/.julia/packages/Distributions/Xrm9e/src/univariate/continuous/normal.jl:37 [inlined]\n",
    "  [3] Normal\n",
    "    @ ~/.julia/packages/Distributions/Xrm9e/src/univariate/continuous/normal.jl:36 [inlined]\n",
    "  [4] createinstance\n",
    "    @ ~/.julia/packages/StructArrays/w2GaP/src/interface.jl:49 [inlined]\n",
    "  [5] getindex\n",
    "    @ ~/.julia/packages/StructArrays/w2GaP/src/structarray.jl:365 [inlined]\n",
    "  [6] _getindex\n",
    "    @ ./abstractarray.jl:1274 [inlined]\n",
    "  [7] getindex\n",
    "    @ ./abstractarray.jl:1241 [inlined]\n",
    "  [8] _broadcast_getindex\n",
    "    @ ./broadcast.jl:636 [inlined]\n",
    "  [9] _getindex\n",
    "    @ ./broadcast.jl:667 [inlined]\n",
    " [10] _getindex\n",
    "    @ ./broadcast.jl:666 [inlined]\n",
    " [11] _broadcast_getindex\n",
    "    @ ./broadcast.jl:642 [inlined]\n",
    " [12] getindex\n",
    "    @ ./broadcast.jl:597 [inlined]\n",
    " [13] copy(bc::Base.Broadcast.Broadcasted{StructArrays.StructArrayStyle{Base.Broadcast.DefaultArrayStyle{2}, 2}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, typeof(rand), Tuple{Base.RefValue{Random._GLOBAL_RNG}, StructArrays.StructArray{Normal, 2, NamedTuple{(:μ, :σ), Tuple{Matrix{Float64}, Matrix{Float64}}}, Int64}}})\n",
    "    @ Base.Broadcast ./broadcast.jl:899\n",
    " [14] materialize\n",
    "    @ ./broadcast.jl:860 [inlined]\n",
    " [15] (::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}})(env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing})\n",
    "    @ ReinforcementLearningZoo ~/.julia/packages/ReinforcementLearningZoo/tvfq9/src/algorithms/policy_gradient/ppo.jl:192\n",
    " [16] _run(policy::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing}, stop_condition::StopAfterStep{ProgressMeter.Progress}, hook::ComposedHook{Tuple{DoEveryNStep{typeof(saveModel)}, DoEveryNStep{typeof(validate_policy)}}})\n",
    "    @ ReinforcementLearningZoo ~/.julia/packages/ReinforcementLearningZoo/tvfq9/src/algorithms/policy_gradient/run.jl:17\n",
    " [17] run(policy::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing}, stop_condition::StopAfterStep{ProgressMeter.Progress}, hook::ComposedHook{Tuple{DoEveryNStep{typeof(saveModel)}, DoEveryNStep{typeof(validate_policy)}}})\n",
    "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/yeRLW/src/core/run.jl:10\n",
    " [18] top-level scope\n",
    "    @ In[29]:1\n",
    " [19] eval\n",
    "    @ ./boot.jl:368 [inlined]\n",
    " [20] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
    "    @ Base ./loading.jl:1428\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49a302a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip850\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip850)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip851\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip850)\" d=\"\n",
       "M202.177 1486.45 L2352.76 1486.45 L2352.76 47.2441 L202.177 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip852\">\n",
       "    <rect x=\"202\" y=\"47\" width=\"2152\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip852)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  516.648,1486.45 516.648,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip852)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  897.057,1486.45 897.057,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip852)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1277.47,1486.45 1277.47,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip852)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1657.88,1486.45 1657.88,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip852)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2038.28,1486.45 2038.28,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.177,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  516.648,1486.45 516.648,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  897.057,1486.45 897.057,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1277.47,1486.45 1277.47,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1657.88,1486.45 1657.88,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2038.28,1486.45 2038.28,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip850)\" d=\"M520.896 1530.21 Q524.252 1530.93 526.127 1533.2 Q528.025 1535.47 528.025 1538.8 Q528.025 1543.92 524.507 1546.72 Q520.988 1549.52 514.507 1549.52 Q512.331 1549.52 510.016 1549.08 Q507.725 1548.66 505.271 1547.81 L505.271 1543.29 Q507.215 1544.43 509.53 1545.01 Q511.845 1545.58 514.368 1545.58 Q518.766 1545.58 521.058 1543.85 Q523.373 1542.11 523.373 1538.8 Q523.373 1535.75 521.22 1534.03 Q519.09 1532.3 515.271 1532.3 L511.243 1532.3 L511.243 1528.45 L515.456 1528.45 Q518.905 1528.45 520.734 1527.09 Q522.563 1525.7 522.563 1523.11 Q522.563 1520.45 520.664 1519.03 Q518.789 1517.6 515.271 1517.6 Q513.35 1517.6 511.151 1518.01 Q508.951 1518.43 506.313 1519.31 L506.313 1515.14 Q508.975 1514.4 511.289 1514.03 Q513.627 1513.66 515.688 1513.66 Q521.012 1513.66 524.113 1516.09 Q527.215 1518.5 527.215 1522.62 Q527.215 1525.49 525.572 1527.48 Q523.928 1529.45 520.896 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M897.462 1529.7 Q894.314 1529.7 892.462 1531.86 Q890.634 1534.01 890.634 1537.76 Q890.634 1541.49 892.462 1543.66 Q894.314 1545.82 897.462 1545.82 Q900.61 1545.82 902.439 1543.66 Q904.291 1541.49 904.291 1537.76 Q904.291 1534.01 902.439 1531.86 Q900.61 1529.7 897.462 1529.7 M906.745 1515.05 L906.745 1519.31 Q904.985 1518.48 903.18 1518.04 Q901.397 1517.6 899.638 1517.6 Q895.009 1517.6 892.555 1520.72 Q890.124 1523.85 889.777 1530.17 Q891.143 1528.15 893.203 1527.09 Q895.263 1526 897.74 1526 Q902.948 1526 905.958 1529.17 Q908.99 1532.32 908.99 1537.76 Q908.99 1543.08 905.842 1546.3 Q902.694 1549.52 897.462 1549.52 Q891.467 1549.52 888.296 1544.94 Q885.124 1540.33 885.124 1531.6 Q885.124 1523.41 889.013 1518.55 Q892.902 1513.66 899.453 1513.66 Q901.212 1513.66 902.995 1514.01 Q904.8 1514.36 906.745 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M1267.77 1548.13 L1267.77 1543.87 Q1269.53 1544.7 1271.33 1545.14 Q1273.14 1545.58 1274.87 1545.58 Q1279.5 1545.58 1281.93 1542.48 Q1284.39 1539.36 1284.73 1533.01 Q1283.39 1535.01 1281.33 1536.07 Q1279.27 1537.13 1276.77 1537.13 Q1271.59 1537.13 1268.55 1534.01 Q1265.55 1530.86 1265.55 1525.42 Q1265.55 1520.1 1268.69 1516.88 Q1271.84 1513.66 1277.07 1513.66 Q1283.07 1513.66 1286.22 1518.27 Q1289.39 1522.85 1289.39 1531.6 Q1289.39 1539.77 1285.5 1544.66 Q1281.63 1549.52 1275.08 1549.52 Q1273.32 1549.52 1271.52 1549.17 Q1269.71 1548.82 1267.77 1548.13 M1277.07 1533.48 Q1280.22 1533.48 1282.05 1531.32 Q1283.9 1529.17 1283.9 1525.42 Q1283.9 1521.7 1282.05 1519.54 Q1280.22 1517.37 1277.07 1517.37 Q1273.92 1517.37 1272.07 1519.54 Q1270.24 1521.7 1270.24 1525.42 Q1270.24 1529.17 1272.07 1531.32 Q1273.92 1533.48 1277.07 1533.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M1633.36 1544.91 L1641 1544.91 L1641 1518.55 L1632.69 1520.21 L1632.69 1515.95 L1640.95 1514.29 L1645.63 1514.29 L1645.63 1544.91 L1653.27 1544.91 L1653.27 1548.85 L1633.36 1548.85 L1633.36 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M1666.74 1544.91 L1683.06 1544.91 L1683.06 1548.85 L1661.12 1548.85 L1661.12 1544.91 Q1663.78 1542.16 1668.36 1537.53 Q1672.97 1532.88 1674.15 1531.53 Q1676.39 1529.01 1677.27 1527.27 Q1678.18 1525.51 1678.18 1523.82 Q1678.18 1521.07 1676.23 1519.33 Q1674.31 1517.6 1671.21 1517.6 Q1669.01 1517.6 1666.56 1518.36 Q1664.13 1519.13 1661.35 1520.68 L1661.35 1515.95 Q1664.17 1514.82 1666.63 1514.24 Q1669.08 1513.66 1671.12 1513.66 Q1676.49 1513.66 1679.68 1516.35 Q1682.88 1519.03 1682.88 1523.52 Q1682.88 1525.65 1682.07 1527.57 Q1681.28 1529.47 1679.17 1532.07 Q1678.59 1532.74 1675.49 1535.95 Q1672.39 1539.15 1666.74 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M2013.47 1544.91 L2021.11 1544.91 L2021.11 1518.55 L2012.8 1520.21 L2012.8 1515.95 L2021.06 1514.29 L2025.74 1514.29 L2025.74 1544.91 L2033.38 1544.91 L2033.38 1548.85 L2013.47 1548.85 L2013.47 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M2042.87 1514.29 L2061.22 1514.29 L2061.22 1518.22 L2047.15 1518.22 L2047.15 1526.7 Q2048.17 1526.35 2049.19 1526.19 Q2050.21 1526 2051.22 1526 Q2057.01 1526 2060.39 1529.17 Q2063.77 1532.34 2063.77 1537.76 Q2063.77 1543.34 2060.3 1546.44 Q2056.83 1549.52 2050.51 1549.52 Q2048.33 1549.52 2046.06 1549.15 Q2043.82 1548.78 2041.41 1548.04 L2041.41 1543.34 Q2043.49 1544.47 2045.71 1545.03 Q2047.94 1545.58 2050.41 1545.58 Q2054.42 1545.58 2056.76 1543.48 Q2059.09 1541.37 2059.09 1537.76 Q2059.09 1534.15 2056.76 1532.04 Q2054.42 1529.94 2050.41 1529.94 Q2048.54 1529.94 2046.66 1530.35 Q2044.81 1530.77 2042.87 1531.65 L2042.87 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip852)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  202.177,1446.83 2352.76,1446.83 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip852)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  202.177,1166.22 2352.76,1166.22 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip852)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  202.177,885.617 2352.76,885.617 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip852)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  202.177,605.01 2352.76,605.01 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip852)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  202.177,324.402 2352.76,324.402 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.177,1486.45 202.177,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.177,1446.83 221.074,1446.83 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.177,1166.22 221.074,1166.22 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.177,885.617 221.074,885.617 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.177,605.01 221.074,605.01 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  202.177,324.402 221.074,324.402 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip850)\" d=\"M154.232 1432.63 Q150.621 1432.63 148.793 1436.2 Q146.987 1439.74 146.987 1446.87 Q146.987 1453.97 148.793 1457.54 Q150.621 1461.08 154.232 1461.08 Q157.867 1461.08 159.672 1457.54 Q161.501 1453.97 161.501 1446.87 Q161.501 1439.74 159.672 1436.2 Q157.867 1432.63 154.232 1432.63 M154.232 1428.93 Q160.042 1428.93 163.098 1433.53 Q166.177 1438.12 166.177 1446.87 Q166.177 1455.59 163.098 1460.2 Q160.042 1464.78 154.232 1464.78 Q148.422 1464.78 145.343 1460.2 Q142.288 1455.59 142.288 1446.87 Q142.288 1438.12 145.343 1433.53 Q148.422 1428.93 154.232 1428.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M54.5569 1179.57 L62.1958 1179.57 L62.1958 1153.2 L53.8856 1154.87 L53.8856 1150.61 L62.1495 1148.94 L66.8254 1148.94 L66.8254 1179.57 L74.4642 1179.57 L74.4642 1183.5 L54.5569 1183.5 L54.5569 1179.57 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M93.9086 1152.02 Q90.2975 1152.02 88.4688 1155.59 Q86.6632 1159.13 86.6632 1166.26 Q86.6632 1173.37 88.4688 1176.93 Q90.2975 1180.47 93.9086 1180.47 Q97.5428 1180.47 99.3483 1176.93 Q101.177 1173.37 101.177 1166.26 Q101.177 1159.13 99.3483 1155.59 Q97.5428 1152.02 93.9086 1152.02 M93.9086 1148.32 Q99.7187 1148.32 102.774 1152.93 Q105.853 1157.51 105.853 1166.26 Q105.853 1174.99 102.774 1179.59 Q99.7187 1184.18 93.9086 1184.18 Q88.0984 1184.18 85.0197 1179.59 Q81.9642 1174.99 81.9642 1166.26 Q81.9642 1157.51 85.0197 1152.93 Q88.0984 1148.32 93.9086 1148.32 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M124.07 1152.02 Q120.459 1152.02 118.631 1155.59 Q116.825 1159.13 116.825 1166.26 Q116.825 1173.37 118.631 1176.93 Q120.459 1180.47 124.07 1180.47 Q127.705 1180.47 129.51 1176.93 Q131.339 1173.37 131.339 1166.26 Q131.339 1159.13 129.51 1155.59 Q127.705 1152.02 124.07 1152.02 M124.07 1148.32 Q129.881 1148.32 132.936 1152.93 Q136.015 1157.51 136.015 1166.26 Q136.015 1174.99 132.936 1179.59 Q129.881 1184.18 124.07 1184.18 Q118.26 1184.18 115.182 1179.59 Q112.126 1174.99 112.126 1166.26 Q112.126 1157.51 115.182 1152.93 Q118.26 1148.32 124.07 1148.32 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M154.232 1152.02 Q150.621 1152.02 148.793 1155.59 Q146.987 1159.13 146.987 1166.26 Q146.987 1173.37 148.793 1176.93 Q150.621 1180.47 154.232 1180.47 Q157.867 1180.47 159.672 1176.93 Q161.501 1173.37 161.501 1166.26 Q161.501 1159.13 159.672 1155.59 Q157.867 1152.02 154.232 1152.02 M154.232 1148.32 Q160.042 1148.32 163.098 1152.93 Q166.177 1157.51 166.177 1166.26 Q166.177 1174.99 163.098 1179.59 Q160.042 1184.18 154.232 1184.18 Q148.422 1184.18 145.343 1179.59 Q142.288 1174.99 142.288 1166.26 Q142.288 1157.51 145.343 1152.93 Q148.422 1148.32 154.232 1148.32 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M57.7745 898.962 L74.0939 898.962 L74.0939 902.897 L52.1495 902.897 L52.1495 898.962 Q54.8115 896.208 59.3949 891.578 Q64.0013 886.925 65.1819 885.583 Q67.4272 883.06 68.3068 881.323 Q69.2096 879.564 69.2096 877.874 Q69.2096 875.12 67.2652 873.384 Q65.3439 871.648 62.2421 871.648 Q60.043 871.648 57.5893 872.411 Q55.1588 873.175 52.381 874.726 L52.381 870.004 Q55.2051 868.87 57.6588 868.291 Q60.1124 867.712 62.1495 867.712 Q67.5198 867.712 70.7142 870.398 Q73.9087 873.083 73.9087 877.573 Q73.9087 879.703 73.0985 881.624 Q72.3115 883.523 70.205 886.115 Q69.6263 886.786 66.5245 890.004 Q63.4226 893.198 57.7745 898.962 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M93.9086 871.416 Q90.2975 871.416 88.4688 874.981 Q86.6632 878.523 86.6632 885.652 Q86.6632 892.759 88.4688 896.323 Q90.2975 899.865 93.9086 899.865 Q97.5428 899.865 99.3483 896.323 Q101.177 892.759 101.177 885.652 Q101.177 878.523 99.3483 874.981 Q97.5428 871.416 93.9086 871.416 M93.9086 867.712 Q99.7187 867.712 102.774 872.319 Q105.853 876.902 105.853 885.652 Q105.853 894.379 102.774 898.985 Q99.7187 903.569 93.9086 903.569 Q88.0984 903.569 85.0197 898.985 Q81.9642 894.379 81.9642 885.652 Q81.9642 876.902 85.0197 872.319 Q88.0984 867.712 93.9086 867.712 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M124.07 871.416 Q120.459 871.416 118.631 874.981 Q116.825 878.523 116.825 885.652 Q116.825 892.759 118.631 896.323 Q120.459 899.865 124.07 899.865 Q127.705 899.865 129.51 896.323 Q131.339 892.759 131.339 885.652 Q131.339 878.523 129.51 874.981 Q127.705 871.416 124.07 871.416 M124.07 867.712 Q129.881 867.712 132.936 872.319 Q136.015 876.902 136.015 885.652 Q136.015 894.379 132.936 898.985 Q129.881 903.569 124.07 903.569 Q118.26 903.569 115.182 898.985 Q112.126 894.379 112.126 885.652 Q112.126 876.902 115.182 872.319 Q118.26 867.712 124.07 867.712 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M154.232 871.416 Q150.621 871.416 148.793 874.981 Q146.987 878.523 146.987 885.652 Q146.987 892.759 148.793 896.323 Q150.621 899.865 154.232 899.865 Q157.867 899.865 159.672 896.323 Q161.501 892.759 161.501 885.652 Q161.501 878.523 159.672 874.981 Q157.867 871.416 154.232 871.416 M154.232 867.712 Q160.042 867.712 163.098 872.319 Q166.177 876.902 166.177 885.652 Q166.177 894.379 163.098 898.985 Q160.042 903.569 154.232 903.569 Q148.422 903.569 145.343 898.985 Q142.288 894.379 142.288 885.652 Q142.288 876.902 145.343 872.319 Q148.422 867.712 154.232 867.712 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M67.9133 603.656 Q71.2698 604.373 73.1448 606.642 Q75.0429 608.91 75.0429 612.244 Q75.0429 617.359 71.5244 620.16 Q68.0059 622.961 61.5245 622.961 Q59.3486 622.961 57.0338 622.521 Q54.7421 622.105 52.2884 621.248 L52.2884 616.734 Q54.2328 617.869 56.5477 618.447 Q58.8625 619.026 61.3856 619.026 Q65.7837 619.026 68.0754 617.29 Q70.3902 615.554 70.3902 612.244 Q70.3902 609.188 68.2374 607.475 Q66.1078 605.739 62.2884 605.739 L58.2606 605.739 L58.2606 601.897 L62.4735 601.897 Q65.9226 601.897 67.7513 600.531 Q69.58 599.142 69.58 596.549 Q69.58 593.887 67.6819 592.475 Q65.8069 591.04 62.2884 591.04 Q60.3671 591.04 58.168 591.457 Q55.969 591.873 53.3301 592.753 L53.3301 588.586 Q55.9921 587.846 58.3069 587.475 Q60.6449 587.105 62.705 587.105 Q68.0291 587.105 71.1309 589.535 Q74.2327 591.943 74.2327 596.063 Q74.2327 598.934 72.5892 600.924 Q70.9457 602.892 67.9133 603.656 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M93.9086 590.809 Q90.2975 590.809 88.4688 594.373 Q86.6632 597.915 86.6632 605.045 Q86.6632 612.151 88.4688 615.716 Q90.2975 619.258 93.9086 619.258 Q97.5428 619.258 99.3483 615.716 Q101.177 612.151 101.177 605.045 Q101.177 597.915 99.3483 594.373 Q97.5428 590.809 93.9086 590.809 M93.9086 587.105 Q99.7187 587.105 102.774 591.711 Q105.853 596.295 105.853 605.045 Q105.853 613.771 102.774 618.378 Q99.7187 622.961 93.9086 622.961 Q88.0984 622.961 85.0197 618.378 Q81.9642 613.771 81.9642 605.045 Q81.9642 596.295 85.0197 591.711 Q88.0984 587.105 93.9086 587.105 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M124.07 590.809 Q120.459 590.809 118.631 594.373 Q116.825 597.915 116.825 605.045 Q116.825 612.151 118.631 615.716 Q120.459 619.258 124.07 619.258 Q127.705 619.258 129.51 615.716 Q131.339 612.151 131.339 605.045 Q131.339 597.915 129.51 594.373 Q127.705 590.809 124.07 590.809 M124.07 587.105 Q129.881 587.105 132.936 591.711 Q136.015 596.295 136.015 605.045 Q136.015 613.771 132.936 618.378 Q129.881 622.961 124.07 622.961 Q118.26 622.961 115.182 618.378 Q112.126 613.771 112.126 605.045 Q112.126 596.295 115.182 591.711 Q118.26 587.105 124.07 587.105 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M154.232 590.809 Q150.621 590.809 148.793 594.373 Q146.987 597.915 146.987 605.045 Q146.987 612.151 148.793 615.716 Q150.621 619.258 154.232 619.258 Q157.867 619.258 159.672 615.716 Q161.501 612.151 161.501 605.045 Q161.501 597.915 159.672 594.373 Q157.867 590.809 154.232 590.809 M154.232 587.105 Q160.042 587.105 163.098 591.711 Q166.177 596.295 166.177 605.045 Q166.177 613.771 163.098 618.378 Q160.042 622.961 154.232 622.961 Q148.422 622.961 145.343 618.378 Q142.288 613.771 142.288 605.045 Q142.288 596.295 145.343 591.711 Q148.422 587.105 154.232 587.105 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M66.5939 311.197 L54.7884 329.645 L66.5939 329.645 L66.5939 311.197 M65.367 307.122 L71.2466 307.122 L71.2466 329.645 L76.1772 329.645 L76.1772 333.534 L71.2466 333.534 L71.2466 341.682 L66.5939 341.682 L66.5939 333.534 L50.9921 333.534 L50.9921 329.02 L65.367 307.122 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M93.9086 310.201 Q90.2975 310.201 88.4688 313.766 Q86.6632 317.308 86.6632 324.437 Q86.6632 331.544 88.4688 335.108 Q90.2975 338.65 93.9086 338.65 Q97.5428 338.65 99.3483 335.108 Q101.177 331.544 101.177 324.437 Q101.177 317.308 99.3483 313.766 Q97.5428 310.201 93.9086 310.201 M93.9086 306.497 Q99.7187 306.497 102.774 311.104 Q105.853 315.687 105.853 324.437 Q105.853 333.164 102.774 337.77 Q99.7187 342.354 93.9086 342.354 Q88.0984 342.354 85.0197 337.77 Q81.9642 333.164 81.9642 324.437 Q81.9642 315.687 85.0197 311.104 Q88.0984 306.497 93.9086 306.497 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M124.07 310.201 Q120.459 310.201 118.631 313.766 Q116.825 317.308 116.825 324.437 Q116.825 331.544 118.631 335.108 Q120.459 338.65 124.07 338.65 Q127.705 338.65 129.51 335.108 Q131.339 331.544 131.339 324.437 Q131.339 317.308 129.51 313.766 Q127.705 310.201 124.07 310.201 M124.07 306.497 Q129.881 306.497 132.936 311.104 Q136.015 315.687 136.015 324.437 Q136.015 333.164 132.936 337.77 Q129.881 342.354 124.07 342.354 Q118.26 342.354 115.182 337.77 Q112.126 333.164 112.126 324.437 Q112.126 315.687 115.182 311.104 Q118.26 306.497 124.07 306.497 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M154.232 310.201 Q150.621 310.201 148.793 313.766 Q146.987 317.308 146.987 324.437 Q146.987 331.544 148.793 335.108 Q150.621 338.65 154.232 338.65 Q157.867 338.65 159.672 335.108 Q161.501 331.544 161.501 324.437 Q161.501 317.308 159.672 313.766 Q157.867 310.201 154.232 310.201 M154.232 306.497 Q160.042 306.497 163.098 311.104 Q166.177 315.687 166.177 324.437 Q166.177 333.164 163.098 337.77 Q160.042 342.354 154.232 342.354 Q148.422 342.354 145.343 337.77 Q142.288 333.164 142.288 324.437 Q142.288 315.687 145.343 311.104 Q148.422 306.497 154.232 306.497 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip852)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  263.042,1445.72 389.845,1403.5 516.648,1381.08 643.451,1445.72 770.254,93.0682 897.057,1445.72 1023.86,1445.72 1150.66,94.1989 1277.47,1445.72 1404.27,1445.7 \n",
       "  1531.07,1445.71 1657.88,87.9763 1784.68,1445.71 1911.48,1445.72 2038.28,1386.18 2165.09,1385.89 2291.89,91.0859 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip850)\" d=\"\n",
       "M1989.69 198.898 L2281.07 198.898 L2281.07 95.2176 L1989.69 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1989.69,198.898 2281.07,198.898 2281.07,95.2176 1989.69,95.2176 1989.69,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip850)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2013.58,147.058 2156.95,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip850)\" d=\"M2194.69 166.745 Q2192.89 171.375 2191.17 172.787 Q2189.46 174.199 2186.59 174.199 L2183.19 174.199 L2183.19 170.634 L2185.69 170.634 Q2187.45 170.634 2188.42 169.8 Q2189.39 168.967 2190.57 165.865 L2191.34 163.921 L2180.85 138.412 L2185.36 138.412 L2193.46 158.689 L2201.57 138.412 L2206.08 138.412 L2194.69 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip850)\" d=\"M2213.37 160.402 L2221.01 160.402 L2221.01 134.037 L2212.7 135.703 L2212.7 131.444 L2220.96 129.778 L2225.64 129.778 L2225.64 160.402 L2233.28 160.402 L2233.28 164.338 L2213.37 164.338 L2213.37 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(episode_test_reward_hook.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb0d4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_visualization(); # closes the MeshCat visualization"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
