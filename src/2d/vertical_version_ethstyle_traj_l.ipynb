{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649b76a",
   "metadata": {},
   "source": [
    "# Init Bionic VTOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96751412",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position\n",
    "\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;\n",
    "using Distributions;\n",
    "\n",
    "using Plots;\n",
    "using Statistics;\n",
    "\n",
    "using BSON: @save, @load # save mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e4ee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: MeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "│ http://127.0.0.1:8700\n",
      "└ @ MeshCat /home/larissa/.julia/packages/MeshCat/Ax8pH/src/visualizer.jl:73\n"
     ]
    }
   ],
   "source": [
    "create_visualization();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9557df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indicates how many threads Julia was started with. This is important for the multi-threaded environment\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411db62",
   "metadata": {},
   "source": [
    "# Create Reinforcement Learning Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96af6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametric Constructor for a subtype of AbstractEnv\n",
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv \n",
    "    action_space::A # action space\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}} # observation space\n",
    "    state::Vector{T} # current state space\n",
    "    action::ACT # action space\n",
    "    done::Bool # done\n",
    "    t::T # time\n",
    "    rng::R # random number generator\n",
    "\n",
    "    name::String # for multible environoments\n",
    "    visualization::Bool # visualization\n",
    "    realtime::Bool # realtime\n",
    "    \n",
    "    # Everything you need aditionaly can also go in here.\n",
    "    x_W::Vector{T} # current position\n",
    "    v_B::Vector{T} # velocity\n",
    "    R_W::Matrix{T} # current rotation\n",
    "    ω_B::Vector{T} # rotation velocitiy\n",
    "    wind_W::Vector{T} # wind\n",
    "    Δt::T # Δ time\n",
    "    \n",
    "    # Current Bonus / Target\n",
    "    num_waypoints::Int # includig start point\n",
    "    waypoints::Vector{Vector{T}}\n",
    "    reached_goal::BitVector\n",
    "    \n",
    "    norm_way::T\n",
    "    progress::T\n",
    "    progress_prev::T\n",
    "    current_point::Int\n",
    "    reached_goal_in_step::Bool\n",
    "    \n",
    "    r_tol::T # tolerance within drones has to reach waypoint\n",
    "    projected_position::Vector{T} # projected position of drone along trajectory\n",
    "\n",
    "    slow_mode::Bool # slow flight learning mode\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ede3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_TOL = 1.0;\n",
    "N_WAYPOINTS = 8;\n",
    "SLOW_MODE = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a6873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a keyword-based constructor for the type declared in the mutable struct typedef. \n",
    "# It could also be done with the macro Base.@kwdef.\n",
    "function VtolEnv(;\n",
    "    rng = Random.GLOBAL_RNG, # Random number generation\n",
    "    name = \"vtol\",\n",
    "    visualization = false,\n",
    "    realtime = false,\n",
    "    kwargs... # let the function take an arbitrary number of keyword arguments \n",
    ")\n",
    "    \n",
    "    T = Float64; # explicit type which is used e.g. in state. Cannot be altered due to the poor matrix defininon.\n",
    "\n",
    "    \n",
    "    action_space = Space(\n",
    "        ClosedInterval{T}[\n",
    "            0.0..2.0, # propeller 1\n",
    "            0.0..2.0, # propeller 2\n",
    "            ], \n",
    "    )\n",
    "\n",
    "    \n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            # orientate yourself on the state space from the paper\n",
    "            typemin(T)..typemax(T), # position along x\n",
    "            typemin(T)..typemax(T), # position along z\n",
    "            \n",
    "            typemin(T)..typemax(T), # orientation along x\n",
    "            typemin(T)..typemax(T), # orientation along z\n",
    "            \n",
    "            typemin(T)..typemax(T), # velocity along x BODY coordinates\n",
    "            typemin(T)..typemax(T), # velocity along y BODY coordinates\n",
    "            \n",
    "            typemin(T)..typemax(T), # rotational velocity along z BODY coordinates\n",
    "            \n",
    "            typemin(T)..typemax(T), # position error along x (next gate - current position)\n",
    "            typemin(T)..typemax(T), # position error along z (next gate - current position)\n",
    "            \n",
    "            typemin(T)..typemax(T), # way to next next gate x (next next gate - next gate)\n",
    "            typemin(T)..typemax(T), # way to next next gate z (next next gate - next gate)\n",
    "            # TODO: more points?\n",
    "            ], \n",
    "    )\n",
    "    \n",
    "    num_waypoints = N_WAYPOINTS # number of waypoints, includig start point\n",
    "    waypoints = generate_trajectory(num_waypoints) # trajectory with num_waypoints waypoints (+ start point) \n",
    "    reached_goal = falses(num_waypoints)\n",
    "    \n",
    "    norm_way = 0.0 \n",
    "    for i in 1:(num_waypoints - 1)\n",
    "        norm_way += norm(waypoints[i] - waypoints[i + 1])\n",
    "    end\n",
    "    \n",
    "    if visualization #visualizes VTOL and waypoints\n",
    "        create_VTOL(name, actuators = true, color_vec=[1.0; 1.0; 0.6; 1.0]);\n",
    "        visualize_waypoints(waypoints, 0.15)\n",
    "    end\n",
    "\n",
    "    environment = VtolEnv(\n",
    "        action_space,\n",
    "        state_space, \n",
    "        zeros(T, length(state_space)), # current state, needs to be extended\n",
    "        rand(action_space), #initialization action\n",
    "        false, # episode done \n",
    "        0.0, # time\n",
    "        rng, # random number generator  \n",
    "        \n",
    "        name,\n",
    "        visualization,\n",
    "        realtime,\n",
    "        \n",
    "        zeros(T, 3), # x_W, current position\n",
    "        zeros(T, 3), # v_B, velocity\n",
    "        [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0], # R_W, current rotation, Float64... so T needs to be Float64\n",
    "        zeros(T, 3), # ω_B\n",
    "        zeros(T, 3), # wind_W\n",
    "        T(0.025), # Δt \n",
    "        \n",
    "        num_waypoints, # includig start point\n",
    "        waypoints, \n",
    "        reached_goal,\n",
    "        \n",
    "        norm_way, # norm_way\n",
    "        0.0, # progress\n",
    "        0.0, # progress_prev\n",
    "        2, # current point\n",
    "        false, # reached_goal_in_step\n",
    "        \n",
    "        R_TOL, # r_tol\n",
    "        zeros(T, 3), # projected_position\n",
    "\n",
    "        SLOW_MODE # slow_mode\n",
    "    )\n",
    "    \n",
    "    \n",
    "    reset!(environment)\n",
    "    \n",
    "    return environment\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec660d5e",
   "metadata": {},
   "source": [
    "Just for explanation:\n",
    "\n",
    "1. A mutable Struct is created. A struct is a constructor and a constructor is a function that creates new objects.\n",
    "2. A outer keyword-based constructor method is added for the type declared in the mutable struct typedef before.\n",
    "\n",
    "So now we have a function with two methods. Julia will decide which method to call by multiple dispatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3c4bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "# 2 methods for type constructor:<ul><li> VtolEnv(; <i>rng, name, visualization, realtime, kwargs...</i>) in Main at In[6]:3</li> <li> VtolEnv(action_space::<b>A</b>, observation_space::<b>Space{Array{ClosedInterval{T}, 1}}</b>, state::<b>Vector{T}</b>, action::<b>ACT</b>, done::<b>Bool</b>, t::<b>T</b>, rng::<b>R</b>, name::<b>String</b>, visualization::<b>Bool</b>, realtime::<b>Bool</b>, x_W::<b>Vector{T}</b>, v_B::<b>Vector{T}</b>, R_W::<b>Matrix{T}</b>, ω_B::<b>Vector{T}</b>, wind_W::<b>Vector{T}</b>, Δt::<b>T</b>, num_waypoints::<b>Int64</b>, waypoints::<b>Array{Vector{T}, 1}</b>, reached_goal::<b>BitVector</b>, norm_way::<b>T</b>, progress::<b>T</b>, progress_prev::<b>T</b>, current_point::<b>Int64</b>, reached_goal_in_step::<b>Bool</b>, r_tol::<b>T</b>, projected_position::<b>Vector{T}</b>, slow_mode::<b>Bool</b>)<i> where {A, T, ACT, R<:AbstractRNG}</i> in Main at In[4]:2</li> </ul>"
      ],
      "text/plain": [
       "# 2 methods for type constructor:\n",
       "[1] VtolEnv(; rng, name, visualization, realtime, kwargs...) in Main at In[6]:3\n",
       "[2] VtolEnv(action_space::A, observation_space::Space{Array{ClosedInterval{T}, 1}}, state::Vector{T}, action::ACT, done::Bool, t::T, rng::R, name::String, visualization::Bool, realtime::Bool, x_W::Vector{T}, v_B::Vector{T}, R_W::Matrix{T}, ω_B::Vector{T}, wind_W::Vector{T}, Δt::T, num_waypoints::Int64, waypoints::Array{Vector{T}, 1}, reached_goal::BitVector, norm_way::T, progress::T, progress_prev::T, current_point::Int64, reached_goal_in_step::Bool, r_tol::T, projected_position::Vector{T}, slow_mode::Bool) where {A, T, ACT, R<:AbstractRNG} in Main at In[4]:2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(VtolEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806413d1",
   "metadata": {},
   "source": [
    "# Define the RL interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f822029",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b48de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "function scale_for_slowmode(slow_mode::Bool, v_min::T, v_max::T, d_max::T, x_W::Vector{T}, projected_position::Vector{T}, v_B::Vector{T}) where T\n",
    "    # TODO safe in utils\n",
    "    if slow_mode == false\n",
    "        return 1\n",
    "    else\n",
    "        if norm(v_B) > v_max\n",
    "            s_vmax = 10^(v_max - norm(v_B))\n",
    "        else\n",
    "            s_vmax = 1\n",
    "        end\n",
    "\n",
    "        if norm(v_B) < v_min\n",
    "            s_vmin = 10^(norm(v_B) - v_min)\n",
    "        else\n",
    "            s_vmin = 1\n",
    "        end\n",
    "\n",
    "        if norm(x_W - projected_position) > d_max\n",
    "            s_gd = exp(-norm(x_W - projected_position) + d_max)\n",
    "        else\n",
    "            s_gd = 1\n",
    "        end\n",
    "        s = s_vmax * s_vmin * s_gd\n",
    "    end\n",
    "    return s\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f7fb89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function computeReward(env::VtolEnv{A,T}) where {A,T}\n",
    "    \n",
    "    v_min = 4.0 # min velocity\n",
    "    v_max = 50.0 # max velocity\n",
    "    d_max = 0.50 \n",
    "\n",
    "\n",
    "    s = scale_for_slowmode(env.slow_mode, v_min, v_max, d_max, env.x_W, env.projected_position, env.v_B)\n",
    "    \n",
    "    # Todo norm weg? \n",
    "    k_p = 5.0 * s / env.norm_way # factor for progress (between current position and last position) reward \n",
    "    r_p = (env.progress - env.progress_prev); # reward for progress (between current position and last position)\n",
    "\n",
    "    k_s = s * (2 * v_max * env.Δt) / (env.norm_way^2) #5.0 # factor for reached distance (overall) reward\n",
    "    r_s = env.progress # reward for reached distance (overall)\n",
    "    \n",
    "    k_wp = 10.0 # * env.num_waypoints # factor for reached gate reward\n",
    "    r_wp = 0.0 # reward for reached gate\n",
    "    if env.reached_goal_in_step\n",
    "        r_wp = exp(-norm(env.x_W - env.waypoints[env.current_point - 1])/env.r_tol)\n",
    "    end \n",
    "\n",
    "    k_ω = 0.001 # factor for too high body rate penalty\n",
    "    norm_ω = norm(env.ω_B[3]) # penalty for body rate\n",
    "\n",
    "    if env.x_W[3] < -2\n",
    "        fall = 1\n",
    "    else\n",
    "        fall = 0\n",
    "    end\n",
    "\n",
    "    return k_p * r_p + k_s * r_s + k_wp * r_wp - k_ω * norm_ω - fall\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = computeReward(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae45ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    # Visualize initial state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, [0.0; 0.0; 0.0; 0.0]);\n",
    "    end\n",
    "    \n",
    "    env.x_W = [0.0; 0.0; 0.0];\n",
    "    env.v_B = [0.0; 0.0; 0.0];\n",
    "    env.R_W = Matrix(UnitQuaternion(RotZ(-pi/2.0)*RotY(-pi/2.0)*RotX(pi)));\n",
    "\n",
    "    env.ω_B = [0.0; 0.0; 0.0];\n",
    "    env.wind_W = [0.0; 0.0; 0.0];\n",
    "    \n",
    "    #env.num_waypoints = 4; # includig start point\n",
    "    env.waypoints = generate_trajectory(env.num_waypoints);\n",
    "    env.reached_goal = falses(env.num_waypoints);\n",
    "    env.reached_goal[1] = true; # set first point to reached (start point)\n",
    "    \n",
    "    env.current_point = 2;\n",
    "    env.reached_goal_in_step = false;\n",
    "    #env.r_tol = 0.3;\n",
    "    \n",
    "    if env.visualization\n",
    "        visualize_waypoints(env.waypoints, 0.15); \n",
    "    end\n",
    "    \n",
    "    norm_way = 0.0 \n",
    "    for i in 1:(env.num_waypoints - 1)\n",
    "        norm_way += norm(env.waypoints[i] - env.waypoints[i + 1])\n",
    "    end\n",
    "    \n",
    "    env.norm_way = norm_way\n",
    "    env.progress = 0.0;\n",
    "    env.progress_prev = 0.0;\n",
    "    \n",
    "    \n",
    "    env.state = [env.x_W[1]; # position along x\n",
    "                 env.x_W[3]; # position along z\n",
    "        \n",
    "                 env.R_W[1,1]; # orientation along x\n",
    "                 env.R_W[3,1]; # orientation along z\n",
    "        \n",
    "                 env.v_B[1]; # velocity along x BODY coordinates\n",
    "                 env.v_B[2]; # velocity along y BODY coordinates  \n",
    "        \n",
    "                 env.ω_B[3]; # rotational velocity along z BODY coordinates\n",
    "        \n",
    "                 env.waypoints[2][1] - env.x_W[1]; # position error to next gate along x\n",
    "                 env.waypoints[2][3] - env.x_W[3]; # position error to next gate along z\n",
    "                 \n",
    "                 0.0; # way to next next gate x \n",
    "                 2.0] # way to next next gate z \n",
    "    \n",
    "    if env.num_waypoints >= 3\n",
    "        env.state[10] = env.waypoints[3][1] - env.x_W[1]; # way to next next gate x \n",
    "        env.state[11] = env.waypoints[3][3] - env.x_W[3]; # way to next next gate z \n",
    "    end\n",
    "        \n",
    "    env.t = 0.0;\n",
    "    env.action = [0.0, 0.0];\n",
    "    env.done = false;\n",
    "\n",
    "    env.projected_position = [0; 0; 0]\n",
    "    \n",
    "    nothing\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cf1a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a methods for a callable object.\n",
    "# So when a VtolEnv object is created, it has this method that can be called\n",
    "function (env::VtolEnv)(a)\n",
    "    # TODO: set flaps later in 3D\n",
    "    # set the propeller trust and the two flaps 2D case\n",
    "    next_action = [a[1], a[2], 0.0, 0.0]\n",
    "   \n",
    "    _step!(env, next_action)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0e9eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VtolEnv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26a116cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "# 3 methods for callable object:<ul><li> (env::<b>VtolEnv</b>)(a) in Main at In[12]:3</li> <li> (env::<b>AbstractEnv</b>)(action) in ReinforcementLearningBase</li> <li> (env::<b>AbstractEnv</b>)(action, player) in ReinforcementLearningBase</li> </ul>"
      ],
      "text/plain": [
       "# 3 methods for callable object:\n",
       "[1] (env::VtolEnv)(a) in Main at In[12]:3\n",
       "[2] (env::AbstractEnv)(action) in ReinforcementLearningBase\n",
       "[3] (env::AbstractEnv)(action, player) in ReinforcementLearningBase"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(env) # Just to explain which methods the object has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e7d4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "function _step!(env::VtolEnv, next_action)\n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(env.v_B, env.R_W, env.wind_W)\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = vtol_model(v_in_wind_B, next_action, eth_vtol_param);\n",
    "    # Limit to 2D\n",
    "    force_B[3] = 0.0; # Body Z\n",
    "    env.v_B[3] = 0.0;\n",
    "    torque_B[1] = 0.0; torque_B[2] = 0.0;  # Body X and Y\n",
    "    env.ω_B[1] = 0.0; env.ω_B[2] = 0.0;\n",
    "    # integrate rigid body dynamics for Δt\n",
    "    env.x_W, env.v_B, env.R_W, env.ω_B, time = rigid_body_simple(torque_B, force_B, env.x_W, env.v_B, env.R_W, env.ω_B, env.t, env.Δt, eth_vtol_param)\n",
    "    \n",
    "    \n",
    "    env.reached_goal_in_step = false;\n",
    "    if norm(env.x_W - env.waypoints[env.current_point]) < env.r_tol\n",
    "        env.reached_goal_in_step = true;\n",
    "        env.reached_goal[env.current_point] = true;\n",
    "        env.current_point += 1;\n",
    "    end\n",
    "        \n",
    "            \n",
    "    # calculate progress on trajectory\n",
    "    env.progress_prev = env.progress\n",
    "    \n",
    "    current_progress = 0.0\n",
    "    line_segment, env.projected_position = calculate_progress(env.waypoints, env.x_W)\n",
    "    \n",
    "    #env.current_point = line_segment + 1\n",
    "\n",
    "    for i in 2:(line_segment)\n",
    "       current_progress +=  norm(env.waypoints[i] - env.waypoints[i - 1])  \n",
    "    end\n",
    "    current_progress += norm(env.waypoints[line_segment] - env.projected_position)\n",
    "    \n",
    "    env.progress = current_progress\n",
    "    \n",
    "\n",
    "    if env.realtime\n",
    "        sleep(env.Δt) # TODO: just a dirty hack. this is of course slower than real time.\n",
    "    end\n",
    "\n",
    "    # Visualize the new state \n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, next_action)\n",
    "        \n",
    "        for i in eachindex(env.reached_goal)\n",
    "            if env.reached_goal[i]\n",
    "                create_sphere(\"fixgoal_$i\", 0.2, color=RGBA{Float32}(1.0, 0.0, 0.0, 1.0));\n",
    "                set_transform(\"fixgoal_$i\", env.waypoints[i]);\n",
    "            end\n",
    "        end\n",
    "    end\n",
    " \n",
    "\n",
    "    env.t += env.Δt\n",
    "    \n",
    "    env.state[1] = env.x_W[1]; # position along x\n",
    "    env.state[2] = env.x_W[3]; # position along z\n",
    "    \n",
    "    env.state[3] = env.R_W[1,1]; # orientation along x\n",
    "    env.state[4] = env.R_W[3,1]; # orientation along z\n",
    "    \n",
    "    env.state[5] = env.v_B[1]; # velocity along x BODY coordinates\n",
    "    env.state[6] = env.v_B[2]; # velocity along y BODY coordinates\n",
    "    \n",
    "    env.state[7] = env.ω_B[3];  # rotational velocity along z BODY coordinates\n",
    "    \n",
    "    # TODO add points\n",
    "    if env.current_point <= env.num_waypoints\n",
    "        env.state[8] = env.waypoints[env.current_point][1] - env.x_W[1]; # position error along x\n",
    "        env.state[9] = env.waypoints[env.current_point][3] - env.x_W[3]; # position error along z\n",
    "        \n",
    "        if env.current_point <= env.num_waypoints - 1\n",
    "            env.state[10] = env.waypoints[env.current_point + 1][1] - env.x_W[1]; # way to next next gate x (next next gate - next gate)\n",
    "            env.state[11] = env.waypoints[env.current_point + 1][3] - env.x_W[3]; # way to next next gate z (next next gate - next gate)\n",
    "        else\n",
    "            env.state[10] = env.state[8] + 0.0 # way to next next gate x (next next gate - next gate)\n",
    "            env.state[11] = env.state[9] + 2.0 # way to next next gate z (next next gate - next gate)\n",
    "        end\n",
    "    else\n",
    "        env.state[8] = 0.0; # position error along x\n",
    "        env.state[9] = 2.0; # position error along z\n",
    "        env.state[10] = 0.0 # way to next next gate x (next next gate - next gate)\n",
    "        env.state[11] = 2.0 # way to next next gate z (next next gate - next gate)\n",
    "    end\n",
    "        \n",
    "    \n",
    "    # Termination criteria\n",
    "    # TODO: Use many termination criteria so that you do not train unnecessarily in wrong areas\n",
    "    env.done = #true\n",
    "        # After time... How fast is drone+Range of desired point\n",
    "        # After reaching position (circle of r_tol)\n",
    "        norm(env.ω_B) > 100.0 || \n",
    "        norm(env.v_B) > 100.0 || # stop if body is too fast_point \n",
    "        env.x_W[3] < -5.0 || # stop if body is below -5m\n",
    "        env.t > env.num_waypoints * 3.0 ||# stop after 3s per point\n",
    "        norm(env.x_W - env.projected_position) > 5.0 || # too far off the path \n",
    "        env.reached_goal == trues(env.num_waypoints)\n",
    "\n",
    "    nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e1cd988",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:              | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "random policy with VtolEnv | \u001b[32m2000  \u001b[39m\u001b[36m 2000  \u001b[39m\u001b[0m2.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"random policy with VtolEnv\", Any[], 2000, false, false, true, 1.674056061158597e9, 1.674056063524517e9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RLBase.test_runnable!(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223a31f",
   "metadata": {},
   "source": [
    "Show an overview of the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6de74",
   "metadata": {},
   "source": [
    "# Setup of a reinforcement learning experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5683fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "MultiThreadEnv(8 x VtolEnv)"
      ],
      "text/plain": [
       "MultiThreadEnv(8 x VtolEnv)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123    \n",
    "rng = StableRNG(seed)\n",
    "    N_ENV = 8\n",
    "    UPDATE_FREQ = 1024\n",
    "    \n",
    "    \n",
    "    # define multiple environments for parallel training\n",
    "    env = MultiThreadEnv([\n",
    "        # use different names for the visualization\n",
    "        VtolEnv(; rng = StableRNG(hash(seed+i)), name = \"vtol$i\") for i in 1:N_ENV\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1f128b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function approximator\n",
    "# TODO: change architecture eventually, smaller?\n",
    "    ns, na = length(state(env[1])), length(action_space(env[1]))\n",
    "    approximator = ActorCritic(\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                    Dense(ns, 128, tanh; initW = glorot_uniform(rng)),#\n",
    "                    Dense(128, 128, tanh; initW = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(Dense(128, na; initW = glorot_uniform(rng))),\n",
    "                    logσ = Chain(Dense(128, na; initW = glorot_uniform(rng))),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 128, tanh; initW = glorot_uniform(rng)),\n",
    "                    Dense(128, 128, tanh; initW = glorot_uniform(rng)),\n",
    "                    Dense(128, 1; initW = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(1e-3),\n",
    "            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ea4c37c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: The GPU function is being called but the GPU is not accessible. \n",
      "│ Defaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "└ @ Flux /home/larissa/.julia/packages/Flux/7nTyc/src/functor.jl:187\n"
     ]
    }
   ],
   "source": [
    "    agent = Agent( # A wrapper of an AbstractPolicy\n",
    "        # AbstractPolicy: the policy to use\n",
    "        # TODO: change eventually to SAC or compare\n",
    "        policy = PPOPolicy(;\n",
    "                    approximator = approximator |> gpu,\n",
    "                    update_freq=UPDATE_FREQ,\n",
    "                    dist = Normal,\n",
    "                    # For parameters visit the docu: https://juliareinforcementlearning.org/docs/rlzoo/#ReinforcementLearningZoo.PPOPolicy\n",
    "                    ),\n",
    "        \n",
    "        # AbstractTrajectory: used to store transitions between an agent and an environment source\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float64} => (ns, N_ENV),\n",
    "            action = Matrix{Float64} => (na, N_ENV),\n",
    "            action_log_prob = Vector{Float64} => (N_ENV,),\n",
    "            reward = Vector{Float64} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f158a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "function saveModel(t, agent, env)\n",
    "    model = cpu(agent.policy.approximator)\n",
    "    # TODO: slow mode, fast mode\n",
    "    f = joinpath(\"./RL_models_fast/\", \"vtol_2D_ppo_$t.bson\") # TODO: evtl anpassen\n",
    "    @save f model\n",
    "    println(\"parameters at step $t saved to $f\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c689a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function loadModel()\n",
    "    # TODO: slow, fast mode\n",
    "    f = joinpath(\"./RL_models_slow/\", \"vtol_2D_ppo_700000.bson\") # TODO: evtl anpassen\n",
    "    @load f model\n",
    "    return model\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3c1858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validate_policy(t, agent, env)\n",
    "    run(agent.policy, test_env, StopAfterEpisode(1), episode_test_reward_hook)\n",
    "    # the result of the hook\n",
    "    println(\"test reward at step $t: $(episode_test_reward_hook.rewards[end])\")\n",
    "    \n",
    "end;\n",
    "\n",
    "episode_test_reward_hook = TotalRewardPerEpisode(;is_display_on_exit=false)\n",
    "# create a env only for reward test\n",
    "test_env = VtolEnv(;name = \"testVTOL\", visualization = true, realtime = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af72d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.policy.approximator = loadModel(); # TODO: un/comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb737010",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▌                                        |  ETA: 1:50:41\u001b[39mm9m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 10000 saved to ./RL_models_fast/vtol_2D_ppo_10000.bson\n",
      "test reward at step 10000: 13.577500537888692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▏                                       |  ETA: 1:01:23\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 20000 saved to ./RL_models_fast/vtol_2D_ppo_20000.bson\n",
      "test reward at step 20000: 38.01265955282131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▊                                       |  ETA: 0:53:03\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 30000 saved to ./RL_models_fast/vtol_2D_ppo_30000.bson\n",
      "test reward at step 30000: 38.14801729157819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▍                                      |  ETA: 0:45:05\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 40000 saved to ./RL_models_fast/vtol_2D_ppo_40000.bson\n",
      "test reward at step 40000: 39.07726522601278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   7%|██▉                                      |  ETA: 0:40:06\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 50000 saved to ./RL_models_fast/vtol_2D_ppo_50000.bson\n",
      "test reward at step 50000: 38.663934865859055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   9%|███▌                                     |  ETA: 0:36:45\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 60000 saved to ./RL_models_fast/vtol_2D_ppo_60000.bson\n",
      "test reward at step 60000: 38.23790807377817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  10%|████▏                                    |  ETA: 0:34:02\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 70000 saved to ./RL_models_fast/vtol_2D_ppo_70000.bson\n",
      "test reward at step 70000: 40.24512969417507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  11%|████▋                                    |  ETA: 0:33:24\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 80000 saved to ./RL_models_fast/vtol_2D_ppo_80000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:  11%|████▋                                    |  ETA: 0:35:02\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 80000: 38.778555271586384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  13%|█████▎                                   |  ETA: 0:32:17\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 90000 saved to ./RL_models_fast/vtol_2D_ppo_90000.bson\n",
      "test reward at step 90000: 37.528373214944196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  14%|█████▉                                   |  ETA: 0:30:48\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 100000 saved to ./RL_models_fast/vtol_2D_ppo_100000.bson\n",
      "test reward at step 100000: 42.93414721407266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  16%|██████▌                                  |  ETA: 0:30:14\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 110000 saved to ./RL_models_fast/vtol_2D_ppo_110000.bson\n",
      "test reward at step 110000: 37.613278970997776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  17%|███████                                  |  ETA: 0:29:11\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 120000 saved to ./RL_models_fast/vtol_2D_ppo_120000.bson\n",
      "test reward at step 120000: 38.19134608157998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  18%|███████▌                                 |  ETA: 0:28:15\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 130000 saved to ./RL_models_fast/vtol_2D_ppo_130000.bson\n",
      "test reward at step 130000: 41.63318578463873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  20%|████████▎                                |  ETA: 0:27:11\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 140000 saved to ./RL_models_fast/vtol_2D_ppo_140000.bson\n",
      "test reward at step 140000: 39.507704278332156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  21%|████████▊                                |  ETA: 0:26:54\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 150000 saved to ./RL_models_fast/vtol_2D_ppo_150000.bson\n",
      "test reward at step 150000: 38.21505170562461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  23%|█████████▍                               |  ETA: 0:25:50\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 160000 saved to ./RL_models_fast/vtol_2D_ppo_160000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:  23%|█████████▍                               |  ETA: 0:26:19\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 160000: 36.304188406531715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  24%|██████████                               |  ETA: 0:24:59\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 170000 saved to ./RL_models_fast/vtol_2D_ppo_170000.bson\n",
      "test reward at step 170000: 38.62763481473114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  25%|██████████▌                              |  ETA: 0:24:19\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 180000 saved to ./RL_models_fast/vtol_2D_ppo_180000.bson\n",
      "test reward at step 180000: 39.8113241476964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  27%|███████████▏                             |  ETA: 0:23:27\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 190000 saved to ./RL_models_fast/vtol_2D_ppo_190000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:  27%|███████████▏                             |  ETA: 0:24:36\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 190000: 22.54499005511397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  28%|███████████▋                             |  ETA: 0:23:49\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 200000 saved to ./RL_models_fast/vtol_2D_ppo_200000.bson\n",
      "test reward at step 200000: 38.48793099336862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  30%|████████████▎                            |  ETA: 0:23:03\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 210000 saved to ./RL_models_fast/vtol_2D_ppo_210000.bson\n",
      "test reward at step 210000: 37.73443529434072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  31%|████████████▉                            |  ETA: 0:22:26\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 220000 saved to ./RL_models_fast/vtol_2D_ppo_220000.bson\n",
      "test reward at step 220000: 38.74955458293727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  33%|█████████████▍                           |  ETA: 0:21:48\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 230000 saved to ./RL_models_fast/vtol_2D_ppo_230000.bson\n",
      "test reward at step 230000: 37.46743785806359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  34%|██████████████                           |  ETA: 0:21:07\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 240000 saved to ./RL_models_fast/vtol_2D_ppo_240000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:  34%|██████████████                           |  ETA: 0:21:20\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 240000: 38.590005767492315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  36%|██████████████▋                          |  ETA: 0:20:32\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 250000 saved to ./RL_models_fast/vtol_2D_ppo_250000.bson\n",
      "test reward at step 250000: 38.749702360939686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  37%|███████████████▎                         |  ETA: 0:19:51\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 260000 saved to ./RL_models_fast/vtol_2D_ppo_260000.bson\n",
      "test reward at step 260000: 37.22822632110395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  39%|███████████████▊                         |  ETA: 0:19:10\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 270000 saved to ./RL_models_fast/vtol_2D_ppo_270000.bson\n",
      "test reward at step 270000: 39.25748745554385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  40%|████████████████▍                        |  ETA: 0:18:39\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 280000 saved to ./RL_models_fast/vtol_2D_ppo_280000.bson\n",
      "test reward at step 280000: 37.95836863855193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  41%|█████████████████                        |  ETA: 0:17:57\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 290000 saved to ./RL_models_fast/vtol_2D_ppo_290000.bson\n",
      "test reward at step 290000: 37.953470347439385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  43%|█████████████████▌                       |  ETA: 0:17:27\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 300000 saved to ./RL_models_fast/vtol_2D_ppo_300000.bson\n",
      "test reward at step 300000: 38.10156805503924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  44%|██████████████████                       |  ETA: 0:16:58\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 310000 saved to ./RL_models_fast/vtol_2D_ppo_310000.bson\n",
      "test reward at step 310000: 39.3691597453529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  46%|██████████████████▊                      |  ETA: 0:16:19\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 320000 saved to ./RL_models_fast/vtol_2D_ppo_320000.bson\n",
      "test reward at step 320000: 37.61605763485946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  47%|███████████████████▎                     |  ETA: 0:15:48\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 330000 saved to ./RL_models_fast/vtol_2D_ppo_330000.bson\n",
      "test reward at step 330000: 38.33889773931252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  48%|███████████████████▊                     |  ETA: 0:15:27\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 340000 saved to ./RL_models_fast/vtol_2D_ppo_340000.bson\n",
      "test reward at step 340000: 38.3385756225895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  50%|████████████████████▌                    |  ETA: 0:14:54\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 350000 saved to ./RL_models_fast/vtol_2D_ppo_350000.bson\n",
      "test reward at step 350000: 38.23153997746427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  51%|█████████████████████                    |  ETA: 0:14:26\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 360000 saved to ./RL_models_fast/vtol_2D_ppo_360000.bson\n",
      "test reward at step 360000: 38.37739591384558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  53%|█████████████████████▋                   |  ETA: 0:14:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 370000 saved to ./RL_models_fast/vtol_2D_ppo_370000.bson\n",
      "test reward at step 370000: 37.360506430784206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  54%|██████████████████████▎                  |  ETA: 0:13:30\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 380000 saved to ./RL_models_fast/vtol_2D_ppo_380000.bson\n",
      "test reward at step 380000: 37.79735402489209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  56%|██████████████████████▊                  |  ETA: 0:13:05\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 390000 saved to ./RL_models_fast/vtol_2D_ppo_390000.bson\n",
      "test reward at step 390000: 39.08337232991798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  57%|███████████████████████▍                 |  ETA: 0:12:37\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 400000 saved to ./RL_models_fast/vtol_2D_ppo_400000.bson\n",
      "test reward at step 400000: 39.89803744264521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  59%|████████████████████████                 |  ETA: 0:12:08\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 410000 saved to ./RL_models_fast/vtol_2D_ppo_410000.bson\n",
      "test reward at step 410000: 38.18619009137491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  60%|████████████████████████▌                |  ETA: 0:11:43\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 420000 saved to ./RL_models_fast/vtol_2D_ppo_420000.bson\n",
      "test reward at step 420000: 37.97132154617209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  61%|█████████████████████████▏               |  ETA: 0:11:13\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 430000 saved to ./RL_models_fast/vtol_2D_ppo_430000.bson\n",
      "test reward at step 430000: 34.493107344407704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  63%|█████████████████████████▊               |  ETA: 0:10:47\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 440000 saved to ./RL_models_fast/vtol_2D_ppo_440000.bson\n",
      "test reward at step 440000: 38.15685814013172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  64%|██████████████████████████▍              |  ETA: 0:10:20\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 450000 saved to ./RL_models_fast/vtol_2D_ppo_450000.bson\n",
      "test reward at step 450000: 37.804852715874276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  66%|██████████████████████████▉              |  ETA: 0:09:54\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 460000 saved to ./RL_models_fast/vtol_2D_ppo_460000.bson\n",
      "test reward at step 460000: 37.006382713911954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  67%|███████████████████████████▌             |  ETA: 0:09:24\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 470000 saved to ./RL_models_fast/vtol_2D_ppo_470000.bson\n",
      "test reward at step 470000: 38.01485181302518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  69%|████████████████████████████▏            |  ETA: 0:08:57\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 480000 saved to ./RL_models_fast/vtol_2D_ppo_480000.bson\n",
      "test reward at step 480000: 38.001638249619404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  70%|████████████████████████████▋            |  ETA: 0:08:30\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 490000 saved to ./RL_models_fast/vtol_2D_ppo_490000.bson\n",
      "test reward at step 490000: 36.8763642788502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  71%|█████████████████████████████▎           |  ETA: 0:08:06\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 500000 saved to ./RL_models_fast/vtol_2D_ppo_500000.bson\n",
      "test reward at step 500000: 37.49807936772541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  73%|█████████████████████████████▉           |  ETA: 0:07:37\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 510000 saved to ./RL_models_fast/vtol_2D_ppo_510000.bson\n",
      "test reward at step 510000: 39.22835529352462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  74%|██████████████████████████████▍          |  ETA: 0:07:13\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 520000 saved to ./RL_models_fast/vtol_2D_ppo_520000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:  74%|██████████████████████████████▌          |  ETA: 0:07:14\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 520000: 38.68956548607115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  76%|███████████████████████████████          |  ETA: 0:06:48\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 530000 saved to ./RL_models_fast/vtol_2D_ppo_530000.bson\n",
      "test reward at step 530000: 36.533952400962065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  77%|███████████████████████████████▋         |  ETA: 0:06:21\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 540000 saved to ./RL_models_fast/vtol_2D_ppo_540000.bson\n",
      "test reward at step 540000: 38.05743826844586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  78%|████████████████████████████████▏        |  ETA: 0:06:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 550000 saved to ./RL_models_fast/vtol_2D_ppo_550000.bson\n",
      "test reward at step 550000: 37.41600879414901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  80%|████████████████████████████████▊        |  ETA: 0:05:31\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 560000 saved to ./RL_models_fast/vtol_2D_ppo_560000.bson\n",
      "test reward at step 560000: 37.91648455789537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  81%|█████████████████████████████████▎       |  ETA: 0:05:09\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 570000 saved to ./RL_models_fast/vtol_2D_ppo_570000.bson\n",
      "test reward at step 570000: 38.836546056457195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  83%|█████████████████████████████████▉       |  ETA: 0:04:44\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 580000 saved to ./RL_models_fast/vtol_2D_ppo_580000.bson\n",
      "test reward at step 580000: 39.461351071972274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  84%|██████████████████████████████████▌      |  ETA: 0:04:16\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 590000 saved to ./RL_models_fast/vtol_2D_ppo_590000.bson\n",
      "test reward at step 590000: 38.67231825889293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  85%|███████████████████████████████████      |  ETA: 0:03:56\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 600000 saved to ./RL_models_fast/vtol_2D_ppo_600000.bson\n",
      "test reward at step 600000: 39.276751253554586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  87%|███████████████████████████████████▋     |  ETA: 0:03:30\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 610000 saved to ./RL_models_fast/vtol_2D_ppo_610000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:  87%|███████████████████████████████████▊     |  ETA: 0:03:29\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 610000: 32.5937372906753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  88%|████████████████████████████████████▎    |  ETA: 0:03:06\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 620000 saved to ./RL_models_fast/vtol_2D_ppo_620000.bson\n",
      "test reward at step 620000: 38.83472815156048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  90%|████████████████████████████████████▉    |  ETA: 0:02:42\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 630000 saved to ./RL_models_fast/vtol_2D_ppo_630000.bson\n",
      "test reward at step 630000: 38.44602768596884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  91%|█████████████████████████████████████▌   |  ETA: 0:02:18\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 640000 saved to ./RL_models_fast/vtol_2D_ppo_640000.bson\n",
      "test reward at step 640000: 16.289366012564678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  93%|██████████████████████████████████████   |  ETA: 0:01:58\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 650000 saved to ./RL_models_fast/vtol_2D_ppo_650000.bson\n",
      "test reward at step 650000: 38.76333745339752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  94%|██████████████████████████████████████▋  |  ETA: 0:01:34\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 660000 saved to ./RL_models_fast/vtol_2D_ppo_660000.bson\n",
      "test reward at step 660000: 14.280307103405827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  96%|███████████████████████████████████████▎ |  ETA: 0:01:09\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 670000 saved to ./RL_models_fast/vtol_2D_ppo_670000.bson\n",
      "test reward at step 670000: 38.24089548598353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  97%|███████████████████████████████████████▉ |  ETA: 0:00:46\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 680000 saved to ./RL_models_fast/vtol_2D_ppo_680000.bson\n",
      "test reward at step 680000: 29.916767688185747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  98%|████████████████████████████████████████▎|  ETA: 0:00:27\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 690000 saved to ./RL_models_fast/vtol_2D_ppo_690000.bson\n",
      "test reward at step 690000: 38.819067696495544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:26:17\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 700000 saved to ./RL_models_fast/vtol_2D_ppo_700000.bson\n",
      "test reward at step 700000: 36.67995595418623\n"
     ]
    }
   ],
   "source": [
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(700_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=10_000), \n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49a302a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip540\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip540)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip541\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip540)\" d=\"\n",
       "M141.853 1486.45 L2352.76 1486.45 L2352.76 47.2441 L141.853 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip542\">\n",
       "    <rect x=\"141\" y=\"47\" width=\"2212\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.197,1486.45 174.197,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  778.765,1486.45 778.765,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1383.33,1486.45 1383.33,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1987.9,1486.45 1987.9,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.197,1486.45 174.197,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  778.765,1486.45 778.765,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1383.33,1486.45 1383.33,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.9,1486.45 1987.9,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip540)\" d=\"M174.197 1517.37 Q170.586 1517.37 168.758 1520.93 Q166.952 1524.47 166.952 1531.6 Q166.952 1538.71 168.758 1542.27 Q170.586 1545.82 174.197 1545.82 Q177.832 1545.82 179.637 1542.27 Q181.466 1538.71 181.466 1531.6 Q181.466 1524.47 179.637 1520.93 Q177.832 1517.37 174.197 1517.37 M174.197 1513.66 Q180.007 1513.66 183.063 1518.27 Q186.142 1522.85 186.142 1531.6 Q186.142 1540.33 183.063 1544.94 Q180.007 1549.52 174.197 1549.52 Q168.387 1549.52 165.308 1544.94 Q162.253 1540.33 162.253 1531.6 Q162.253 1522.85 165.308 1518.27 Q168.387 1513.66 174.197 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M757.538 1544.91 L773.857 1544.91 L773.857 1548.85 L751.913 1548.85 L751.913 1544.91 Q754.575 1542.16 759.158 1537.53 Q763.765 1532.88 764.945 1531.53 Q767.191 1529.01 768.07 1527.27 Q768.973 1525.51 768.973 1523.82 Q768.973 1521.07 767.029 1519.33 Q765.107 1517.6 762.006 1517.6 Q759.806 1517.6 757.353 1518.36 Q754.922 1519.13 752.144 1520.68 L752.144 1515.95 Q754.969 1514.82 757.422 1514.24 Q759.876 1513.66 761.913 1513.66 Q767.283 1513.66 770.478 1516.35 Q773.672 1519.03 773.672 1523.52 Q773.672 1525.65 772.862 1527.57 Q772.075 1529.47 769.968 1532.07 Q769.39 1532.74 766.288 1535.95 Q763.186 1539.15 757.538 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M793.672 1517.37 Q790.061 1517.37 788.232 1520.93 Q786.427 1524.47 786.427 1531.6 Q786.427 1538.71 788.232 1542.27 Q790.061 1545.82 793.672 1545.82 Q797.306 1545.82 799.112 1542.27 Q800.941 1538.71 800.941 1531.6 Q800.941 1524.47 799.112 1520.93 Q797.306 1517.37 793.672 1517.37 M793.672 1513.66 Q799.482 1513.66 802.538 1518.27 Q805.616 1522.85 805.616 1531.6 Q805.616 1540.33 802.538 1544.94 Q799.482 1549.52 793.672 1549.52 Q787.862 1549.52 784.783 1544.94 Q781.728 1540.33 781.728 1531.6 Q781.728 1522.85 784.783 1518.27 Q787.862 1513.66 793.672 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M1371.5 1518.36 L1359.7 1536.81 L1371.5 1536.81 L1371.5 1518.36 M1370.28 1514.29 L1376.16 1514.29 L1376.16 1536.81 L1381.09 1536.81 L1381.09 1540.7 L1376.16 1540.7 L1376.16 1548.85 L1371.5 1548.85 L1371.5 1540.7 L1355.9 1540.7 L1355.9 1536.19 L1370.28 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M1398.82 1517.37 Q1395.21 1517.37 1393.38 1520.93 Q1391.57 1524.47 1391.57 1531.6 Q1391.57 1538.71 1393.38 1542.27 Q1395.21 1545.82 1398.82 1545.82 Q1402.45 1545.82 1404.26 1542.27 Q1406.09 1538.71 1406.09 1531.6 Q1406.09 1524.47 1404.26 1520.93 Q1402.45 1517.37 1398.82 1517.37 M1398.82 1513.66 Q1404.63 1513.66 1407.68 1518.27 Q1410.76 1522.85 1410.76 1531.6 Q1410.76 1540.33 1407.68 1544.94 Q1404.63 1549.52 1398.82 1549.52 Q1393.01 1549.52 1389.93 1544.94 Q1386.87 1540.33 1386.87 1531.6 Q1386.87 1522.85 1389.93 1518.27 Q1393.01 1513.66 1398.82 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M1973.3 1529.7 Q1970.16 1529.7 1968.3 1531.86 Q1966.48 1534.01 1966.48 1537.76 Q1966.48 1541.49 1968.3 1543.66 Q1970.16 1545.82 1973.3 1545.82 Q1976.45 1545.82 1978.28 1543.66 Q1980.13 1541.49 1980.13 1537.76 Q1980.13 1534.01 1978.28 1531.86 Q1976.45 1529.7 1973.3 1529.7 M1982.59 1515.05 L1982.59 1519.31 Q1980.83 1518.48 1979.02 1518.04 Q1977.24 1517.6 1975.48 1517.6 Q1970.85 1517.6 1968.4 1520.72 Q1965.97 1523.85 1965.62 1530.17 Q1966.99 1528.15 1969.05 1527.09 Q1971.11 1526 1973.58 1526 Q1978.79 1526 1981.8 1529.17 Q1984.83 1532.32 1984.83 1537.76 Q1984.83 1543.08 1981.68 1546.3 Q1978.54 1549.52 1973.3 1549.52 Q1967.31 1549.52 1964.14 1544.94 Q1960.97 1540.33 1960.97 1531.6 Q1960.97 1523.41 1964.86 1518.55 Q1968.74 1513.66 1975.3 1513.66 Q1977.05 1513.66 1978.84 1514.01 Q1980.64 1514.36 1982.59 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M2002.89 1517.37 Q1999.28 1517.37 1997.45 1520.93 Q1995.64 1524.47 1995.64 1531.6 Q1995.64 1538.71 1997.45 1542.27 Q1999.28 1545.82 2002.89 1545.82 Q2006.52 1545.82 2008.33 1542.27 Q2010.16 1538.71 2010.16 1531.6 Q2010.16 1524.47 2008.33 1520.93 Q2006.52 1517.37 2002.89 1517.37 M2002.89 1513.66 Q2008.7 1513.66 2011.75 1518.27 Q2014.83 1522.85 2014.83 1531.6 Q2014.83 1540.33 2011.75 1544.94 Q2008.7 1549.52 2002.89 1549.52 Q1997.08 1549.52 1994 1544.94 Q1990.94 1540.33 1990.94 1531.6 Q1990.94 1522.85 1994 1518.27 Q1997.08 1513.66 2002.89 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,1379.93 2352.76,1379.93 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,1148.68 2352.76,1148.68 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,917.427 2352.76,917.427 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,686.178 2352.76,686.178 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,454.929 2352.76,454.929 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip542)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,223.68 2352.76,223.68 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1486.45 141.853,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1379.93 160.751,1379.93 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1148.68 160.751,1148.68 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,917.427 160.751,917.427 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,686.178 160.751,686.178 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,454.929 160.751,454.929 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,223.68 160.751,223.68 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip540)\" d=\"M55.5523 1393.27 L63.1911 1393.27 L63.1911 1366.9 L54.881 1368.57 L54.881 1364.31 L63.1448 1362.65 L67.8207 1362.65 L67.8207 1393.27 L75.4596 1393.27 L75.4596 1397.21 L55.5523 1397.21 L55.5523 1393.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M84.9503 1362.65 L103.307 1362.65 L103.307 1366.58 L89.2327 1366.58 L89.2327 1375.05 Q90.2512 1374.71 91.2697 1374.54 Q92.2882 1374.36 93.3067 1374.36 Q99.0937 1374.36 102.473 1377.53 Q105.853 1380.7 105.853 1386.12 Q105.853 1391.7 102.381 1394.8 Q98.9085 1397.88 92.5891 1397.88 Q90.4132 1397.88 88.1447 1397.51 Q85.8993 1397.14 83.492 1396.4 L83.492 1391.7 Q85.5753 1392.83 87.7975 1393.39 Q90.0197 1393.94 92.4965 1393.94 Q96.5011 1393.94 98.8391 1391.84 Q101.177 1389.73 101.177 1386.12 Q101.177 1382.51 98.8391 1380.4 Q96.5011 1378.29 92.4965 1378.29 Q90.6215 1378.29 88.7466 1378.71 Q86.8947 1379.13 84.9503 1380.01 L84.9503 1362.65 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M57.7745 1162.02 L74.0939 1162.02 L74.0939 1165.96 L52.1495 1165.96 L52.1495 1162.02 Q54.8115 1159.27 59.3949 1154.64 Q64.0013 1149.98 65.1819 1148.64 Q67.4272 1146.12 68.3068 1144.38 Q69.2096 1142.62 69.2096 1140.93 Q69.2096 1138.18 67.2652 1136.44 Q65.3439 1134.71 62.2421 1134.71 Q60.043 1134.71 57.5893 1135.47 Q55.1588 1136.23 52.381 1137.79 L52.381 1133.06 Q55.2051 1131.93 57.6588 1131.35 Q60.1124 1130.77 62.1495 1130.77 Q67.5198 1130.77 70.7142 1133.46 Q73.9087 1136.14 73.9087 1140.63 Q73.9087 1142.76 73.0985 1144.68 Q72.3115 1146.58 70.205 1149.17 Q69.6263 1149.85 66.5245 1153.06 Q63.4226 1156.26 57.7745 1162.02 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M93.9086 1134.47 Q90.2975 1134.47 88.4688 1138.04 Q86.6632 1141.58 86.6632 1148.71 Q86.6632 1155.82 88.4688 1159.38 Q90.2975 1162.92 93.9086 1162.92 Q97.5428 1162.92 99.3483 1159.38 Q101.177 1155.82 101.177 1148.71 Q101.177 1141.58 99.3483 1138.04 Q97.5428 1134.47 93.9086 1134.47 M93.9086 1130.77 Q99.7187 1130.77 102.774 1135.38 Q105.853 1139.96 105.853 1148.71 Q105.853 1157.44 102.774 1162.04 Q99.7187 1166.63 93.9086 1166.63 Q88.0984 1166.63 85.0197 1162.04 Q81.9642 1157.44 81.9642 1148.71 Q81.9642 1139.96 85.0197 1135.38 Q88.0984 1130.77 93.9086 1130.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M58.7699 930.772 L75.0892 930.772 L75.0892 934.707 L53.1449 934.707 L53.1449 930.772 Q55.8069 928.017 60.3902 923.388 Q64.9967 918.735 66.1772 917.393 Q68.4226 914.869 69.3022 913.133 Q70.205 911.374 70.205 909.684 Q70.205 906.93 68.2606 905.193 Q66.3393 903.457 63.2374 903.457 Q61.0384 903.457 58.5847 904.221 Q56.1541 904.985 53.3764 906.536 L53.3764 901.814 Q56.2004 900.68 58.6541 900.101 Q61.1078 899.522 63.1448 899.522 Q68.5152 899.522 71.7096 902.207 Q74.904 904.893 74.904 909.383 Q74.904 911.513 74.0939 913.434 Q73.3068 915.332 71.2004 917.925 Q70.6217 918.596 67.5198 921.814 Q64.418 925.008 58.7699 930.772 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M84.9503 900.147 L103.307 900.147 L103.307 904.082 L89.2327 904.082 L89.2327 912.555 Q90.2512 912.207 91.2697 912.045 Q92.2882 911.86 93.3067 911.86 Q99.0937 911.86 102.473 915.031 Q105.853 918.203 105.853 923.619 Q105.853 929.198 102.381 932.3 Q98.9085 935.379 92.5891 935.379 Q90.4132 935.379 88.1447 935.008 Q85.8993 934.638 83.492 933.897 L83.492 929.198 Q85.5753 930.332 87.7975 930.888 Q90.0197 931.443 92.4965 931.443 Q96.5011 931.443 98.8391 929.337 Q101.177 927.23 101.177 923.619 Q101.177 920.008 98.8391 917.902 Q96.5011 915.795 92.4965 915.795 Q90.6215 915.795 88.7466 916.212 Q86.8947 916.629 84.9503 917.508 L84.9503 900.147 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M67.9133 684.824 Q71.2698 685.542 73.1448 687.81 Q75.0429 690.079 75.0429 693.412 Q75.0429 698.528 71.5244 701.329 Q68.0059 704.129 61.5245 704.129 Q59.3486 704.129 57.0338 703.69 Q54.7421 703.273 52.2884 702.417 L52.2884 697.903 Q54.2328 699.037 56.5477 699.616 Q58.8625 700.194 61.3856 700.194 Q65.7837 700.194 68.0754 698.458 Q70.3902 696.722 70.3902 693.412 Q70.3902 690.356 68.2374 688.643 Q66.1078 686.907 62.2884 686.907 L58.2606 686.907 L58.2606 683.065 L62.4735 683.065 Q65.9226 683.065 67.7513 681.699 Q69.58 680.31 69.58 677.718 Q69.58 675.056 67.6819 673.644 Q65.8069 672.208 62.2884 672.208 Q60.3671 672.208 58.168 672.625 Q55.969 673.042 53.3301 673.921 L53.3301 669.755 Q55.9921 669.014 58.3069 668.644 Q60.6449 668.273 62.705 668.273 Q68.0291 668.273 71.1309 670.704 Q74.2327 673.111 74.2327 677.231 Q74.2327 680.102 72.5892 682.093 Q70.9457 684.06 67.9133 684.824 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M93.9086 671.977 Q90.2975 671.977 88.4688 675.542 Q86.6632 679.083 86.6632 686.213 Q86.6632 693.319 88.4688 696.884 Q90.2975 700.426 93.9086 700.426 Q97.5428 700.426 99.3483 696.884 Q101.177 693.319 101.177 686.213 Q101.177 679.083 99.3483 675.542 Q97.5428 671.977 93.9086 671.977 M93.9086 668.273 Q99.7187 668.273 102.774 672.88 Q105.853 677.463 105.853 686.213 Q105.853 694.94 102.774 699.546 Q99.7187 704.129 93.9086 704.129 Q88.0984 704.129 85.0197 699.546 Q81.9642 694.94 81.9642 686.213 Q81.9642 677.463 85.0197 672.88 Q88.0984 668.273 93.9086 668.273 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M68.9087 453.575 Q72.2652 454.293 74.1402 456.561 Q76.0383 458.83 76.0383 462.163 Q76.0383 467.279 72.5198 470.079 Q69.0013 472.88 62.5198 472.88 Q60.3439 472.88 58.0291 472.441 Q55.7375 472.024 53.2838 471.167 L53.2838 466.654 Q55.2282 467.788 57.543 468.367 Q59.8578 468.945 62.381 468.945 Q66.7791 468.945 69.0707 467.209 Q71.3855 465.473 71.3855 462.163 Q71.3855 459.107 69.2328 457.394 Q67.1032 455.658 63.2837 455.658 L59.256 455.658 L59.256 451.816 L63.4689 451.816 Q66.918 451.816 68.7467 450.45 Q70.5754 449.061 70.5754 446.468 Q70.5754 443.806 68.6772 442.394 Q66.8022 440.959 63.2837 440.959 Q61.3624 440.959 59.1634 441.376 Q56.9643 441.793 54.3254 442.672 L54.3254 438.506 Q56.9875 437.765 59.3023 437.394 Q61.6402 437.024 63.7004 437.024 Q69.0244 437.024 72.1263 439.455 Q75.2281 441.862 75.2281 445.982 Q75.2281 448.853 73.5846 450.843 Q71.9411 452.811 68.9087 453.575 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M84.9503 437.649 L103.307 437.649 L103.307 441.584 L89.2327 441.584 L89.2327 450.056 Q90.2512 449.709 91.2697 449.547 Q92.2882 449.362 93.3067 449.362 Q99.0937 449.362 102.473 452.533 Q105.853 455.705 105.853 461.121 Q105.853 466.7 102.381 469.802 Q98.9085 472.88 92.5891 472.88 Q90.4132 472.88 88.1447 472.51 Q85.8993 472.14 83.492 471.399 L83.492 466.7 Q85.5753 467.834 87.7975 468.39 Q90.0197 468.945 92.4965 468.945 Q96.5011 468.945 98.8391 466.839 Q101.177 464.732 101.177 461.121 Q101.177 457.51 98.8391 455.404 Q96.5011 453.297 92.4965 453.297 Q90.6215 453.297 88.7466 453.714 Q86.8947 454.13 84.9503 455.01 L84.9503 437.649 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M66.5939 210.474 L54.7884 228.923 L66.5939 228.923 L66.5939 210.474 M65.367 206.4 L71.2466 206.4 L71.2466 228.923 L76.1772 228.923 L76.1772 232.812 L71.2466 232.812 L71.2466 240.96 L66.5939 240.96 L66.5939 232.812 L50.9921 232.812 L50.9921 228.298 L65.367 206.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M93.9086 209.479 Q90.2975 209.479 88.4688 213.044 Q86.6632 216.585 86.6632 223.715 Q86.6632 230.821 88.4688 234.386 Q90.2975 237.928 93.9086 237.928 Q97.5428 237.928 99.3483 234.386 Q101.177 230.821 101.177 223.715 Q101.177 216.585 99.3483 213.044 Q97.5428 209.479 93.9086 209.479 M93.9086 205.775 Q99.7187 205.775 102.774 210.381 Q105.853 214.965 105.853 223.715 Q105.853 232.442 102.774 237.048 Q99.7187 241.631 93.9086 241.631 Q88.0984 241.631 85.0197 237.048 Q81.9642 232.442 81.9642 223.715 Q81.9642 214.965 85.0197 210.381 Q88.0984 205.775 93.9086 205.775 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip542)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  204.426,1445.72 234.654,315.594 264.882,309.334 295.111,266.356 325.339,285.473 355.568,305.176 385.796,212.343 416.024,280.172 446.253,337.992 476.481,87.9763 \n",
       "  506.709,334.065 536.938,307.33 567.166,148.145 597.394,246.449 627.623,306.234 657.851,394.611 688.08,287.152 718.308,232.406 748.536,1030.97 778.765,293.613 \n",
       "  808.993,328.462 839.221,281.513 869.45,340.811 899.678,288.892 929.907,281.506 960.135,351.874 990.363,258.021 1020.59,318.105 1050.82,318.332 1081.05,311.482 \n",
       "  1111.28,252.856 1141.51,333.937 1171.73,300.506 1201.96,300.521 1232.19,305.471 1262.42,298.725 1292.65,345.756 1322.88,325.552 1353.1,266.074 1383.33,228.396 \n",
       "  1413.56,307.568 1443.79,317.506 1474.02,478.373 1504.25,308.925 1534.47,325.205 1564.7,362.134 1594.93,315.493 1625.16,316.104 1655.39,368.148 1685.62,339.393 \n",
       "  1715.84,259.368 1746.07,284.287 1776.3,383.984 1806.53,313.523 1836.76,343.189 1866.99,320.042 1897.21,277.49 1927.44,248.592 1957.67,285.085 1987.9,257.13 \n",
       "  2018.13,566.218 2048.36,277.574 2078.58,295.551 2108.81,1320.29 2139.04,280.875 2169.27,1413.21 2199.5,305.038 2229.73,690.028 2259.95,278.298 2290.18,377.231 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip540)\" d=\"\n",
       "M1980.97 198.898 L2279.06 198.898 L2279.06 95.2176 L1980.97 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1980.97,198.898 2279.06,198.898 2279.06,95.2176 1980.97,95.2176 1980.97,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip540)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2005.54,147.058 2152.93,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip540)\" d=\"M2191.34 166.745 Q2189.53 171.375 2187.82 172.787 Q2186.11 174.199 2183.24 174.199 L2179.84 174.199 L2179.84 170.634 L2182.34 170.634 Q2184.09 170.634 2185.07 169.8 Q2186.04 168.967 2187.22 165.865 L2187.98 163.921 L2177.5 138.412 L2182.01 138.412 L2190.11 158.689 L2198.22 138.412 L2202.73 138.412 L2191.34 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip540)\" d=\"M2210.02 160.402 L2217.66 160.402 L2217.66 134.037 L2209.35 135.703 L2209.35 131.444 L2217.61 129.778 L2222.29 129.778 L2222.29 160.402 L2229.93 160.402 L2229.93 164.338 L2210.02 164.338 L2210.02 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(episode_test_reward_hook.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb0d4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_visualization(); # closes the MeshCat visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf8ffc2",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = VtolEnv(;name = \"testVTOL\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "function loadModel(path, num)\n",
    "    f = joinpath(path, \"vtol_2D_ppo_$num.bson\") # TODO: evtl anpassen\n",
    "    @load f model\n",
    "    return model\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed379703",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validate(num_models, num_test)\n",
    "    episode_test_reward_hook = TotalRewardPerEpisode(;is_display_on_exit=false)\n",
    "    # create a env only for reward test\n",
    "    \n",
    "    for i in 1:num_models\n",
    "          \n",
    "        sum_rewards_model = 0;\n",
    "        sum_successes_model = 0;\n",
    "        sum_avg_vel_model = 0;\n",
    "        n_success = 0;\n",
    "        \n",
    "        for exp in 1:num_test\n",
    "            RLBase.reset!(test_env)\n",
    "            agent.policy.approximator = loadModel(\"./RL_models_fast/\", i*10000); # TODO: change to desired\n",
    "            run(agent.policy, test_env, StopAfterEpisode(1), episode_test_reward_hook)\n",
    "            # the result of the hook\n",
    "            sum_rewards_model += episode_test_reward_hook.rewards[end];\n",
    "            \n",
    "            if test_env.reached_goal == trues(test_env.num_waypoints)\n",
    "                n_success += 1\n",
    "                sum_avg_vel_model += test_env.norm_way / test_env.t\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        rewards[i] = sum_rewards_model / num_test;\n",
    "        success_rate[i] = n_success / num_test;\n",
    "        if n_success > 0\n",
    "            avg_velocity[i] = sum_avg_vel_model / n_success;\n",
    "        else\n",
    "            avg_velocity[i] = NaN\n",
    "        end\n",
    "        percent = percent = round(i * 100 / num_models, digits=2)\n",
    "        println(\"progress: $(percent)%\")\n",
    "        \n",
    "    end\n",
    "    \n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a98dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_model = 70\n",
    "num_test = 100\n",
    "\n",
    "rewards = zeros(num_models,1);\n",
    "success_rate = zeros(num_models,1);\n",
    "avg_velocity = zeros(num_models,1);\n",
    "\n",
    "validate(num_model, num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([1:num_model] * 10000, rewards, xlabel=\"Iterations\", ylabel=\"Reward\", legend = false, xformatter = :scientific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([1:num_model] * 10000, success_rate, xlabel=\"Iterations\", ylabel=\"Success Rate\", legend = false, xformatter = :scientific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([1:num_model] * 10000, avg_velocity, xlabel=\"Iterations\", ylabel=\"Average Velocity\", legend = false, xformatter = :scientific)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
