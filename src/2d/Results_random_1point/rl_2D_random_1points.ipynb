{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649b76a",
   "metadata": {},
   "source": [
    "# Init Bionic VTOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96751412",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position\n",
    "\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;\n",
    "using Distributions;\n",
    "\n",
    "using Plots;\n",
    "using Statistics;\n",
    "\n",
    "using BSON: @save, @load # save mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e4ee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: MeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "│ http://127.0.0.1:8702\n",
      "└ @ MeshCat /home/larissa/.julia/packages/MeshCat/Ax8pH/src/visualizer.jl:73\n"
     ]
    }
   ],
   "source": [
    "create_visualization();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9557df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indicates how many threads Julia was started with. This is important for the multi-threaded environment\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea451ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eth_vtol_param[\"gravity\"] = 9.81; # set gravity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411db62",
   "metadata": {},
   "source": [
    "# Create Reinforcement Learning Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96af6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv # Parametric Constructor for a subtype of AbstractEnv\n",
    "    action_space::A # action space\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}} # observation space\n",
    "    state::Vector{T} # current state space\n",
    "    action::ACT # action space\n",
    "    done::Bool # done\n",
    "    t::T # time\n",
    "    rng::R # random number generator\n",
    "\n",
    "    name::String # for multible environoments\n",
    "    visualization::Bool # visualization\n",
    "    realtime::Bool # realtime\n",
    "    \n",
    "    # Everything you need aditionaly can also go in here.\n",
    "    x_W::Vector{T} # current position\n",
    "    v_B::Vector{T} # velocity\n",
    "    R_W::Matrix{T} # current rotation\n",
    "    ω_B::Vector{T} # rotation velocitiy\n",
    "    wind_W::Vector{T} # wind\n",
    "    Δt::T # Δ time\n",
    "    \n",
    "    # Current Bonus / Target\n",
    "    num_waypoints::Int # includig start point\n",
    "    waypoints::Vector{Vector{T}}\n",
    "    reached_goal::BitVector\n",
    "    \n",
    "    progress::T\n",
    "    progress_prev::T\n",
    "    current_point::Int\n",
    "    reached_goal_in_step::Bool\n",
    "    \n",
    "    r_tol::T\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a6873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a keyword-based constructor for the type declared in the mutable struct typedef. \n",
    "# It could also be done with the macro Base.@kwdef.\n",
    "function VtolEnv(;\n",
    "    rng = Random.GLOBAL_RNG, # Random number generation\n",
    "    name = \"vtol\",\n",
    "    visualization = false,\n",
    "    realtime = false,\n",
    "    kwargs... # let the function take an arbitrary number of keyword arguments \n",
    ")\n",
    "    \n",
    "    T = Float64; # explicit type which is used e.g. in state. Cannot be altered due to the poor matrix defininon.\n",
    "\n",
    "    \n",
    "    action_space = Space(\n",
    "        ClosedInterval{T}[\n",
    "            0.0..2.0, # propeller 1\n",
    "            0.0..2.0, # propeller 2\n",
    "            ], \n",
    "    )\n",
    "\n",
    "    \n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            # orientate yourself on the state space from the paper\n",
    "            typemin(T)..typemax(T), # position along x\n",
    "            typemin(T)..typemax(T), # position along z\n",
    "            \n",
    "            typemin(T)..typemax(T), # orientation along x\n",
    "            typemin(T)..typemax(T), # orientation along z\n",
    "            \n",
    "            typemin(T)..typemax(T), # velocity along x BODY coordinates\n",
    "            typemin(T)..typemax(T), # velocity along y BODY coordinates\n",
    "            \n",
    "            typemin(T)..typemax(T), # rotational velocity along z BODY coordinates\n",
    "            \n",
    "            typemin(T)..typemax(T), # position error along x\n",
    "            typemin(T)..typemax(T), # position error along z\n",
    "            # TODO: nore points?\n",
    "            ], \n",
    "    )\n",
    "    \n",
    "    num_waypoints = 2 # number of waypoints, includig start point\n",
    "    waypoints = generate_trajectory(num_waypoints) # trajectory with num_waypoints waypoints (+ start point) \n",
    "    reached_goal = falses(num_waypoints)\n",
    "    \n",
    "    if visualization #visualizes VTOL and waypoints\n",
    "        create_VTOL(name, actuators = true, color_vec=[1.0; 1.0; 0.6; 1.0]);\n",
    "        visualize_waypoints(waypoints, 0.15)\n",
    "    end\n",
    "\n",
    "    environment = VtolEnv(\n",
    "        action_space,\n",
    "        state_space, \n",
    "        zeros(T, length(state_space)), # current state, needs to be extended\n",
    "        rand(action_space), #initialization action\n",
    "        false, # episode done \n",
    "        0.0, # time\n",
    "        rng, # random number generator  \n",
    "        \n",
    "        name,\n",
    "        visualization,\n",
    "        realtime,\n",
    "        \n",
    "        zeros(T, 3), # x_W, current position\n",
    "        zeros(T, 3), # v_B, velocity\n",
    "        [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0], # R_W, current rotation, Float64... so T needs to be Float64\n",
    "        zeros(T, 3), # ω_B\n",
    "        zeros(T, 3), # wind_W\n",
    "        T(0.025), # Δt \n",
    "        \n",
    "        num_waypoints, # includig start point\n",
    "        waypoints, \n",
    "        reached_goal,\n",
    "        \n",
    "        0.0, # progress\n",
    "        0.0, # progress_prev\n",
    "        2, # current point\n",
    "        false, # reached_goal_in_step\n",
    "        \n",
    "        0.5 # r_tol\n",
    "    )\n",
    "    \n",
    "    \n",
    "    reset!(environment)\n",
    "    \n",
    "    return environment\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec660d5e",
   "metadata": {},
   "source": [
    "Just for explanation:\n",
    "\n",
    "1. A mutable Struct is created. A struct is a constructor and a constructor is a function that creates new objects.\n",
    "2. A outer keyword-based constructor method is added for the type declared in the mutable struct typedef before.\n",
    "\n",
    "So now we have a function with two methods. Julia will decide which method to call by multiple dispatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3c4bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "# 2 methods for type constructor:<ul><li> VtolEnv(; <i>rng, name, visualization, realtime, kwargs...</i>) in Main at In[6]:3</li> <li> VtolEnv(action_space::<b>A</b>, observation_space::<b>Space{Array{ClosedInterval{T}, 1}}</b>, state::<b>Vector{T}</b>, action::<b>ACT</b>, done::<b>Bool</b>, t::<b>T</b>, rng::<b>R</b>, name::<b>String</b>, visualization::<b>Bool</b>, realtime::<b>Bool</b>, x_W::<b>Vector{T}</b>, v_B::<b>Vector{T}</b>, R_W::<b>Matrix{T}</b>, ω_B::<b>Vector{T}</b>, wind_W::<b>Vector{T}</b>, Δt::<b>T</b>, num_waypoints::<b>Int64</b>, waypoints::<b>Array{Vector{T}, 1}</b>, reached_goal::<b>BitVector</b>, progress::<b>T</b>, progress_prev::<b>T</b>, current_point::<b>Int64</b>, reached_goal_in_step::<b>Bool</b>, r_tol::<b>T</b>)<i> where {A, T, ACT, R<:AbstractRNG}</i> in Main at In[5]:2</li> </ul>"
      ],
      "text/plain": [
       "# 2 methods for type constructor:\n",
       "[1] VtolEnv(; rng, name, visualization, realtime, kwargs...) in Main at In[6]:3\n",
       "[2] VtolEnv(action_space::A, observation_space::Space{Array{ClosedInterval{T}, 1}}, state::Vector{T}, action::ACT, done::Bool, t::T, rng::R, name::String, visualization::Bool, realtime::Bool, x_W::Vector{T}, v_B::Vector{T}, R_W::Matrix{T}, ω_B::Vector{T}, wind_W::Vector{T}, Δt::T, num_waypoints::Int64, waypoints::Array{Vector{T}, 1}, reached_goal::BitVector, progress::T, progress_prev::T, current_point::Int64, reached_goal_in_step::Bool, r_tol::T) where {A, T, ACT, R<:AbstractRNG} in Main at In[5]:2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(VtolEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806413d1",
   "metadata": {},
   "source": [
    "# Define the RL interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f822029",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7fb89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function computeReward(env::VtolEnv{A,T}) where {A,T}\n",
    "    \n",
    "    k_wp = 5.0 # factor for reached gate reward\n",
    "    r_wp = 0.0 # reward for reached gate, TODO: change to gates later (when gates != waypoints)\n",
    "    if env.reached_goal_in_step\n",
    "        r_wp = exp(-norm(env.x_W - env.waypoints[env.current_point - 1])/env.r_tol)\n",
    "    end\n",
    "    \n",
    "    k_ω = 0.01 # factor for too high body rate\n",
    "    norm_ω = norm(env.ω_B[3]) # reward for body rate (penalty)\n",
    "\n",
    "    k_s = 0.0 #5.0 # factor for reached distance (overall) reward, TODO later add factor as in paper (p. 4)\n",
    "    r_s = env.progress # reward for reached distance (overall)\n",
    "    \n",
    "    \n",
    "    \n",
    "    k_p = 5.0 # factor for progress (between current position and last position) reward \n",
    "    r_p = env.progress - env.progress_prev # reward for progress (between current position and last position)\n",
    "\n",
    "    return k_p * r_p + k_s * k_s + k_wp * r_wp - k_ω * norm_ω\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = computeReward(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae45ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    # Visualize initial state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, [0.0; 0.0; 0.0; 0.0]);\n",
    "    end\n",
    "    \n",
    "    env.x_W = [0.0; 0.0; 0.0];\n",
    "    env.v_B = [0.0; 0.0; 0.0];\n",
    "    env.R_W = Matrix(UnitQuaternion(RotZ(-pi/2.0)*RotY(-pi/2.0)*RotX(pi)));\n",
    "\n",
    "    env.ω_B = [0.0; 0.0; 0.0];\n",
    "    env.wind_W = [0.0; 0.0; 0.0];\n",
    "    \n",
    "    env.num_waypoints = 2; # includig start point\n",
    "    env.waypoints = generate_trajectory(env.num_waypoints);\n",
    "    env.reached_goal = falses(env.num_waypoints);\n",
    "    env.reached_goal[1] = true; # set first point to reached (start point)\n",
    "    \n",
    "    env.current_point = 2;\n",
    "    env.reached_goal_in_step = false;\n",
    "    env.r_tol = 0.5;\n",
    "    \n",
    "    if env.visualization\n",
    "        visualize_waypoints(env.waypoints, 0.15); # debug: other radius?\n",
    "    end\n",
    "    \n",
    "\n",
    "    env.progress = 0.0;\n",
    "    env.progress_prev = 0.0;\n",
    "    \n",
    "    norm_dir = 1# norm(env.waypoints[2] - env.x_W)\n",
    "    \n",
    "    env.state = [env.x_W[1]; # position along x\n",
    "                 env.x_W[3]; # position along z\n",
    "        \n",
    "                 env.R_W[1,1]; # orientation along x\n",
    "                 env.R_W[3,1]; # orientation along z\n",
    "        \n",
    "                 env.v_B[1]; # velocity along x BODY coordinates\n",
    "                 env.v_B[2]; # velocity along y BODY coordinates  \n",
    "        \n",
    "                 env.ω_B[3]; # rotational velocity along z BODY coordinates\n",
    "        \n",
    "                 (env.waypoints[2][1] - env.x_W[1]) / norm_dir; # position error along x\n",
    "                 (env.waypoints[2][3] - env.x_W[3]) / norm_dir] # position error along z\n",
    "    \n",
    "    env.t = 0.0;\n",
    "    env.action = [0.0, 0.0];\n",
    "    env.done = false;\n",
    "    \n",
    "    nothing\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf1a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a methods for a callable object.\n",
    "# So when a VtolEnv object is created, it has this method that can be called\n",
    "function (env::VtolEnv)(a)\n",
    "    # TODO: set flaps later in 3D\n",
    "    # set the propeller trust and the two flaps 2D case\n",
    "    next_action = [a[1], a[2], 0.0, 0.0]\n",
    "   \n",
    "    _step!(env, next_action)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e9eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VtolEnv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a116cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "# 3 methods for callable object:<ul><li> (env::<b>VtolEnv</b>)(a) in Main at In[11]:3</li> <li> (env::<b>AbstractEnv</b>)(action) in ReinforcementLearningBase</li> <li> (env::<b>AbstractEnv</b>)(action, player) in ReinforcementLearningBase</li> </ul>"
      ],
      "text/plain": [
       "# 3 methods for callable object:\n",
       "[1] (env::VtolEnv)(a) in Main at In[11]:3\n",
       "[2] (env::AbstractEnv)(action) in ReinforcementLearningBase\n",
       "[3] (env::AbstractEnv)(action, player) in ReinforcementLearningBase"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(env) # Just to explain which methods the object has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7d4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "function _step!(env::VtolEnv, next_action)\n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(env.v_B, env.R_W, env.wind_W)\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = vtol_model(v_in_wind_B, next_action, eth_vtol_param);\n",
    "    # Limit to 2D\n",
    "    force_B[3] = 0.0; # Body Z\n",
    "    env.v_B[3] = 0.0;\n",
    "    torque_B[1] = 0.0; torque_B[2] = 0.0;  # Body X and Y\n",
    "    env.ω_B[1] = 0.0; env.ω_B[2] = 0.0;\n",
    "    # integrate rigid body dynamics for Δt\n",
    "    env.x_W, env.v_B, env.R_W, env.ω_B, time = rigid_body_simple(torque_B, force_B, env.x_W, env.v_B, env.R_W, env.ω_B, env.t, env.Δt, eth_vtol_param)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    env.reached_goal_in_step = false;\n",
    "    if norm(env.x_W - env.waypoints[env.current_point]) < env.r_tol\n",
    "        env.reached_goal_in_step = true;\n",
    "        env.reached_goal[env.current_point] = true;\n",
    "        env.current_point += 1;\n",
    "    end\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # calculate progress on trajectory\n",
    "    env.progress_prev = env.progress\n",
    "    \n",
    "    current_progress = 0.0\n",
    "    line_segment, progress = calculate_progress(env.waypoints, env.x_W)\n",
    "    for i in 2:(line_segment)\n",
    "       current_progress +=  norm(env.waypoints[i] - env.waypoints[i - 1])  \n",
    "    end\n",
    "    current_progress += norm(env.waypoints[line_segment] - progress)\n",
    "    \n",
    "    env.progress = current_progress\n",
    "    \n",
    "    \n",
    "\n",
    "    if env.realtime\n",
    "        sleep(env.Δt) # TODO: just a dirty hack. this is of course slower than real time.\n",
    "    end\n",
    "\n",
    "    # Visualize the new state \n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, next_action)\n",
    "        \n",
    "        for i in eachindex(env.reached_goal)\n",
    "            if env.reached_goal[i]\n",
    "                create_sphere(\"fixgoal_$i\", 0.2, color=RGBA{Float32}(1.0, 0.0, 0.0, 1.0));\n",
    "                set_transform(\"fixgoal_$i\", env.waypoints[i]);\n",
    "            end\n",
    "        end\n",
    "    end\n",
    " \n",
    "    env.t += env.Δt\n",
    "\n",
    "    \n",
    "    \n",
    "    env.state[1] = env.x_W[1]; # position along x\n",
    "    env.state[2] = env.x_W[3]; # position along z\n",
    "    \n",
    "    env.state[3] = env.R_W[1,1]; # orientation along x\n",
    "    env.state[4] = env.R_W[3,1]; # orientation along z\n",
    "    \n",
    "    env.state[5] = env.v_B[1]; # velocity along x BODY coordinates\n",
    "    env.state[6] = env.v_B[2]; # velocity along y BODY coordinates\n",
    "    \n",
    "    env.state[7] = env.ω_B[3];  # rotational velocity along z BODY coordinates\n",
    "    \n",
    "    \n",
    "    if env.current_point <= env.num_waypoints\n",
    "        norm_dir = 1 #norm(env.waypoints[env.current_point] - env.x_W)\n",
    "        env.state[8] = (env.waypoints[env.current_point][1] - env.x_W[1]) / norm_dir; # position error along x\n",
    "        env.state[9] = (env.waypoints[env.current_point][3] - env.x_W[3]) / norm_dir; # position error along z\n",
    "    else\n",
    "        env.state[8] = 0.0; # position error along x\n",
    "        env.state[9] = 0.0; # position error along z\n",
    "    end\n",
    "        \n",
    "    \n",
    "    # Termination criteria\n",
    "    # TODO: Use many termination criteria so that you do not train unnecessarily in wrong areas\n",
    "    env.done = #true\n",
    "        # After time... How fast is drone+Range of desired point\n",
    "        # After reaching position (circle of r_tol)\n",
    "        norm(env.ω_B) > 100.0 || \n",
    "        norm(env.v_B) > 100.0 || # stop if body is too fast # TODO: set higher later in fast training phase\n",
    "        env.x_W[3] < -5.0 || # stop if body is below -5m\n",
    "        env.t > env.num_waypoints * 5.0 ||# stop after 5s per point\n",
    "        norm(env.x_W - progress) > 2.0 || # too far off the path\n",
    "        env.current_point > env.num_waypoints # all points reached\n",
    "    nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e1cd988",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:              | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "random policy with VtolEnv | \u001b[32m2000  \u001b[39m\u001b[36m 2000  \u001b[39m\u001b[0m2.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"random policy with VtolEnv\", Any[], 2000, false, false, true, 1.67034805099378e9, 1.670348053672271e9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RLBase.test_runnable!(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223a31f",
   "metadata": {},
   "source": [
    "Show an overview of the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6de74",
   "metadata": {},
   "source": [
    "# Setup of a reinforcement learning experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5683fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "MultiThreadEnv(8 x VtolEnv)"
      ],
      "text/plain": [
       "MultiThreadEnv(8 x VtolEnv)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123    \n",
    "rng = StableRNG(seed)\n",
    "    N_ENV = 8\n",
    "    UPDATE_FREQ = 1024\n",
    "    \n",
    "    \n",
    "    # define multiple environments for parallel training\n",
    "    env = MultiThreadEnv([\n",
    "        # use different names for the visualization\n",
    "        VtolEnv(; rng = StableRNG(hash(seed+i)), name = \"vtol$i\") for i in 1:N_ENV\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1f128b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function approximator\n",
    "# TODO: change architecture eventually \n",
    "    ns, na = length(state(env[1])), length(action_space(env[1]))\n",
    "    approximator = ActorCritic(\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                    Dense(ns, 128, tanh; initW = glorot_uniform(rng)),#\n",
    "                    Dense(128, 128, tanh; initW = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(Dense(128, na; initW = glorot_uniform(rng))),\n",
    "                    logσ = Chain(Dense(128, na; initW = glorot_uniform(rng))),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 128, tanh; initW = glorot_uniform(rng)),\n",
    "                    Dense(128, 128, tanh; initW = glorot_uniform(rng)),\n",
    "                    Dense(128, 1; initW = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(1e-3),\n",
    "            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ea4c37c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: The GPU function is being called but the GPU is not accessible. \n",
      "│ Defaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "└ @ Flux /home/larissa/.julia/packages/Flux/7nTyc/src/functor.jl:187\n"
     ]
    }
   ],
   "source": [
    "    agent = Agent( # A wrapper of an AbstractPolicy\n",
    "        # AbstractPolicy: the policy to use\n",
    "        # TODO: change eventually\n",
    "        policy = PPOPolicy(;\n",
    "                    approximator = approximator |> gpu,\n",
    "                    update_freq=UPDATE_FREQ,\n",
    "                    dist = Normal,\n",
    "                    # For parameters visit the docu: https://juliareinforcementlearning.org/docs/rlzoo/#ReinforcementLearningZoo.PPOPolicy\n",
    "                    ),\n",
    "        \n",
    "        # AbstractTrajectory: used to store transitions between an agent and an environment source\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float64} => (ns, N_ENV),\n",
    "            action = Matrix{Float64} => (na, N_ENV),\n",
    "            action_log_prob = Vector{Float64} => (N_ENV,),\n",
    "            reward = Vector{Float64} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f158a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "function saveModel(t, agent, env)\n",
    "    model = cpu(agent.policy.approximator)   \n",
    "    f = joinpath(\"./RL_models_l/\", \"vtol_2D_ppo_$t.bson\") # TODO: evtl anpassen\n",
    "    @save f model\n",
    "    println(\"parameters at step $t saved to $f\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07c5ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "function loadModel()\n",
    "    f = joinpath(\"./RL_models_l/\", \"vtol_2D_ppo_trained_on_fixed_point.bson\") # TODO: evtl anpassen\n",
    "    @load f model\n",
    "    return model\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3c1858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validate_policy(t, agent, env)\n",
    "    run(agent.policy, test_env, StopAfterEpisode(1), episode_test_reward_hook)\n",
    "    # the result of the hook\n",
    "    println(\"test reward at step $t: $(episode_test_reward_hook.rewards[end])\")\n",
    "    \n",
    "end;\n",
    "\n",
    "episode_test_reward_hook = TotalRewardPerEpisode(;is_display_on_exit=false)\n",
    "# create a env only for reward test\n",
    "test_env = VtolEnv(;name = \"testVTOL\", visualization = true, realtime = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdc71a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.policy.approximator = loadModel(); # TODO: un/comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb737010",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▎                                        |  ETA: 3:10:04\u001b[39m39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 10000: 34.12725831131034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▌                                        |  ETA: 1:54:12\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 20000: 34.83182210522378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|▉                                        |  ETA: 1:21:47\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 30000: 27.821055335686758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█                                        |  ETA: 1:10:44\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 40000: 36.809418233538125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▍                                       |  ETA: 1:01:30\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 50000: 39.96358402025995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▋                                       |  ETA: 0:54:45\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 60000: 35.2287758811548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|█▉                                       |  ETA: 0:51:30\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 70000: 30.189131608574833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██▏                                      |  ETA: 0:47:59\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 80000: 28.920522830424186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▌                                      |  ETA: 0:45:42\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 90000: 15.099916889249322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   7%|██▊                                      |  ETA: 0:43:58\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 100000 saved to ./RL_models_l/vtol_2D_ppo_100000.bson\n",
      "test reward at step 100000: 31.368517492418718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   7%|███                                      |  ETA: 0:43:02\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 110000: 37.21267511296462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   8%|███▎                                     |  ETA: 0:41:34\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 120000: 22.45304419908416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   9%|███▌                                     |  ETA: 0:40:25\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 130000: 27.21176008527262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   9%|███▊                                     |  ETA: 0:39:37\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 140000: 33.01721696890498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  10%|████▏                                    |  ETA: 0:39:13\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 150000: 44.454362804482216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  11%|████▍                                    |  ETA: 0:39:17\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 160000: 40.22809009029038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  11%|████▋                                    |  ETA: 0:38:57\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 170000: 26.910317804865056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  12%|████▉                                    |  ETA: 0:38:26\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 180000: 29.053162899686185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  13%|█████▏                                   |  ETA: 0:37:56\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 190000: 35.766889148773856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  13%|█████▍                                   |  ETA: 0:37:19\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 200000 saved to ./RL_models_l/vtol_2D_ppo_200000.bson\n",
      "test reward at step 200000: 36.45811090511687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  14%|█████▊                                   |  ETA: 0:36:41\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 210000: 36.44917272291243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  15%|██████                                   |  ETA: 0:35:57\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 220000: 40.98879232012059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  15%|██████▏                                  |  ETA: 0:35:48\u001b[39m"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] iterate",
      "    @ ./multidimensional.jl:399 [inlined]",
      "  [2] copy",
      "    @ ./broadcast.jl:892 [inlined]",
      "  [3] materialize",
      "    @ ./broadcast.jl:860 [inlined]",
      "  [4] adjoint",
      "    @ ~/.julia/packages/Zygote/PD12J/src/lib/broadcast.jl:110 [inlined]",
      "  [5] _pullback",
      "    @ ~/.julia/packages/ZygoteRules/AIbCs/src/adjoint.jl:65 [inlined]",
      "  [6] _pullback",
      "    @ ~/.julia/packages/Flux/7nTyc/src/layers/basic.jl:158 [inlined]",
      "  [7] _pullback(ctx::Zygote.Context{true}, f::Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, args::Matrix{Float64})",
      "    @ Zygote ~/.julia/packages/Zygote/PD12J/src/compiler/interface2.jl:0",
      "  [8] _pullback",
      "    @ ~/.julia/packages/Flux/7nTyc/src/layers/basic.jl:47 [inlined]",
      "  [9] _pullback(::Zygote.Context{true}, ::typeof(Flux.applychain), ::Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}, ::Matrix{Float64})",
      "    @ Zygote ~/.julia/packages/Zygote/PD12J/src/compiler/interface2.jl:0",
      " [10] _pullback",
      "    @ ~/.julia/packages/Flux/7nTyc/src/layers/basic.jl:49 [inlined]",
      " [11] _pullback(ctx::Zygote.Context{true}, f::Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, args::Matrix{Float64})",
      "    @ Zygote ~/.julia/packages/Zygote/PD12J/src/compiler/interface2.jl:0",
      " [12] _pullback",
      "    @ ~/.julia/packages/ReinforcementLearningZoo/tvfq9/src/algorithms/policy_gradient/ppo.jl:288 [inlined]",
      " [13] _pullback(::Zygote.Context{true}, ::ReinforcementLearningZoo.var\"#178#181\"{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Float32, Float32, Float32, Float32, ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Int64, Int64, Vector{Float64}, Vector{Float64}, Vector{Float64}, Matrix{Float64}})",
      "    @ Zygote ~/.julia/packages/Zygote/PD12J/src/compiler/interface2.jl:0",
      " [14] pullback(f::Function, ps::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})",
      "    @ Zygote ~/.julia/packages/Zygote/PD12J/src/compiler/interface.jl:373",
      " [15] gradient(f::Function, args::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})",
      "    @ Zygote ~/.julia/packages/Zygote/PD12J/src/compiler/interface.jl:96",
      " [16] _update!(p::PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, t::Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}})",
      "    @ ReinforcementLearningZoo ~/.julia/packages/ReinforcementLearningZoo/tvfq9/src/algorithms/policy_gradient/ppo.jl:287",
      " [17] update!",
      "    @ ~/.julia/packages/ReinforcementLearningZoo/tvfq9/src/algorithms/policy_gradient/ppo.jl:210 [inlined]",
      " [18] (::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}})(stage::PreActStage, env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing}, action::ReinforcementLearningZoo.EnrichedAction{Matrix{Float64}, NamedTuple{(:action_log_prob,), Tuple{Vector{Float64}}}})",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/yeRLW/src/policies/agents/agent.jl:78",
      " [19] _run(policy::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing}, stop_condition::StopAfterStep{ProgressMeter.Progress}, hook::ComposedHook{Tuple{DoEveryNStep{typeof(saveModel)}, DoEveryNStep{typeof(validate_policy)}}})",
      "    @ ReinforcementLearningZoo ~/.julia/packages/ReinforcementLearningZoo/tvfq9/src/algorithms/policy_gradient/run.jl:18",
      " [20] run(policy::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing}, stop_condition::StopAfterStep{ProgressMeter.Progress}, hook::ComposedHook{Tuple{DoEveryNStep{typeof(saveModel)}, DoEveryNStep{typeof(validate_policy)}}})",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/yeRLW/src/core/run.jl:10",
      " [21] top-level scope",
      "    @ In[23]:1",
      " [22] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [23] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both Losses and NNlib export \"ctc_loss\"; uses of it in module Flux must be qualified\n"
     ]
    }
   ],
   "source": [
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(1_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000), \n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49a302a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip790\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip790)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip791\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip790)\" d=\"\n",
       "M141.853 1486.45 L2352.76 1486.45 L2352.76 47.2441 L141.853 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip792\">\n",
       "    <rect x=\"141\" y=\"47\" width=\"2212\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip792)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  601.713,1486.45 601.713,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip792)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1098.32,1486.45 1098.32,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip792)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1594.93,1486.45 1594.93,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip792)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2091.54,1486.45 2091.54,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  601.713,1486.45 601.713,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1098.32,1486.45 1098.32,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1594.93,1486.45 1594.93,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2091.54,1486.45 2091.54,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip790)\" d=\"M591.991 1514.29 L610.347 1514.29 L610.347 1518.22 L596.273 1518.22 L596.273 1526.7 Q597.292 1526.35 598.31 1526.19 Q599.329 1526 600.347 1526 Q606.134 1526 609.514 1529.17 Q612.893 1532.34 612.893 1537.76 Q612.893 1543.34 609.421 1546.44 Q605.949 1549.52 599.629 1549.52 Q597.454 1549.52 595.185 1549.15 Q592.94 1548.78 590.532 1548.04 L590.532 1543.34 Q592.616 1544.47 594.838 1545.03 Q597.06 1545.58 599.537 1545.58 Q603.542 1545.58 605.879 1543.48 Q608.217 1541.37 608.217 1537.76 Q608.217 1534.15 605.879 1532.04 Q603.542 1529.94 599.537 1529.94 Q597.662 1529.94 595.787 1530.35 Q593.935 1530.77 591.991 1531.65 L591.991 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M1073.01 1544.91 L1080.65 1544.91 L1080.65 1518.55 L1072.34 1520.21 L1072.34 1515.95 L1080.6 1514.29 L1085.28 1514.29 L1085.28 1544.91 L1092.92 1544.91 L1092.92 1548.85 L1073.01 1548.85 L1073.01 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M1112.36 1517.37 Q1108.75 1517.37 1106.92 1520.93 Q1105.12 1524.47 1105.12 1531.6 Q1105.12 1538.71 1106.92 1542.27 Q1108.75 1545.82 1112.36 1545.82 Q1116 1545.82 1117.8 1542.27 Q1119.63 1538.71 1119.63 1531.6 Q1119.63 1524.47 1117.8 1520.93 Q1116 1517.37 1112.36 1517.37 M1112.36 1513.66 Q1118.17 1513.66 1121.23 1518.27 Q1124.31 1522.85 1124.31 1531.6 Q1124.31 1540.33 1121.23 1544.94 Q1118.17 1549.52 1112.36 1549.52 Q1106.55 1549.52 1103.47 1544.94 Q1100.42 1540.33 1100.42 1531.6 Q1100.42 1522.85 1103.47 1518.27 Q1106.55 1513.66 1112.36 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M1570.12 1544.91 L1577.75 1544.91 L1577.75 1518.55 L1569.44 1520.21 L1569.44 1515.95 L1577.71 1514.29 L1582.38 1514.29 L1582.38 1544.91 L1590.02 1544.91 L1590.02 1548.85 L1570.12 1548.85 L1570.12 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M1599.51 1514.29 L1617.87 1514.29 L1617.87 1518.22 L1603.8 1518.22 L1603.8 1526.7 Q1604.81 1526.35 1605.83 1526.19 Q1606.85 1526 1607.87 1526 Q1613.66 1526 1617.04 1529.17 Q1620.42 1532.34 1620.42 1537.76 Q1620.42 1543.34 1616.94 1546.44 Q1613.47 1549.52 1607.15 1549.52 Q1604.98 1549.52 1602.71 1549.15 Q1600.46 1548.78 1598.06 1548.04 L1598.06 1543.34 Q1600.14 1544.47 1602.36 1545.03 Q1604.58 1545.58 1607.06 1545.58 Q1611.06 1545.58 1613.4 1543.48 Q1615.74 1541.37 1615.74 1537.76 Q1615.74 1534.15 1613.4 1532.04 Q1611.06 1529.94 1607.06 1529.94 Q1605.19 1529.94 1603.31 1530.35 Q1601.46 1530.77 1599.51 1531.65 L1599.51 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M2070.31 1544.91 L2086.63 1544.91 L2086.63 1548.85 L2064.69 1548.85 L2064.69 1544.91 Q2067.35 1542.16 2071.93 1537.53 Q2076.54 1532.88 2077.72 1531.53 Q2079.97 1529.01 2080.85 1527.27 Q2081.75 1525.51 2081.75 1523.82 Q2081.75 1521.07 2079.8 1519.33 Q2077.88 1517.6 2074.78 1517.6 Q2072.58 1517.6 2070.13 1518.36 Q2067.7 1519.13 2064.92 1520.68 L2064.92 1515.95 Q2067.74 1514.82 2070.2 1514.24 Q2072.65 1513.66 2074.69 1513.66 Q2080.06 1513.66 2083.25 1516.35 Q2086.45 1519.03 2086.45 1523.52 Q2086.45 1525.65 2085.64 1527.57 Q2084.85 1529.47 2082.74 1532.07 Q2082.16 1532.74 2079.06 1535.95 Q2075.96 1539.15 2070.31 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M2106.45 1517.37 Q2102.84 1517.37 2101.01 1520.93 Q2099.2 1524.47 2099.2 1531.6 Q2099.2 1538.71 2101.01 1542.27 Q2102.84 1545.82 2106.45 1545.82 Q2110.08 1545.82 2111.89 1542.27 Q2113.72 1538.71 2113.72 1531.6 Q2113.72 1524.47 2111.89 1520.93 Q2110.08 1517.37 2106.45 1517.37 M2106.45 1513.66 Q2112.26 1513.66 2115.31 1518.27 Q2118.39 1522.85 2118.39 1531.6 Q2118.39 1540.33 2115.31 1544.94 Q2112.26 1549.52 2106.45 1549.52 Q2100.64 1549.52 2097.56 1544.94 Q2094.5 1540.33 2094.5 1531.6 Q2094.5 1522.85 2097.56 1518.27 Q2100.64 1513.66 2106.45 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip792)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,1450.34 2352.76,1450.34 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip792)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,1219.07 2352.76,1219.07 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip792)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,987.804 2352.76,987.804 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip792)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,756.538 2352.76,756.538 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip792)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,525.272 2352.76,525.272 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip792)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,294.005 2352.76,294.005 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip792)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,62.7388 2352.76,62.7388 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1486.45 141.853,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1450.34 160.751,1450.34 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1219.07 160.751,1219.07 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,987.804 160.751,987.804 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,756.538 160.751,756.538 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,525.272 160.751,525.272 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,294.005 160.751,294.005 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,62.7388 160.751,62.7388 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip790)\" d=\"M55.5523 1463.68 L63.1911 1463.68 L63.1911 1437.32 L54.881 1438.98 L54.881 1434.72 L63.1448 1433.06 L67.8207 1433.06 L67.8207 1463.68 L75.4596 1463.68 L75.4596 1467.62 L55.5523 1467.62 L55.5523 1463.68 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M84.9503 1433.06 L103.307 1433.06 L103.307 1436.99 L89.2327 1436.99 L89.2327 1445.46 Q90.2512 1445.12 91.2697 1444.96 Q92.2882 1444.77 93.3067 1444.77 Q99.0937 1444.77 102.473 1447.94 Q105.853 1451.11 105.853 1456.53 Q105.853 1462.11 102.381 1465.21 Q98.9085 1468.29 92.5891 1468.29 Q90.4132 1468.29 88.1447 1467.92 Q85.8993 1467.55 83.492 1466.81 L83.492 1462.11 Q85.5753 1463.24 87.7975 1463.8 Q90.0197 1464.35 92.4965 1464.35 Q96.5011 1464.35 98.8391 1462.25 Q101.177 1460.14 101.177 1456.53 Q101.177 1452.92 98.8391 1450.81 Q96.5011 1448.71 92.4965 1448.71 Q90.6215 1448.71 88.7466 1449.12 Q86.8947 1449.54 84.9503 1450.42 L84.9503 1433.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M57.7745 1232.42 L74.0939 1232.42 L74.0939 1236.35 L52.1495 1236.35 L52.1495 1232.42 Q54.8115 1229.66 59.3949 1225.03 Q64.0013 1220.38 65.1819 1219.04 Q67.4272 1216.51 68.3068 1214.78 Q69.2096 1213.02 69.2096 1211.33 Q69.2096 1208.57 67.2652 1206.84 Q65.3439 1205.1 62.2421 1205.1 Q60.043 1205.1 57.5893 1205.86 Q55.1588 1206.63 52.381 1208.18 L52.381 1203.46 Q55.2051 1202.32 57.6588 1201.74 Q60.1124 1201.17 62.1495 1201.17 Q67.5198 1201.17 70.7142 1203.85 Q73.9087 1206.54 73.9087 1211.03 Q73.9087 1213.16 73.0985 1215.08 Q72.3115 1216.98 70.205 1219.57 Q69.6263 1220.24 66.5245 1223.46 Q63.4226 1226.65 57.7745 1232.42 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M93.9086 1204.87 Q90.2975 1204.87 88.4688 1208.43 Q86.6632 1211.98 86.6632 1219.11 Q86.6632 1226.21 88.4688 1229.78 Q90.2975 1233.32 93.9086 1233.32 Q97.5428 1233.32 99.3483 1229.78 Q101.177 1226.21 101.177 1219.11 Q101.177 1211.98 99.3483 1208.43 Q97.5428 1204.87 93.9086 1204.87 M93.9086 1201.17 Q99.7187 1201.17 102.774 1205.77 Q105.853 1210.36 105.853 1219.11 Q105.853 1227.83 102.774 1232.44 Q99.7187 1237.02 93.9086 1237.02 Q88.0984 1237.02 85.0197 1232.44 Q81.9642 1227.83 81.9642 1219.11 Q81.9642 1210.36 85.0197 1205.77 Q88.0984 1201.17 93.9086 1201.17 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M58.7699 1001.15 L75.0892 1001.15 L75.0892 1005.08 L53.1449 1005.08 L53.1449 1001.15 Q55.8069 998.395 60.3902 993.765 Q64.9967 989.112 66.1772 987.77 Q68.4226 985.247 69.3022 983.51 Q70.205 981.751 70.205 980.061 Q70.205 977.307 68.2606 975.571 Q66.3393 973.835 63.2374 973.835 Q61.0384 973.835 58.5847 974.598 Q56.1541 975.362 53.3764 976.913 L53.3764 972.191 Q56.2004 971.057 58.6541 970.478 Q61.1078 969.899 63.1448 969.899 Q68.5152 969.899 71.7096 972.585 Q74.904 975.27 74.904 979.76 Q74.904 981.89 74.0939 983.811 Q73.3068 985.709 71.2004 988.302 Q70.6217 988.973 67.5198 992.191 Q64.418 995.385 58.7699 1001.15 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M84.9503 970.524 L103.307 970.524 L103.307 974.46 L89.2327 974.46 L89.2327 982.932 Q90.2512 982.584 91.2697 982.422 Q92.2882 982.237 93.3067 982.237 Q99.0937 982.237 102.473 985.409 Q105.853 988.58 105.853 993.996 Q105.853 999.575 102.381 1002.68 Q98.9085 1005.76 92.5891 1005.76 Q90.4132 1005.76 88.1447 1005.39 Q85.8993 1005.01 83.492 1004.27 L83.492 999.575 Q85.5753 1000.71 87.7975 1001.26 Q90.0197 1001.82 92.4965 1001.82 Q96.5011 1001.82 98.8391 999.714 Q101.177 997.608 101.177 993.996 Q101.177 990.385 98.8391 988.279 Q96.5011 986.172 92.4965 986.172 Q90.6215 986.172 88.7466 986.589 Q86.8947 987.006 84.9503 987.885 L84.9503 970.524 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M67.9133 755.184 Q71.2698 755.901 73.1448 758.17 Q75.0429 760.438 75.0429 763.772 Q75.0429 768.887 71.5244 771.688 Q68.0059 774.489 61.5245 774.489 Q59.3486 774.489 57.0338 774.049 Q54.7421 773.633 52.2884 772.776 L52.2884 768.262 Q54.2328 769.397 56.5477 769.975 Q58.8625 770.554 61.3856 770.554 Q65.7837 770.554 68.0754 768.818 Q70.3902 767.082 70.3902 763.772 Q70.3902 760.716 68.2374 759.003 Q66.1078 757.267 62.2884 757.267 L58.2606 757.267 L58.2606 753.425 L62.4735 753.425 Q65.9226 753.425 67.7513 752.059 Q69.58 750.67 69.58 748.077 Q69.58 745.415 67.6819 744.003 Q65.8069 742.568 62.2884 742.568 Q60.3671 742.568 58.168 742.985 Q55.969 743.401 53.3301 744.281 L53.3301 740.114 Q55.9921 739.374 58.3069 739.003 Q60.6449 738.633 62.705 738.633 Q68.0291 738.633 71.1309 741.064 Q74.2327 743.471 74.2327 747.591 Q74.2327 750.462 72.5892 752.452 Q70.9457 754.42 67.9133 755.184 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M93.9086 742.337 Q90.2975 742.337 88.4688 745.901 Q86.6632 749.443 86.6632 756.573 Q86.6632 763.679 88.4688 767.244 Q90.2975 770.786 93.9086 770.786 Q97.5428 770.786 99.3483 767.244 Q101.177 763.679 101.177 756.573 Q101.177 749.443 99.3483 745.901 Q97.5428 742.337 93.9086 742.337 M93.9086 738.633 Q99.7187 738.633 102.774 743.239 Q105.853 747.823 105.853 756.573 Q105.853 765.299 102.774 769.906 Q99.7187 774.489 93.9086 774.489 Q88.0984 774.489 85.0197 769.906 Q81.9642 765.299 81.9642 756.573 Q81.9642 747.823 85.0197 743.239 Q88.0984 738.633 93.9086 738.633 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M68.9087 523.917 Q72.2652 524.635 74.1402 526.904 Q76.0383 529.172 76.0383 532.505 Q76.0383 537.621 72.5198 540.422 Q69.0013 543.223 62.5198 543.223 Q60.3439 543.223 58.0291 542.783 Q55.7375 542.366 53.2838 541.51 L53.2838 536.996 Q55.2282 538.13 57.543 538.709 Q59.8578 539.288 62.381 539.288 Q66.7791 539.288 69.0707 537.552 Q71.3855 535.815 71.3855 532.505 Q71.3855 529.45 69.2328 527.737 Q67.1032 526.001 63.2837 526.001 L59.256 526.001 L59.256 522.158 L63.4689 522.158 Q66.918 522.158 68.7467 520.792 Q70.5754 519.404 70.5754 516.811 Q70.5754 514.149 68.6772 512.737 Q66.8022 511.302 63.2837 511.302 Q61.3624 511.302 59.1634 511.718 Q56.9643 512.135 54.3254 513.015 L54.3254 508.848 Q56.9875 508.107 59.3023 507.737 Q61.6402 507.367 63.7004 507.367 Q69.0244 507.367 72.1263 509.797 Q75.2281 512.205 75.2281 516.325 Q75.2281 519.195 73.5846 521.186 Q71.9411 523.154 68.9087 523.917 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M84.9503 507.992 L103.307 507.992 L103.307 511.927 L89.2327 511.927 L89.2327 520.399 Q90.2512 520.052 91.2697 519.89 Q92.2882 519.704 93.3067 519.704 Q99.0937 519.704 102.473 522.876 Q105.853 526.047 105.853 531.464 Q105.853 537.042 102.381 540.144 Q98.9085 543.223 92.5891 543.223 Q90.4132 543.223 88.1447 542.852 Q85.8993 542.482 83.492 541.741 L83.492 537.042 Q85.5753 538.177 87.7975 538.732 Q90.0197 539.288 92.4965 539.288 Q96.5011 539.288 98.8391 537.181 Q101.177 535.075 101.177 531.464 Q101.177 527.853 98.8391 525.746 Q96.5011 523.64 92.4965 523.64 Q90.6215 523.64 88.7466 524.056 Q86.8947 524.473 84.9503 525.353 L84.9503 507.992 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M66.5939 280.799 L54.7884 299.248 L66.5939 299.248 L66.5939 280.799 M65.367 276.725 L71.2466 276.725 L71.2466 299.248 L76.1772 299.248 L76.1772 303.137 L71.2466 303.137 L71.2466 311.285 L66.5939 311.285 L66.5939 303.137 L50.9921 303.137 L50.9921 298.623 L65.367 276.725 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M93.9086 279.804 Q90.2975 279.804 88.4688 283.369 Q86.6632 286.91 86.6632 294.04 Q86.6632 301.146 88.4688 304.711 Q90.2975 308.253 93.9086 308.253 Q97.5428 308.253 99.3483 304.711 Q101.177 301.146 101.177 294.04 Q101.177 286.91 99.3483 283.369 Q97.5428 279.804 93.9086 279.804 M93.9086 276.1 Q99.7187 276.1 102.774 280.707 Q105.853 285.29 105.853 294.04 Q105.853 302.767 102.774 307.373 Q99.7187 311.956 93.9086 311.956 Q88.0984 311.956 85.0197 307.373 Q81.9642 302.767 81.9642 294.04 Q81.9642 285.29 85.0197 280.707 Q88.0984 276.1 93.9086 276.1 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M67.5893 49.5328 L55.7838 67.9818 L67.5893 67.9818 L67.5893 49.5328 M66.3624 45.4588 L72.242 45.4588 L72.242 67.9818 L77.1725 67.9818 L77.1725 71.8707 L72.242 71.8707 L72.242 80.0188 L67.5893 80.0188 L67.5893 71.8707 L51.9875 71.8707 L51.9875 67.3568 L66.3624 45.4588 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M84.9503 45.4588 L103.307 45.4588 L103.307 49.3939 L89.2327 49.3939 L89.2327 57.8661 Q90.2512 57.5189 91.2697 57.3569 Q92.2882 57.1717 93.3067 57.1717 Q99.0937 57.1717 102.473 60.3429 Q105.853 63.5142 105.853 68.9309 Q105.853 74.5095 102.381 77.6114 Q98.9085 80.6901 92.5891 80.6901 Q90.4132 80.6901 88.1447 80.3197 Q85.8993 79.9493 83.492 79.2086 L83.492 74.5095 Q85.5753 75.6438 87.7975 76.1993 Q90.0197 76.7549 92.4965 76.7549 Q96.5011 76.7549 98.8391 74.6484 Q101.177 72.542 101.177 68.9309 Q101.177 65.3198 98.8391 63.2133 Q96.5011 61.1068 92.4965 61.1068 Q90.6215 61.1068 88.7466 61.5235 Q86.8947 61.9402 84.9503 62.8198 L84.9503 45.4588 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip792)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  204.426,565.639 303.747,533.05 403.069,857.321 502.391,441.58 601.713,295.69 701.035,514.69 800.356,747.79 899.678,806.467 999,1445.72 1098.32,693.24 \n",
       "  1197.64,422.928 1296.97,1105.61 1396.29,885.503 1495.61,616.982 1594.93,87.9763 1694.25,283.455 1793.57,899.446 1892.9,800.332 1992.22,489.8 2091.54,457.829 \n",
       "  2190.86,458.243 2290.18,248.27 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip790)\" d=\"\n",
       "M1980.97 198.898 L2279.06 198.898 L2279.06 95.2176 L1980.97 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1980.97,198.898 2279.06,198.898 2279.06,95.2176 1980.97,95.2176 1980.97,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip790)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2005.54,147.058 2152.93,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip790)\" d=\"M2191.34 166.745 Q2189.53 171.375 2187.82 172.787 Q2186.11 174.199 2183.24 174.199 L2179.84 174.199 L2179.84 170.634 L2182.34 170.634 Q2184.09 170.634 2185.07 169.8 Q2186.04 168.967 2187.22 165.865 L2187.98 163.921 L2177.5 138.412 L2182.01 138.412 L2190.11 158.689 L2198.22 138.412 L2202.73 138.412 L2191.34 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip790)\" d=\"M2210.02 160.402 L2217.66 160.402 L2217.66 134.037 L2209.35 135.703 L2209.35 131.444 L2217.61 129.778 L2222.29 129.778 L2222.29 160.402 L2229.93 160.402 L2229.93 164.338 L2210.02 164.338 L2210.02 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(episode_test_reward_hook.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb0d4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_visualization(); # closes the MeshCat visualization"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
