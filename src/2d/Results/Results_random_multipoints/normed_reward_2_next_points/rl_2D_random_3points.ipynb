{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649b76a",
   "metadata": {},
   "source": [
    "# Init Bionic VTOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96751412",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position\n",
    "\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;\n",
    "using Distributions;\n",
    "\n",
    "using Plots;\n",
    "using Statistics;\n",
    "\n",
    "using BSON: @save, @load # save mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e4ee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: MeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "│ http://127.0.0.1:8700\n",
      "└ @ MeshCat /home/larissa/.julia/packages/MeshCat/Ax8pH/src/visualizer.jl:73\n"
     ]
    }
   ],
   "source": [
    "create_visualization();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9557df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indicates how many threads Julia was started with. This is important for the multi-threaded environment\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411db62",
   "metadata": {},
   "source": [
    "# Create Reinforcement Learning Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96af6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv # Parametric Constructor for a subtype of AbstractEnv\n",
    "    action_space::A # action space\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}} # observation space\n",
    "    state::Vector{T} # current state space\n",
    "    action::ACT # action space\n",
    "    done::Bool # done\n",
    "    t::T # time\n",
    "    rng::R # random number generator\n",
    "\n",
    "    name::String # for multible environoments\n",
    "    visualization::Bool # visualization\n",
    "    realtime::Bool # realtime\n",
    "    \n",
    "    # Everything you need aditionaly can also go in here.\n",
    "    x_W::Vector{T} # current position\n",
    "    v_B::Vector{T} # velocity\n",
    "    R_W::Matrix{T} # current rotation\n",
    "    ω_B::Vector{T} # rotation velocitiy\n",
    "    wind_W::Vector{T} # wind\n",
    "    Δt::T # Δ time\n",
    "    \n",
    "    # Current Bonus / Target\n",
    "    num_waypoints::Int # includig start point\n",
    "    waypoints::Vector{Vector{T}}\n",
    "    reached_goal::BitVector\n",
    "    \n",
    "    progress::T\n",
    "    progress_prev::T\n",
    "    current_point::Int\n",
    "    reached_goal_in_step::Bool\n",
    "    \n",
    "    r_tol::T\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a6873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a keyword-based constructor for the type declared in the mutable struct typedef. \n",
    "# It could also be done with the macro Base.@kwdef.\n",
    "function VtolEnv(;\n",
    "    rng = Random.GLOBAL_RNG, # Random number generation\n",
    "    name = \"vtol\",\n",
    "    visualization = false,\n",
    "    realtime = false,\n",
    "    kwargs... # let the function take an arbitrary number of keyword arguments \n",
    ")\n",
    "    \n",
    "    T = Float64; # explicit type which is used e.g. in state. Cannot be altered due to the poor matrix defininon.\n",
    "\n",
    "    \n",
    "    action_space = Space(\n",
    "        ClosedInterval{T}[\n",
    "            0.0..2.0, # propeller 1\n",
    "            0.0..2.0, # propeller 2\n",
    "            ], \n",
    "    )\n",
    "\n",
    "    \n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            # orientate yourself on the state space from the paper\n",
    "            typemin(T)..typemax(T), # position along x\n",
    "            typemin(T)..typemax(T), # position along z\n",
    "            \n",
    "            typemin(T)..typemax(T), # orientation along x\n",
    "            typemin(T)..typemax(T), # orientation along z\n",
    "            \n",
    "            typemin(T)..typemax(T), # velocity along x BODY coordinates\n",
    "            typemin(T)..typemax(T), # velocity along y BODY coordinates\n",
    "            \n",
    "            typemin(T)..typemax(T), # rotational velocity along z BODY coordinates\n",
    "            \n",
    "            typemin(T)..typemax(T), # position error along x (next gate - current position)\n",
    "            typemin(T)..typemax(T), # position error along z (next gate - current position)\n",
    "            \n",
    "            typemin(T)..typemax(T), # way to next next gate x (next next gate - next gate)\n",
    "            typemin(T)..typemax(T), # way to next next gate z (next next gate - next gate)\n",
    "            # TODO: more points?\n",
    "            ], \n",
    "    )\n",
    "    \n",
    "    num_waypoints = 3 # number of waypoints, includig start point\n",
    "    waypoints = generate_trajectory(num_waypoints) # trajectory with num_waypoints waypoints (+ start point) \n",
    "    reached_goal = falses(num_waypoints)\n",
    "    \n",
    "    if visualization #visualizes VTOL and waypoints\n",
    "        create_VTOL(name, actuators = true, color_vec=[1.0; 1.0; 0.6; 1.0]);\n",
    "        visualize_waypoints(waypoints, 0.15)\n",
    "    end\n",
    "\n",
    "    environment = VtolEnv(\n",
    "        action_space,\n",
    "        state_space, \n",
    "        zeros(T, length(state_space)), # current state, needs to be extended\n",
    "        rand(action_space), #initialization action\n",
    "        false, # episode done \n",
    "        0.0, # time\n",
    "        rng, # random number generator  \n",
    "        \n",
    "        name,\n",
    "        visualization,\n",
    "        realtime,\n",
    "        \n",
    "        zeros(T, 3), # x_W, current position\n",
    "        zeros(T, 3), # v_B, velocity\n",
    "        [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0], # R_W, current rotation, Float64... so T needs to be Float64\n",
    "        zeros(T, 3), # ω_B\n",
    "        zeros(T, 3), # wind_W\n",
    "        T(0.025), # Δt \n",
    "        \n",
    "        num_waypoints, # includig start point\n",
    "        waypoints, \n",
    "        reached_goal,\n",
    "        \n",
    "        0.0, # progress\n",
    "        0.0, # progress_prev\n",
    "        2, # current point\n",
    "        false, # reached_goal_in_step\n",
    "        \n",
    "        0.5 # r_tol\n",
    "    )\n",
    "    \n",
    "    \n",
    "    reset!(environment)\n",
    "    \n",
    "    return environment\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec660d5e",
   "metadata": {},
   "source": [
    "Just for explanation:\n",
    "\n",
    "1. A mutable Struct is created. A struct is a constructor and a constructor is a function that creates new objects.\n",
    "2. A outer keyword-based constructor method is added for the type declared in the mutable struct typedef before.\n",
    "\n",
    "So now we have a function with two methods. Julia will decide which method to call by multiple dispatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3c4bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "# 2 methods for type constructor:<ul><li> VtolEnv(; <i>rng, name, visualization, realtime, kwargs...</i>) in Main at In[5]:3</li> <li> VtolEnv(action_space::<b>A</b>, observation_space::<b>Space{Array{ClosedInterval{T}, 1}}</b>, state::<b>Vector{T}</b>, action::<b>ACT</b>, done::<b>Bool</b>, t::<b>T</b>, rng::<b>R</b>, name::<b>String</b>, visualization::<b>Bool</b>, realtime::<b>Bool</b>, x_W::<b>Vector{T}</b>, v_B::<b>Vector{T}</b>, R_W::<b>Matrix{T}</b>, ω_B::<b>Vector{T}</b>, wind_W::<b>Vector{T}</b>, Δt::<b>T</b>, num_waypoints::<b>Int64</b>, waypoints::<b>Array{Vector{T}, 1}</b>, reached_goal::<b>BitVector</b>, progress::<b>T</b>, progress_prev::<b>T</b>, current_point::<b>Int64</b>, reached_goal_in_step::<b>Bool</b>, r_tol::<b>T</b>)<i> where {A, T, ACT, R<:AbstractRNG}</i> in Main at In[4]:2</li> </ul>"
      ],
      "text/plain": [
       "# 2 methods for type constructor:\n",
       "[1] VtolEnv(; rng, name, visualization, realtime, kwargs...) in Main at In[5]:3\n",
       "[2] VtolEnv(action_space::A, observation_space::Space{Array{ClosedInterval{T}, 1}}, state::Vector{T}, action::ACT, done::Bool, t::T, rng::R, name::String, visualization::Bool, realtime::Bool, x_W::Vector{T}, v_B::Vector{T}, R_W::Matrix{T}, ω_B::Vector{T}, wind_W::Vector{T}, Δt::T, num_waypoints::Int64, waypoints::Array{Vector{T}, 1}, reached_goal::BitVector, progress::T, progress_prev::T, current_point::Int64, reached_goal_in_step::Bool, r_tol::T) where {A, T, ACT, R<:AbstractRNG} in Main at In[4]:2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(VtolEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806413d1",
   "metadata": {},
   "source": [
    "# Define the RL interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f822029",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f7fb89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function computeReward(env::VtolEnv{A,T}) where {A,T}\n",
    "    \n",
    "    norm_way = 0.0 # DEBUG: save in environment\n",
    "    for i in 1:(env.num_waypoints - 1)\n",
    "        norm_way += norm(env.waypoints[i] - env.waypoints[i + 1])\n",
    "    end\n",
    "    \n",
    "    v_min = 0.0 # min velocity\n",
    "    v_max = 3.0 # max velocity\n",
    "    \n",
    "#     k_v = 0.1 # factor for velocity penalty\n",
    "#     norm_v = norm(env.v_B) # penalty for velocity\n",
    "#     if (v_min <= norm_v && norm_v <= v_max) \n",
    "#         0.0\n",
    "#     end\n",
    "    \n",
    "    \n",
    "    k_wp = 5.0 * env.num_waypoints # factor for reached gate reward\n",
    "    r_wp = 0.0 # reward for reached gate, TODO: change to gates later (when gates != waypoints)\n",
    "    if env.reached_goal_in_step\n",
    "        r_wp = exp(-norm(env.x_W - env.waypoints[env.current_point - 1])/env.r_tol)\n",
    "    end\n",
    "    \n",
    "    k_ω = 0.01 # factor for too high body rate penalty\n",
    "    norm_ω = norm(env.ω_B[3]) # penalty for body rate \n",
    "\n",
    "    k_s = 0.0 / norm_way #5.0 # factor for reached distance (overall) reward, TODO later add factor as in paper (p. 4)\n",
    "    r_s = env.progress # reward for reached distance (overall)\n",
    "    \n",
    "    k_p = 5.0 * env.num_waypoints / norm_way;# factor for progress (between current position and last position) reward \n",
    "    r_p = (env.progress - env.progress_prev); # reward for progress (between current position and last position)\n",
    "\n",
    "    return k_p * r_p + k_s * k_s + k_wp * r_wp - k_ω * norm_ω # - k_v * norm_v\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = computeReward(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae45ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    # Visualize initial state\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, [0.0; 0.0; 0.0; 0.0]);\n",
    "    end\n",
    "    \n",
    "    env.x_W = [0.0; 0.0; 0.0];\n",
    "    env.v_B = [0.0; 0.0; 0.0];\n",
    "    env.R_W = Matrix(UnitQuaternion(RotZ(-pi/2.0)*RotY(-pi/2.0)*RotX(pi)));\n",
    "\n",
    "    env.ω_B = [0.0; 0.0; 0.0];\n",
    "    env.wind_W = [0.0; 0.0; 0.0];\n",
    "    \n",
    "    env.num_waypoints = 3; # includig start point\n",
    "    env.waypoints = generate_trajectory(env.num_waypoints);\n",
    "    env.reached_goal = falses(env.num_waypoints);\n",
    "    env.reached_goal[1] = true; # set first point to reached (start point)\n",
    "    \n",
    "    env.current_point = 2;\n",
    "    env.reached_goal_in_step = false;\n",
    "    env.r_tol = 0.5;\n",
    "    \n",
    "    if env.visualization\n",
    "        visualize_waypoints(env.waypoints, 0.15); # debug: other radius?\n",
    "    end\n",
    "    \n",
    "\n",
    "    env.progress = 0.0;\n",
    "    env.progress_prev = 0.0;\n",
    "    \n",
    "    \n",
    "    env.state = [env.x_W[1]; # position along x\n",
    "                 env.x_W[3]; # position along z\n",
    "        \n",
    "                 env.R_W[1,1]; # orientation along x\n",
    "                 env.R_W[3,1]; # orientation along z\n",
    "        \n",
    "                 env.v_B[1]; # velocity along x BODY coordinates\n",
    "                 env.v_B[2]; # velocity along y BODY coordinates  \n",
    "        \n",
    "                 env.ω_B[3]; # rotational velocity along z BODY coordinates\n",
    "        \n",
    "                 env.waypoints[2][1] - env.x_W[1]; # position error along x\n",
    "                 env.waypoints[2][3] - env.x_W[3]; # position error along z\n",
    "                 \n",
    "                 0.0; # way to next next gate x (next next gate - next gate)\n",
    "                 0.0] # way to next next gate z (next next gate - next gate)\n",
    "    \n",
    "    if env.num_waypoints >= 3\n",
    "        env.state[10] = env.waypoints[3][1] - env.waypoints[2][1]; # way to next next gate x (next next gate - next gate)\n",
    "        env.state[11] = env.waypoints[3][3] - env.waypoints[2][1]; # way to next next gate z (next next gate - next gate)\n",
    "    end\n",
    "        \n",
    "    env.t = 0.0;\n",
    "    env.action = [0.0, 0.0];\n",
    "    env.done = false;\n",
    "    \n",
    "    nothing\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cf1a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a methods for a callable object.\n",
    "# So when a VtolEnv object is created, it has this method that can be called\n",
    "function (env::VtolEnv)(a)\n",
    "    # TODO: set flaps later in 3D\n",
    "    # set the propeller trust and the two flaps 2D case\n",
    "    next_action = [a[1], a[2], 0.0, 0.0]\n",
    "   \n",
    "    _step!(env, next_action)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e9eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VtolEnv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26a116cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "# 3 methods for callable object:<ul><li> (env::<b>VtolEnv</b>)(a) in Main at In[10]:3</li> <li> (env::<b>AbstractEnv</b>)(action) in ReinforcementLearningBase</li> <li> (env::<b>AbstractEnv</b>)(action, player) in ReinforcementLearningBase</li> </ul>"
      ],
      "text/plain": [
       "# 3 methods for callable object:\n",
       "[1] (env::VtolEnv)(a) in Main at In[10]:3\n",
       "[2] (env::AbstractEnv)(action) in ReinforcementLearningBase\n",
       "[3] (env::AbstractEnv)(action, player) in ReinforcementLearningBase"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(env) # Just to explain which methods the object has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e7d4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "function _step!(env::VtolEnv, next_action)\n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(env.v_B, env.R_W, env.wind_W)\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = vtol_model(v_in_wind_B, next_action, eth_vtol_param);\n",
    "    # Limit to 2D\n",
    "    force_B[3] = 0.0; # Body Z\n",
    "    env.v_B[3] = 0.0;\n",
    "    torque_B[1] = 0.0; torque_B[2] = 0.0;  # Body X and Y\n",
    "    env.ω_B[1] = 0.0; env.ω_B[2] = 0.0;\n",
    "    # integrate rigid body dynamics for Δt\n",
    "    env.x_W, env.v_B, env.R_W, env.ω_B, time = rigid_body_simple(torque_B, force_B, env.x_W, env.v_B, env.R_W, env.ω_B, env.t, env.Δt, eth_vtol_param)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    env.reached_goal_in_step = false;\n",
    "    if norm(env.x_W - env.waypoints[env.current_point]) < env.r_tol\n",
    "        env.reached_goal_in_step = true;\n",
    "        env.reached_goal[env.current_point] = true;\n",
    "        env.current_point += 1;\n",
    "    end\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # calculate progress on trajectory\n",
    "    env.progress_prev = env.progress\n",
    "    \n",
    "    current_progress = 0.0\n",
    "    line_segment, progress = calculate_progress(env.waypoints, env.x_W)\n",
    "    for i in 2:(line_segment)\n",
    "       current_progress +=  norm(env.waypoints[i] - env.waypoints[i - 1])  \n",
    "    end\n",
    "    current_progress += norm(env.waypoints[line_segment] - progress)\n",
    "    \n",
    "    env.progress = current_progress\n",
    "    \n",
    "    \n",
    "\n",
    "    if env.realtime\n",
    "        sleep(env.Δt) # TODO: just a dirty hack. this is of course slower than real time.\n",
    "    end\n",
    "\n",
    "    # Visualize the new state \n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W, QuatRotation(env.R_W));\n",
    "        set_actuators(env.name, next_action)\n",
    "        \n",
    "        for i in eachindex(env.reached_goal)\n",
    "            if env.reached_goal[i]\n",
    "                create_sphere(\"fixgoal_$i\", 0.2, color=RGBA{Float32}(1.0, 0.0, 0.0, 1.0));\n",
    "                set_transform(\"fixgoal_$i\", env.waypoints[i]);\n",
    "            end\n",
    "        end\n",
    "    end\n",
    " \n",
    "    env.t += env.Δt\n",
    "\n",
    "    \n",
    "    \n",
    "    env.state[1] = env.x_W[1]; # position along x\n",
    "    env.state[2] = env.x_W[3]; # position along z\n",
    "    \n",
    "    env.state[3] = env.R_W[1,1]; # orientation along x\n",
    "    env.state[4] = env.R_W[3,1]; # orientation along z\n",
    "    \n",
    "    env.state[5] = env.v_B[1]; # velocity along x BODY coordinates\n",
    "    env.state[6] = env.v_B[2]; # velocity along y BODY coordinates\n",
    "    \n",
    "    env.state[7] = env.ω_B[3];  # rotational velocity along z BODY coordinates\n",
    "    \n",
    "    \n",
    "    if env.current_point <= env.num_waypoints\n",
    "        env.state[8] = env.waypoints[env.current_point][1] - env.x_W[1]; # position error along x\n",
    "        env.state[9] = env.waypoints[env.current_point][3] - env.x_W[3]; # position error along z\n",
    "        \n",
    "        if env.current_point <= env.num_waypoints - 1\n",
    "            env.state[10] = env.waypoints[env.current_point + 1][1] - env.waypoints[env.current_point][1]; # way to next next gate x (next next gate - next gate)\n",
    "            env.state[11] = env.waypoints[env.current_point + 1][3] - env.waypoints[env.current_point][3]; # way to next next gate z (next next gate - next gate)\n",
    "        else\n",
    "            env.state[10] = 0.0 # way to next next gate x (next next gate - next gate)\n",
    "            env.state[11] = 0.0 # way to next next gate z (next next gate - next gate)\n",
    "        end\n",
    "    else\n",
    "        env.state[8] = 0.0; # position error along x\n",
    "        env.state[9] = 0.0; # position error along z\n",
    "        env.state[10] = 0.0 # way to next next gate x (next next gate - next gate)\n",
    "        env.state[11] = 0.0 # way to next next gate z (next next gate - next gate)\n",
    "    end\n",
    "        \n",
    "    \n",
    "    # Termination criteria\n",
    "    # TODO: Use many termination criteria so that you do not train unnecessarily in wrong areas\n",
    "    env.done = #true\n",
    "        # After time... How fast is drone+Range of desired point\n",
    "        # After reaching position (circle of r_tol)\n",
    "        norm(env.ω_B) > 100.0 || \n",
    "        norm(env.v_B) > 100.0 || # stop if body is too fast # TODO: set higher later in fast training phase\n",
    "        env.x_W[3] < -5.0 || # stop if body is below -5m\n",
    "        env.t > env.num_waypoints * 10.0 ||# stop after 10s per point\n",
    "        norm(env.x_W - progress) > 5.0 || # too far off the path \n",
    "        env.current_point > env.num_waypoints # all points reached\n",
    "    nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd358d73",
   "metadata": {},
   "source": [
    "changed to 10s (5s before) per point and 5.0m too far off path (2.0 before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e1cd988",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:              | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "random policy with VtolEnv | \u001b[32m2000  \u001b[39m\u001b[36m 2000  \u001b[39m\u001b[0m2.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"random policy with VtolEnv\", Any[], 2000, false, false, true, 1.670537362069329e9, 1.670537364464737e9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RLBase.test_runnable!(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223a31f",
   "metadata": {},
   "source": [
    "Show an overview of the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6de74",
   "metadata": {},
   "source": [
    "# Setup of a reinforcement learning experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5683fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "MultiThreadEnv(8 x VtolEnv)"
      ],
      "text/plain": [
       "MultiThreadEnv(8 x VtolEnv)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123    \n",
    "rng = StableRNG(seed)\n",
    "    N_ENV = 8\n",
    "    UPDATE_FREQ = 1024\n",
    "    \n",
    "    \n",
    "    # define multiple environments for parallel training\n",
    "    env = MultiThreadEnv([\n",
    "        # use different names for the visualization\n",
    "        VtolEnv(; rng = StableRNG(hash(seed+i)), name = \"vtol$i\") for i in 1:N_ENV\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1f128b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function approximator\n",
    "# TODO: change architecture eventually \n",
    "    ns, na = length(state(env[1])), length(action_space(env[1]))\n",
    "    approximator = ActorCritic(\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                    Dense(ns, 128, tanh; initW = glorot_uniform(rng)),#\n",
    "                    Dense(128, 128, tanh; initW = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(Dense(128, na; initW = glorot_uniform(rng))),\n",
    "                    logσ = Chain(Dense(128, na; initW = glorot_uniform(rng))),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 128, tanh; initW = glorot_uniform(rng)),\n",
    "                    Dense(128, 128, tanh; initW = glorot_uniform(rng)),\n",
    "                    Dense(128, 1; initW = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(1e-3),\n",
    "            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea4c37c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: The GPU function is being called but the GPU is not accessible. \n",
      "│ Defaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "└ @ Flux /home/larissa/.julia/packages/Flux/7nTyc/src/functor.jl:187\n"
     ]
    }
   ],
   "source": [
    "    agent = Agent( # A wrapper of an AbstractPolicy\n",
    "        # AbstractPolicy: the policy to use\n",
    "        # TODO: change eventually\n",
    "        policy = PPOPolicy(;\n",
    "                    approximator = approximator |> gpu,\n",
    "                    update_freq=UPDATE_FREQ,\n",
    "                    dist = Normal,\n",
    "                    # For parameters visit the docu: https://juliareinforcementlearning.org/docs/rlzoo/#ReinforcementLearningZoo.PPOPolicy\n",
    "                    ),\n",
    "        \n",
    "        # AbstractTrajectory: used to store transitions between an agent and an environment source\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float64} => (ns, N_ENV),\n",
    "            action = Matrix{Float64} => (na, N_ENV),\n",
    "            action_log_prob = Vector{Float64} => (N_ENV,),\n",
    "            reward = Vector{Float64} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f158a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "function saveModel(t, agent, env)\n",
    "    model = cpu(agent.policy.approximator)   \n",
    "    f = joinpath(\"./RL_models_l/\", \"vtol_2D_ppo_$t.bson\") # TODO: evtl anpassen\n",
    "    @save f model\n",
    "    println(\"parameters at step $t saved to $f\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07c5ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "function loadModel()\n",
    "    f = joinpath(\"./RL_models_l/\", \"vtol_2D_ppo_trained_on_random_point.bson\") # TODO: evtl anpassen\n",
    "    @load f model\n",
    "    return model\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3c1858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validate_policy(t, agent, env)\n",
    "    run(agent.policy, test_env, StopAfterEpisode(1), episode_test_reward_hook)\n",
    "    # the result of the hook\n",
    "    println(\"test reward at step $t: $(episode_test_reward_hook.rewards[end])\")\n",
    "    \n",
    "end;\n",
    "\n",
    "episode_test_reward_hook = TotalRewardPerEpisode(;is_display_on_exit=false)\n",
    "# create a env only for reward test\n",
    "test_env = VtolEnv(;name = \"testVTOL\", visualization = true, realtime = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c8316db",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.policy.approximator = loadModel(); # TODO: un/comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb737010",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   0%|▏                                        |  ETA: 4:59:03\u001b[39m[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 10000: -2.0888480817676456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▍                                        |  ETA: 2:53:09\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 20000: -0.610470659901308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▌                                        |  ETA: 2:09:13\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 30000: 7.863415297325599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|▋                                        |  ETA: 1:48:25\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 40000: 20.393668587344486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|▊                                        |  ETA: 1:37:49\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 50000: -1.9083591167490324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|█                                        |  ETA: 1:30:19\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 60000: -1.9248353239331164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▏                                       |  ETA: 1:24:16\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 70000: -0.8093865253329748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▎                                       |  ETA: 1:19:26\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 80000: -1.815651333678338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▌                                       |  ETA: 1:16:21\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 90000: 7.107554252755284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▋                                       |  ETA: 1:13:38\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 100000 saved to ./RL_models_l/vtol_2D_ppo_100000.bson\n",
      "test reward at step 100000: 4.33593202532676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▊                                       |  ETA: 1:12:10\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 110000: 2.151850797766166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██                                       |  ETA: 1:09:43\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 120000: 6.4825957337376146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██▏                                      |  ETA: 1:07:36\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 130000: 18.129786225864752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▎                                      |  ETA: 1:06:42\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 140000: 25.755261403469426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▍                                      |  ETA: 1:05:05\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 150000: 8.992994624387437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▋                                      |  ETA: 1:03:31\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 160000: 2.342050950203813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   7%|██▊                                      |  ETA: 1:02:15\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 170000: 11.48942816966507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   7%|███                                      |  ETA: 1:00:43\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 180000: 4.602746791707984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   8%|███▏                                     |  ETA: 0:59:41\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 190000: 6.873626664743279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   8%|███▎                                     |  ETA: 0:58:37\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 200000 saved to ./RL_models_l/vtol_2D_ppo_200000.bson\n",
      "test reward at step 200000: 12.789661518615205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   8%|███▍                                     |  ETA: 0:58:16\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 210000: 6.380351286797615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   9%|███▋                                     |  ETA: 0:58:20\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 220000: 13.453735766390812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   9%|███▊                                     |  ETA: 0:57:25\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 230000: 20.484151326942875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  10%|███▉                                     |  ETA: 0:56:47\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 240000: 17.914847689059048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  10%|████▏                                    |  ETA: 0:55:59\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 250000: 7.955388812717698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  10%|████▎                                    |  ETA: 0:55:33\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 260000: 14.045059883096982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  11%|████▍                                    |  ETA: 0:54:50\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 270000: 19.759917015945856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  11%|████▋                                    |  ETA: 0:54:20\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 280000: 19.19878226883269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  12%|████▊                                    |  ETA: 0:54:03\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 290000: 10.065910922739258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  12%|████▉                                    |  ETA: 0:54:50\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 300000 saved to ./RL_models_l/vtol_2D_ppo_300000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:  12%|████▉                                    |  ETA: 0:55:14\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 300000: 19.800966683839782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  12%|█████▏                                   |  ETA: 0:54:27\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 310000: 21.07041791071029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  13%|█████▎                                   |  ETA: 0:53:56\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 320000: 13.98664213709119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  13%|█████▍                                   |  ETA: 0:53:32\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 330000: 25.048684549968918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  14%|█████▋                                   |  ETA: 0:53:04\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 340000: 27.242606795410808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  14%|█████▊                                   |  ETA: 0:52:37\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 350000: 20.64055280169691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  14%|█████▉                                   |  ETA: 0:52:11\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 360000: 26.91096956126021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  15%|██████                                   |  ETA: 0:51:44\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 370000: 18.96590350328218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  15%|██████▎                                  |  ETA: 0:51:23\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 380000: 20.348501653516365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  16%|██████▍                                  |  ETA: 0:51:03\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 390000: 18.955639725310487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  16%|██████▌                                  |  ETA: 0:50:44\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 400000 saved to ./RL_models_l/vtol_2D_ppo_400000.bson\n",
      "test reward at step 400000: 20.019592372525604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  16%|██████▋                                  |  ETA: 0:50:26\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 410000: 19.925146309316414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  17%|██████▉                                  |  ETA: 0:49:57\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 420000: 25.23151305942752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  17%|███████                                  |  ETA: 0:49:39\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 430000: 25.6399733007816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  17%|███████▏                                 |  ETA: 0:49:23\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 440000: 26.216386109216955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  18%|███████▍                                 |  ETA: 0:49:01\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 450000: 19.346485760185036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  18%|███████▌                                 |  ETA: 0:48:45\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 460000: 27.55443052975736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  19%|███████▊                                 |  ETA: 0:48:21\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 470000: 25.608368790660403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  19%|███████▉                                 |  ETA: 0:48:05\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 480000: 19.75195791489926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  20%|████████                                 |  ETA: 0:47:51\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 490000: 27.95483977817965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  20%|████████▏                                |  ETA: 0:47:31\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 500000 saved to ./RL_models_l/vtol_2D_ppo_500000.bson\n",
      "test reward at step 500000: 20.574078776491653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  20%|████████▍                                |  ETA: 0:47:24\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 510000: 20.22052678071417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  21%|████████▌                                |  ETA: 0:47:11\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 520000: 28.153795503870313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  21%|████████▋                                |  ETA: 0:46:51\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 530000: 19.71527752349343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  22%|████████▉                                |  ETA: 0:46:34\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 540000: 20.42391716295108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  22%|█████████                                |  ETA: 0:46:20\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 550000: 27.386721553193567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  22%|█████████▏                               |  ETA: 0:46:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 560000: 26.143074199322918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  23%|█████████▍                               |  ETA: 0:45:45\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 570000: 19.013402831977267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  23%|█████████▌                               |  ETA: 0:45:28\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 580000: 26.47253251070811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  24%|█████████▋                               |  ETA: 0:45:14\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 590000: 27.198811548275067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  24%|█████████▉                               |  ETA: 0:44:51\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 600000 saved to ./RL_models_l/vtol_2D_ppo_600000.bson\n",
      "test reward at step 600000: 27.111182298480067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  24%|██████████                               |  ETA: 0:44:38\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 610000: 24.99478515305399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  25%|██████████▏                              |  ETA: 0:44:12\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 620000: 26.916700593929626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  25%|██████████▍                              |  ETA: 0:43:50\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 630000: 21.412064700495293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  26%|██████████▌                              |  ETA: 0:43:34\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 640000: 19.275986443187314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  26%|██████████▋                              |  ETA: 0:43:23\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 650000: 26.32779524387442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  26%|██████████▉                              |  ETA: 0:43:05\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 660000: 26.749574639761857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  27%|███████████                              |  ETA: 0:42:46\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 670000: 13.652064800345846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  27%|███████████▏                             |  ETA: 0:42:25\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 680000: 28.60266939571685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  27%|███████████▎                             |  ETA: 0:42:12\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 690000: 24.735920060441316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  28%|███████████▌                             |  ETA: 0:41:46\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 700000 saved to ./RL_models_l/vtol_2D_ppo_700000.bson\n",
      "test reward at step 700000: 20.679693636416847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  28%|███████████▋                             |  ETA: 0:41:28\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 710000: 26.89802655078164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  29%|███████████▊                             |  ETA: 0:41:13\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 720000: 26.108703008144083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  29%|████████████                             |  ETA: 0:40:54\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 730000: 26.466276202885545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  30%|████████████▏                            |  ETA: 0:40:35\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 740000: 25.102349700256664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  30%|████████████▎                            |  ETA: 0:40:21\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 750000: 27.284073179887123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  30%|████████████▍                            |  ETA: 0:40:02\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 760000: 26.98417707934434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  31%|████████████▋                            |  ETA: 0:39:42\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 770000: 27.673763515403895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  31%|████████████▊                            |  ETA: 0:39:24\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 780000: 25.721409111077364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  32%|█████████████                            |  ETA: 0:39:03\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 790000: 25.677249319884037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  32%|█████████████▏                           |  ETA: 0:38:46\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 800000 saved to ./RL_models_l/vtol_2D_ppo_800000.bson\n",
      "test reward at step 800000: 26.572083896181375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  32%|█████████████▎                           |  ETA: 0:38:29\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 810000: 25.07372709806377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  33%|█████████████▍                           |  ETA: 0:38:15\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 820000: 25.052745190354287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  33%|█████████████▋                           |  ETA: 0:37:55\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 830000: 25.836066788837478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  34%|█████████████▊                           |  ETA: 0:37:42\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 840000: 25.65796769684878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  34%|█████████████▉                           |  ETA: 0:37:22\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 850000: 26.219478622212115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  34%|██████████████▏                          |  ETA: 0:37:08\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 860000: 25.880710821383083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  35%|██████████████▎                          |  ETA: 0:36:51\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 870000: 26.43043168357987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  35%|██████████████▍                          |  ETA: 0:36:34\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 880000: 26.324627446136972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  36%|██████████████▌                          |  ETA: 0:36:20\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 890000: 26.904271114195605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  36%|██████████████▊                          |  ETA: 0:36:01\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 900000 saved to ./RL_models_l/vtol_2D_ppo_900000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress:  36%|██████████████▊                          |  ETA: 0:36:17\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 900000: 22.56924221191377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  36%|██████████████▉                          |  ETA: 0:36:03\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 910000: 18.750106090665216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  37%|███████████████▏                         |  ETA: 0:35:44\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 920000: 27.35415019791108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  37%|███████████████▎                         |  ETA: 0:35:32\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 930000: 26.479374438057807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  38%|███████████████▍                         |  ETA: 0:35:12\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 940000: 25.592406137497665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  38%|███████████████▌                         |  ETA: 0:35:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 950000: 26.42444660814869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  38%|███████████████▊                         |  ETA: 0:34:40\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 960000: 29.494937491284986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  39%|███████████████▉                         |  ETA: 0:34:27\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 970000: 20.444654533332006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  39%|████████████████▏                        |  ETA: 0:34:08\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 980000: 27.139995244799476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  40%|████████████████▎                        |  ETA: 0:33:54\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 990000: 27.499250830120722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  40%|████████████████▍                        |  ETA: 0:33:39\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1000000 saved to ./RL_models_l/vtol_2D_ppo_1000000.bson\n",
      "test reward at step 1000000: 26.82413047308263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  40%|████████████████▌                        |  ETA: 0:33:22\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1010000: 25.419204615094017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  41%|████████████████▊                        |  ETA: 0:33:08\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1020000: 26.964239039585884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  41%|████████████████▉                        |  ETA: 0:32:51\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1030000: 29.114729921776387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  41%|█████████████████                        |  ETA: 0:32:39\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1040000: 25.682278990984077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  42%|█████████████████▎                       |  ETA: 0:32:20\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1050000: 19.680132137005476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  42%|█████████████████▍                       |  ETA: 0:32:07\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1060000: 25.02088738748911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  43%|█████████████████▌                       |  ETA: 0:31:51\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1070000: 27.666659728332768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  43%|█████████████████▊                       |  ETA: 0:31:35\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1080000: 25.92692008950941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  44%|█████████████████▉                       |  ETA: 0:31:19\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1090000: 27.257098842078296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  44%|██████████████████                       |  ETA: 0:31:05\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1100000 saved to ./RL_models_l/vtol_2D_ppo_1100000.bson\n",
      "test reward at step 1100000: 27.50632522503075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  44%|██████████████████▎                      |  ETA: 0:30:49\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1110000: 20.053793981912385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  45%|██████████████████▍                      |  ETA: 0:30:37\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1120000: 26.80260506199211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  45%|██████████████████▌                      |  ETA: 0:30:24\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1130000: 27.800492339670125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  46%|██████████████████▋                      |  ETA: 0:30:06\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1140000: 26.831957314905402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  46%|██████████████████▉                      |  ETA: 0:29:51\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1150000: 24.359420817772985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  46%|███████████████████                      |  ETA: 0:29:37\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1160000: 25.917175297206324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  47%|███████████████████▏                     |  ETA: 0:29:21\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1170000: 26.135189820052865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  47%|███████████████████▍                     |  ETA: 0:29:07\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1180000: 24.89585967984989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  48%|███████████████████▌                     |  ETA: 0:28:52\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1190000: 27.751804580297097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  48%|███████████████████▋                     |  ETA: 0:28:38\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1200000 saved to ./RL_models_l/vtol_2D_ppo_1200000.bson\n",
      "test reward at step 1200000: 27.584020164097918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  48%|███████████████████▉                     |  ETA: 0:28:24\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1210000: 18.42803488828104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  49%|████████████████████                     |  ETA: 0:28:11\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1220000: 26.07107381678913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  49%|████████████████████▏                    |  ETA: 0:27:58\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1230000: 27.722906733376487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  50%|████████████████████▍                    |  ETA: 0:27:44\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1240000: 28.706438635934195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  50%|████████████████████▌                    |  ETA: 0:27:29\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1250000: 26.211924091367173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  50%|████████████████████▋                    |  ETA: 0:27:14\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1260000: 27.497878721640177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  51%|████████████████████▊                    |  ETA: 0:27:02\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1270000: 25.24307369882336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  51%|█████████████████████                    |  ETA: 0:26:44\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1280000: 26.657697923509538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  52%|█████████████████████▏                   |  ETA: 0:26:30\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1290000: 26.487658188431396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  52%|█████████████████████▍                   |  ETA: 0:26:16\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1300000 saved to ./RL_models_l/vtol_2D_ppo_1300000.bson\n",
      "test reward at step 1300000: 13.57249108344246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  52%|█████████████████████▌                   |  ETA: 0:26:02\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1310000: 27.269530813971265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  53%|█████████████████████▋                   |  ETA: 0:25:48\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1320000: 25.0997488960494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  53%|█████████████████████▊                   |  ETA: 0:25:35\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1330000: 19.319132508363253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  54%|██████████████████████                   |  ETA: 0:25:21\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1340000: 26.08609638425186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  54%|██████████████████████▏                  |  ETA: 0:25:06\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1350000: 26.75957211563645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  54%|██████████████████████▎                  |  ETA: 0:24:52\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1360000: 27.4259578103612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  55%|██████████████████████▌                  |  ETA: 0:24:41\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1370000: 24.894839591148376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  55%|██████████████████████▋                  |  ETA: 0:24:25\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1380000: 26.569400529397214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  56%|██████████████████████▊                  |  ETA: 0:24:13\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1390000: 27.198699405648433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  56%|███████████████████████                  |  ETA: 0:23:59\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1400000 saved to ./RL_models_l/vtol_2D_ppo_1400000.bson\n",
      "test reward at step 1400000: 26.238218030391902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  56%|███████████████████████▏                 |  ETA: 0:23:46\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1410000: 25.30263019287169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  57%|███████████████████████▎                 |  ETA: 0:23:32\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1420000: 26.193346976978088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  57%|███████████████████████▍                 |  ETA: 0:23:20\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1430000: 26.264001116946535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  58%|███████████████████████▋                 |  ETA: 0:23:05\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1440000: 26.303780318105556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  58%|███████████████████████▊                 |  ETA: 0:22:51\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1450000: 25.471871286080717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  58%|███████████████████████▉                 |  ETA: 0:22:38\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1460000: 25.558345473844337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  59%|████████████████████████▏                |  ETA: 0:22:24\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1470000: 26.980428383120397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  59%|████████████████████████▎                |  ETA: 0:22:10\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1480000: 28.628544747231032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  60%|████████████████████████▍                |  ETA: 0:21:58\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1490000: 25.946903103784827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  60%|████████████████████████▋                |  ETA: 0:21:45\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1500000 saved to ./RL_models_l/vtol_2D_ppo_1500000.bson\n",
      "test reward at step 1500000: 25.939236167619946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  60%|████████████████████████▊                |  ETA: 0:21:30\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1510000: 27.657944123301647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  61%|████████████████████████▉                |  ETA: 0:21:16\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test reward at step 1520000: 26.330059739422985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  61%|█████████████████████████                |  ETA: 0:21:07\u001b[39m"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] Array",
      "    @ ./boot.jl:461 [inlined]",
      "  [2] Array",
      "    @ ./boot.jl:469 [inlined]",
      "  [3] similar",
      "    @ ./array.jl:378 [inlined]",
      "  [4] *",
      "    @ /opt/julia-1.8.0/share/julia/stdlib/v1.8/LinearAlgebra/src/matmul.jl:148 [inlined]",
      "  [5] (::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}})(x::Matrix{Float64})",
      "    @ Flux ~/.julia/packages/Flux/7nTyc/src/layers/basic.jl:158",
      "  [6] applychain (repeats 3 times)",
      "    @ ~/.julia/packages/Flux/7nTyc/src/layers/basic.jl:47 [inlined]",
      "  [7] (::Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})(x::Base.ReshapedArray{Float64, 2, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, Tuple{}})",
      "    @ Flux ~/.julia/packages/Flux/7nTyc/src/layers/basic.jl:49",
      "  [8] _update!(p::PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, t::Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}})",
      "    @ ReinforcementLearningZoo ~/.julia/packages/ReinforcementLearningZoo/tvfq9/src/algorithms/policy_gradient/ppo.jl:240",
      "  [9] update!",
      "    @ ~/.julia/packages/ReinforcementLearningZoo/tvfq9/src/algorithms/policy_gradient/ppo.jl:210 [inlined]",
      " [10] (::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}})(stage::PreActStage, env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing}, action::ReinforcementLearningZoo.EnrichedAction{Matrix{Float64}, NamedTuple{(:action_log_prob,), Tuple{Vector{Float64}}}})",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/yeRLW/src/policies/agents/agent.jl:78",
      " [11] _run(policy::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing}, stop_condition::StopAfterStep{ProgressMeter.Progress}, hook::ComposedHook{Tuple{DoEveryNStep{typeof(saveModel)}, DoEveryNStep{typeof(validate_policy)}}})",
      "    @ ReinforcementLearningZoo ~/.julia/packages/ReinforcementLearningZoo/tvfq9/src/algorithms/policy_gradient/run.jl:18",
      " [12] run(policy::Agent{PPOPolicy{ActorCritic{GaussianNetwork{Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, typeof(tanh)}, Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ADAM}, Normal, Random._GLOBAL_RNG}, Trajectory{NamedTuple{(:action_log_prob, :state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 3, Array{Float64, 3}}, CircularArrayBuffers.CircularArrayBuffer{Float64, 2, Matrix{Float64}}, CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}}}}}, env::MultiThreadEnv{VtolEnv{Space{Vector{ClosedInterval{Float64}}}, Float64, Vector{Float64}, StableRNGs.LehmerRNG}, Matrix{Float64}, Vector{Float64}, Space{Matrix{ClosedInterval{Float64}}}, Space{Matrix{ClosedInterval{Float64}}}, Nothing}, stop_condition::StopAfterStep{ProgressMeter.Progress}, hook::ComposedHook{Tuple{DoEveryNStep{typeof(saveModel)}, DoEveryNStep{typeof(validate_policy)}}})",
      "    @ ReinforcementLearningCore ~/.julia/packages/ReinforcementLearningCore/yeRLW/src/core/run.jl:10",
      " [13] top-level scope",
      "    @ In[22]:1",
      " [14] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [15] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both Losses and NNlib export \"ctc_loss\"; uses of it in module Flux must be qualified\n"
     ]
    }
   ],
   "source": [
    "ReinforcementLearning.run(\n",
    "    agent,\n",
    "    env,\n",
    "    StopAfterStep(2_500_000),\n",
    "    ComposedHook(\n",
    "        DoEveryNStep(saveModel, n=100_000), \n",
    "        DoEveryNStep(validate_policy, n=10_000)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49a302a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip200\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip200)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip201\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip200)\" d=\"\n",
       "M140.696 1486.45 L2352.76 1486.45 L2352.76 47.2441 L140.696 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip202\">\n",
       "    <rect x=\"140\" y=\"47\" width=\"2213\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  189.481,1486.45 189.481,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  880.491,1486.45 880.491,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1571.5,1486.45 1571.5,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2262.51,1486.45 2262.51,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  189.481,1486.45 189.481,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  880.491,1486.45 880.491,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1571.5,1486.45 1571.5,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2262.51,1486.45 2262.51,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip200)\" d=\"M189.481 1517.37 Q185.87 1517.37 184.041 1520.93 Q182.235 1524.47 182.235 1531.6 Q182.235 1538.71 184.041 1542.27 Q185.87 1545.82 189.481 1545.82 Q193.115 1545.82 194.921 1542.27 Q196.749 1538.71 196.749 1531.6 Q196.749 1524.47 194.921 1520.93 Q193.115 1517.37 189.481 1517.37 M189.481 1513.66 Q195.291 1513.66 198.347 1518.27 Q201.425 1522.85 201.425 1531.6 Q201.425 1540.33 198.347 1544.94 Q195.291 1549.52 189.481 1549.52 Q183.671 1549.52 180.592 1544.94 Q177.536 1540.33 177.536 1531.6 Q177.536 1522.85 180.592 1518.27 Q183.671 1513.66 189.481 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M855.19 1514.29 L873.546 1514.29 L873.546 1518.22 L859.472 1518.22 L859.472 1526.7 Q860.491 1526.35 861.509 1526.19 Q862.528 1526 863.546 1526 Q869.333 1526 872.713 1529.17 Q876.092 1532.34 876.092 1537.76 Q876.092 1543.34 872.62 1546.44 Q869.148 1549.52 862.829 1549.52 Q860.653 1549.52 858.384 1549.15 Q856.139 1548.78 853.731 1548.04 L853.731 1543.34 Q855.815 1544.47 858.037 1545.03 Q860.259 1545.58 862.736 1545.58 Q866.741 1545.58 869.079 1543.48 Q871.417 1541.37 871.417 1537.76 Q871.417 1534.15 869.079 1532.04 Q866.741 1529.94 862.736 1529.94 Q860.861 1529.94 858.986 1530.35 Q857.134 1530.77 855.19 1531.65 L855.19 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M895.305 1517.37 Q891.694 1517.37 889.866 1520.93 Q888.06 1524.47 888.06 1531.6 Q888.06 1538.71 889.866 1542.27 Q891.694 1545.82 895.305 1545.82 Q898.94 1545.82 900.745 1542.27 Q902.574 1538.71 902.574 1531.6 Q902.574 1524.47 900.745 1520.93 Q898.94 1517.37 895.305 1517.37 M895.305 1513.66 Q901.115 1513.66 904.171 1518.27 Q907.25 1522.85 907.25 1531.6 Q907.25 1540.33 904.171 1544.94 Q901.115 1549.52 895.305 1549.52 Q889.495 1549.52 886.416 1544.94 Q883.361 1540.33 883.361 1531.6 Q883.361 1522.85 886.416 1518.27 Q889.495 1513.66 895.305 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1531.11 1544.91 L1538.75 1544.91 L1538.75 1518.55 L1530.44 1520.21 L1530.44 1515.95 L1538.7 1514.29 L1543.38 1514.29 L1543.38 1544.91 L1551.01 1544.91 L1551.01 1548.85 L1531.11 1548.85 L1531.11 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1570.46 1517.37 Q1566.85 1517.37 1565.02 1520.93 Q1563.21 1524.47 1563.21 1531.6 Q1563.21 1538.71 1565.02 1542.27 Q1566.85 1545.82 1570.46 1545.82 Q1574.09 1545.82 1575.9 1542.27 Q1577.73 1538.71 1577.73 1531.6 Q1577.73 1524.47 1575.9 1520.93 Q1574.09 1517.37 1570.46 1517.37 M1570.46 1513.66 Q1576.27 1513.66 1579.32 1518.27 Q1582.4 1522.85 1582.4 1531.6 Q1582.4 1540.33 1579.32 1544.94 Q1576.27 1549.52 1570.46 1549.52 Q1564.65 1549.52 1561.57 1544.94 Q1558.51 1540.33 1558.51 1531.6 Q1558.51 1522.85 1561.57 1518.27 Q1564.65 1513.66 1570.46 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M1600.62 1517.37 Q1597.01 1517.37 1595.18 1520.93 Q1593.38 1524.47 1593.38 1531.6 Q1593.38 1538.71 1595.18 1542.27 Q1597.01 1545.82 1600.62 1545.82 Q1604.25 1545.82 1606.06 1542.27 Q1607.89 1538.71 1607.89 1531.6 Q1607.89 1524.47 1606.06 1520.93 Q1604.25 1517.37 1600.62 1517.37 M1600.62 1513.66 Q1606.43 1513.66 1609.49 1518.27 Q1612.56 1522.85 1612.56 1531.6 Q1612.56 1540.33 1609.49 1544.94 Q1606.43 1549.52 1600.62 1549.52 Q1594.81 1549.52 1591.73 1544.94 Q1588.68 1540.33 1588.68 1531.6 Q1588.68 1522.85 1591.73 1518.27 Q1594.81 1513.66 1600.62 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M2222.12 1544.91 L2229.76 1544.91 L2229.76 1518.55 L2221.45 1520.21 L2221.45 1515.95 L2229.71 1514.29 L2234.39 1514.29 L2234.39 1544.91 L2242.02 1544.91 L2242.02 1548.85 L2222.12 1548.85 L2222.12 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M2251.51 1514.29 L2269.87 1514.29 L2269.87 1518.22 L2255.8 1518.22 L2255.8 1526.7 Q2256.82 1526.35 2257.83 1526.19 Q2258.85 1526 2259.87 1526 Q2265.66 1526 2269.04 1529.17 Q2272.42 1532.34 2272.42 1537.76 Q2272.42 1543.34 2268.95 1546.44 Q2265.47 1549.52 2259.15 1549.52 Q2256.98 1549.52 2254.71 1549.15 Q2252.46 1548.78 2250.06 1548.04 L2250.06 1543.34 Q2252.14 1544.47 2254.36 1545.03 Q2256.58 1545.58 2259.06 1545.58 Q2263.07 1545.58 2265.4 1543.48 Q2267.74 1541.37 2267.74 1537.76 Q2267.74 1534.15 2265.4 1532.04 Q2263.07 1529.94 2259.06 1529.94 Q2257.19 1529.94 2255.31 1530.35 Q2253.46 1530.77 2251.51 1531.65 L2251.51 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M2291.63 1517.37 Q2288.02 1517.37 2286.19 1520.93 Q2284.38 1524.47 2284.38 1531.6 Q2284.38 1538.71 2286.19 1542.27 Q2288.02 1545.82 2291.63 1545.82 Q2295.26 1545.82 2297.07 1542.27 Q2298.9 1538.71 2298.9 1531.6 Q2298.9 1524.47 2297.07 1520.93 Q2295.26 1517.37 2291.63 1517.37 M2291.63 1513.66 Q2297.44 1513.66 2300.5 1518.27 Q2303.57 1522.85 2303.57 1531.6 Q2303.57 1540.33 2300.5 1544.94 Q2297.44 1549.52 2291.63 1549.52 Q2285.82 1549.52 2282.74 1544.94 Q2279.69 1540.33 2279.69 1531.6 Q2279.69 1522.85 2282.74 1518.27 Q2285.82 1513.66 2291.63 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,1355.92 2352.76,1355.92 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,926.034 2352.76,926.034 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,496.149 2352.76,496.149 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip202)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  140.696,66.2644 2352.76,66.2644 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1486.45 140.696,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,1355.92 159.593,1355.92 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,926.034 159.593,926.034 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,496.149 159.593,496.149 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  140.696,66.2644 159.593,66.2644 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip200)\" d=\"M92.7512 1341.72 Q89.1401 1341.72 87.3114 1345.28 Q85.5058 1348.82 85.5058 1355.95 Q85.5058 1363.06 87.3114 1366.63 Q89.1401 1370.17 92.7512 1370.17 Q96.3854 1370.17 98.1909 1366.63 Q100.02 1363.06 100.02 1355.95 Q100.02 1348.82 98.1909 1345.28 Q96.3854 1341.72 92.7512 1341.72 M92.7512 1338.01 Q98.5613 1338.01 101.617 1342.62 Q104.696 1347.2 104.696 1355.95 Q104.696 1364.68 101.617 1369.29 Q98.5613 1373.87 92.7512 1373.87 Q86.941 1373.87 83.8623 1369.29 Q80.8068 1364.68 80.8068 1355.95 Q80.8068 1347.2 83.8623 1342.62 Q86.941 1338.01 92.7512 1338.01 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M53.3995 939.379 L61.0384 939.379 L61.0384 913.014 L52.7282 914.68 L52.7282 910.421 L60.9921 908.754 L65.668 908.754 L65.668 939.379 L73.3068 939.379 L73.3068 943.314 L53.3995 943.314 L53.3995 939.379 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M92.7512 911.833 Q89.1401 911.833 87.3114 915.398 Q85.5058 918.939 85.5058 926.069 Q85.5058 933.175 87.3114 936.74 Q89.1401 940.282 92.7512 940.282 Q96.3854 940.282 98.1909 936.74 Q100.02 933.175 100.02 926.069 Q100.02 918.939 98.1909 915.398 Q96.3854 911.833 92.7512 911.833 M92.7512 908.129 Q98.5613 908.129 101.617 912.736 Q104.696 917.319 104.696 926.069 Q104.696 934.796 101.617 939.402 Q98.5613 943.986 92.7512 943.986 Q86.941 943.986 83.8623 939.402 Q80.8068 934.796 80.8068 926.069 Q80.8068 917.319 83.8623 912.736 Q86.941 908.129 92.7512 908.129 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M56.6171 509.494 L72.9365 509.494 L72.9365 513.429 L50.9921 513.429 L50.9921 509.494 Q53.6541 506.74 58.2375 502.11 Q62.8439 497.457 64.0245 496.115 Q66.2698 493.591 67.1494 491.855 Q68.0522 490.096 68.0522 488.406 Q68.0522 485.652 66.1078 483.916 Q64.1865 482.18 61.0847 482.18 Q58.8856 482.18 56.4319 482.943 Q54.0014 483.707 51.2236 485.258 L51.2236 480.536 Q54.0477 479.402 56.5014 478.823 Q58.955 478.244 60.9921 478.244 Q66.3624 478.244 69.5568 480.93 Q72.7513 483.615 72.7513 488.105 Q72.7513 490.235 71.9411 492.156 Q71.1541 494.054 69.0476 496.647 Q68.4689 497.318 65.367 500.536 Q62.2652 503.73 56.6171 509.494 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M92.7512 481.948 Q89.1401 481.948 87.3114 485.513 Q85.5058 489.054 85.5058 496.184 Q85.5058 503.291 87.3114 506.855 Q89.1401 510.397 92.7512 510.397 Q96.3854 510.397 98.1909 506.855 Q100.02 503.291 100.02 496.184 Q100.02 489.054 98.1909 485.513 Q96.3854 481.948 92.7512 481.948 M92.7512 478.244 Q98.5613 478.244 101.617 482.851 Q104.696 487.434 104.696 496.184 Q104.696 504.911 101.617 509.517 Q98.5613 514.101 92.7512 514.101 Q86.941 514.101 83.8623 509.517 Q80.8068 504.911 80.8068 496.184 Q80.8068 487.434 83.8623 482.851 Q86.941 478.244 92.7512 478.244 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M66.7559 64.9102 Q70.1124 65.6278 71.9874 67.8963 Q73.8855 70.1648 73.8855 73.4982 Q73.8855 78.6139 70.367 81.4148 Q66.8485 84.2157 60.3671 84.2157 Q58.1912 84.2157 55.8764 83.7759 Q53.5847 83.3592 51.131 82.5027 L51.131 77.9889 Q53.0754 79.1231 55.3903 79.7018 Q57.7051 80.2805 60.2282 80.2805 Q64.6263 80.2805 66.918 78.5444 Q69.2328 76.8083 69.2328 73.4982 Q69.2328 70.4426 67.08 68.7297 Q64.9504 66.9936 61.131 66.9936 L57.1032 66.9936 L57.1032 63.151 L61.3161 63.151 Q64.7652 63.151 66.5939 61.7853 Q68.4226 60.3964 68.4226 57.8038 Q68.4226 55.1418 66.5245 53.7297 Q64.6495 52.2946 61.131 52.2946 Q59.2097 52.2946 57.0106 52.7112 Q54.8115 53.1279 52.1727 54.0075 L52.1727 49.8409 Q54.8347 49.1001 57.1495 48.7298 Q59.4875 48.3594 61.5476 48.3594 Q66.8717 48.3594 69.9735 50.7899 Q73.0753 53.1973 73.0753 57.3177 Q73.0753 60.188 71.4318 62.1788 Q69.7883 64.1464 66.7559 64.9102 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M92.7512 52.0631 Q89.1401 52.0631 87.3114 55.6279 Q85.5058 59.1695 85.5058 66.2991 Q85.5058 73.4056 87.3114 76.9704 Q89.1401 80.512 92.7512 80.512 Q96.3854 80.512 98.1909 76.9704 Q100.02 73.4056 100.02 66.2991 Q100.02 59.1695 98.1909 55.6279 Q96.3854 52.0631 92.7512 52.0631 M92.7512 48.3594 Q98.5613 48.3594 101.617 52.9659 Q104.696 57.5492 104.696 66.2991 Q104.696 75.0259 101.617 79.6324 Q98.5613 84.2157 92.7512 84.2157 Q86.941 84.2157 83.8623 79.6324 Q80.8068 75.0259 80.8068 66.2991 Q80.8068 57.5492 83.8623 52.9659 Q86.941 48.3594 92.7512 48.3594 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip202)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  203.301,1445.72 217.121,1382.16 230.941,1017.88 244.762,479.226 258.582,1437.96 272.402,1438.67 286.222,1390.71 300.042,1433.97 313.863,1050.38 327.683,1169.52 \n",
       "  341.503,1263.41 355.323,1077.24 369.143,576.547 382.964,248.739 396.784,969.324 410.604,1255.24 424.424,862.006 438.244,1158.05 452.065,1060.43 465.885,806.111 \n",
       "  479.705,1081.64 493.525,777.563 507.345,475.336 521.166,585.787 534.986,1013.93 548.806,752.143 562.626,506.47 576.446,530.592 590.266,923.201 604.087,504.705 \n",
       "  617.907,450.134 631.727,754.655 645.547,279.114 659.367,184.801 673.188,468.613 687.008,199.057 700.828,540.604 714.648,481.168 728.468,541.045 742.289,495.307 \n",
       "  756.109,499.367 769.929,271.254 783.749,253.695 797.569,228.916 811.39,524.243 825.21,171.396 839.03,255.054 852.85,506.812 866.67,154.183 880.491,471.471 \n",
       "  894.311,486.669 908.131,145.63 921.951,508.389 935.771,477.926 949.592,178.605 963.412,232.068 977.232,538.562 991.052,217.905 1004.87,186.683 1018.69,190.45 \n",
       "  1032.51,281.431 1046.33,198.811 1060.15,435.447 1073.97,527.274 1087.79,224.127 1101.61,205.995 1115.43,769.038 1129.25,126.334 1143.07,292.559 1156.89,466.93 \n",
       "  1170.71,199.614 1184.53,233.545 1198.36,218.174 1212.18,276.807 1226,183.018 1239.82,195.91 1253.64,166.266 1267.46,250.195 1281.28,252.093 1295.1,213.625 \n",
       "  1308.92,278.037 1322.74,278.939 1336.56,245.266 1350.38,252.922 1364.2,228.783 1378.02,243.346 1391.84,219.715 1405.66,224.263 1419.48,199.345 1433.3,385.701 \n",
       "  1447.12,549.88 1460.94,180.006 1474.76,217.611 1488.58,255.74 1502.4,219.972 1516.22,87.9763 1530.04,477.034 1543.86,189.212 1557.68,173.768 1571.5,202.79 \n",
       "  1585.32,263.186 1599.14,196.767 1612.96,104.321 1626.78,251.877 1640.6,509.9 1654.42,280.309 1668.24,166.571 1682.06,241.36 1695.88,184.178 1709.7,173.464 \n",
       "  1723.52,493.837 1737.34,203.716 1751.16,160.818 1764.98,202.454 1778.8,308.744 1792.62,241.779 1806.44,232.407 1820.26,285.684 1834.08,162.911 1847.9,170.124 \n",
       "  1861.72,563.726 1875.54,235.163 1889.36,164.153 1903.18,121.873 1917.01,229.108 1930.83,173.827 1944.65,270.758 1958.47,209.945 1972.29,217.255 1986.11,772.458 \n",
       "  1999.93,183.643 2013.75,276.919 2027.57,525.419 2041.39,234.517 2055.21,205.566 2069.03,176.919 2082.85,285.728 2096.67,213.741 2110.49,186.688 2124.31,227.978 \n",
       "  2138.13,268.197 2151.95,229.907 2165.77,226.869 2179.59,225.159 2193.41,260.922 2207.23,257.204 2221.05,196.071 2234.87,125.221 2248.69,240.501 2262.51,240.831 \n",
       "  2276.33,166.946 2290.15,224.03 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip200)\" d=\"\n",
       "M1980.81 198.898 L2279.02 198.898 L2279.02 95.2176 L1980.81 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1980.81,198.898 2279.02,198.898 2279.02,95.2176 1980.81,95.2176 1980.81,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip200)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2005.38,147.058 2152.85,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip200)\" d=\"M2191.28 166.745 Q2189.47 171.375 2187.76 172.787 Q2186.04 174.199 2183.17 174.199 L2179.77 174.199 L2179.77 170.634 L2182.27 170.634 Q2184.03 170.634 2185 169.8 Q2185.98 168.967 2187.16 165.865 L2187.92 163.921 L2177.43 138.412 L2181.95 138.412 L2190.05 158.689 L2198.15 138.412 L2202.66 138.412 L2191.28 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip200)\" d=\"M2209.96 160.402 L2217.6 160.402 L2217.6 134.037 L2209.29 135.703 L2209.29 131.444 L2217.55 129.778 L2222.22 129.778 L2222.22 160.402 L2229.86 160.402 L2229.86 164.338 L2209.96 164.338 L2209.96 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(episode_test_reward_hook.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb0d4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_visualization(); # closes the MeshCat visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32382330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
