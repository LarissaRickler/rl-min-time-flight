{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649b76a",
   "metadata": {},
   "source": [
    "# Init Bionic VTOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96751412",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: ArgumentError: Package Rotations [6038ab10-8711-5258-84ad-4b1120ba62dc] is required but does not seem to be installed:\n - Run `Pkg.instantiate()` to install all recorded dependencies.\n\nin expression starting at /home/larissa/Documents/Projects/Advanced Deep Learning for Robotics/ADLR_template/src/CrazyflieController.jl:1\nin expression starting at /home/larissa/Documents/Projects/Advanced Deep Learning for Robotics/ADLR_template/src/Flyonic.jl:1",
     "output_type": "error",
     "traceback": [
      "LoadError: ArgumentError: Package Rotations [6038ab10-8711-5258-84ad-4b1120ba62dc] is required but does not seem to be installed:\n - Run `Pkg.instantiate()` to install all recorded dependencies.\n\nin expression starting at /home/larissa/Documents/Projects/Advanced Deep Learning for Robotics/ADLR_template/src/CrazyflieController.jl:1\nin expression starting at /home/larissa/Documents/Projects/Advanced Deep Learning for Robotics/ADLR_template/src/Flyonic.jl:1",
      "",
      "Stacktrace:",
      "  [1] _require(pkg::Base.PkgId)",
      "    @ Base ./loading.jl:1306",
      "  [2] _require_prelocked(uuidkey::Base.PkgId)",
      "    @ Base ./loading.jl:1200",
      "  [3] macro expansion",
      "    @ ./loading.jl:1180 [inlined]",
      "  [4] macro expansion",
      "    @ ./lock.jl:223 [inlined]",
      "  [5] require(into::Module, mod::Symbol)",
      "    @ Base ./loading.jl:1144",
      "  [6] include(mod::Module, _path::String)",
      "    @ Base ./Base.jl:419",
      "  [7] include(x::String)",
      "    @ Main.Flyonic ~/Documents/Projects/Advanced Deep Learning for Robotics/ADLR_template/src/Flyonic.jl:1",
      "  [8] top-level scope",
      "    @ ~/Documents/Projects/Advanced Deep Learning for Robotics/ADLR_template/src/Flyonic.jl:5",
      "  [9] include(fname::String)",
      "    @ Base.MainInclude ./client.jl:476",
      " [10] top-level scope",
      "    @ In[1]:1"
     ]
    }
   ],
   "source": [
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position\n",
    "\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;\n",
    "using Distributions;\n",
    "\n",
    "using Plots;\n",
    "using Statistics;\n",
    "\n",
    "using TensorBoardLogger\n",
    "using Logging\n",
    "\n",
    "using BSON: @save, @load # save mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e4ee64",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: create_visualization not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: create_visualization not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[2]:1"
     ]
    }
   ],
   "source": [
    "create_visualization();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19cce80",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: TBLogger not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: TBLogger not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[3]:2"
     ]
    }
   ],
   "source": [
    "# TensorBoard\n",
    "logger = TBLogger(\"tensorboard_PPO\", tb_increment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9557df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indicates how many threads Julia was started with. This is important for the multi-threaded environment\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d945ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Δt = 0.025;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411db62",
   "metadata": {},
   "source": [
    "# Create Reinforcement Learning Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96af6ee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: AbstractRNG not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: AbstractRNG not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[6]:1"
     ]
    }
   ],
   "source": [
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv # Parametric Constructor for a subtype of AbstractEnv\n",
    "    action_space::A # All possible actions the agent can take\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}} # All possible states that the agent can observe.\n",
    "    state::Vector{T} # Current state\n",
    "    action::ACT # next action the agent wants to apply in the environment.\n",
    "    done::Bool # shows whether a terminal condition has been reached.\n",
    "    t::T # time\n",
    "    rng::R # random number generator\n",
    "\n",
    "    name::String # for different naming of multible environoments\n",
    "    visualization::Bool # activate visualisation (Faster computation without visualisation)\n",
    "    worldtime::Bool # visualization in \"real-world\" time (only for watching or filming).\n",
    "    \n",
    "    # Overall state of the environment. This does not correspond to the observation space of the agent but contains all states that describe the environment.\n",
    "    x_W::Vector{T} # Position in World frame\n",
    "    v_B::Vector{T} # Velocity in Body frame\n",
    "    R_W::Matrix{T} # Rotation (matrix) in World frame\n",
    "    ω_B::Vector{T} # Rotation velocity in Body frame\n",
    "    wind_W::Vector{T} # Externel linear velocity acting on the drone\n",
    "    Δt::T # Time step for physics simulation in seconds\n",
    "    v_W_target::Vector{T} # Target Velocity in World frame\n",
    "    \n",
    "    current_action::Vector{T}\n",
    "    last_action::Vector{T}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a6873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a keyword-based constructor for the type declared in the mutable struct typedef. \n",
    "# It could also be done with the macro Base.@kwdef.\n",
    "function VtolEnv(;\n",
    "    rng = Random.GLOBAL_RNG, # Random number generation\n",
    "    name = \"Crazyflie\",\n",
    "    visualization = false,\n",
    "    worldtime = false,\n",
    "    kwargs... # let the function take an arbitrary number of keyword arguments\n",
    ")\n",
    "    \n",
    "    T = Float64; # explicit type which is used e.g. in state. Cannot be altered due to the poor matrix defininon.\n",
    "    \n",
    "    # final PWM Values for Crazyflie. The interval definition has no effect in the current implementation.\n",
    "    action_space = Space(\n",
    "        ClosedInterval{T}[\n",
    "            0..1#0..65535, # motor 1\n",
    "            0..1#0..65535, # motor 2\n",
    "            0..1#0..65535, # motor 3\n",
    "            0..1#0..65535, # motor 4\n",
    "            ], \n",
    "    )\n",
    "\n",
    "    \n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            typemin(T)..typemax(T), # 1  World Vector UP x\n",
    "            typemin(T)..typemax(T), # 2  World Vector UP y\n",
    "            typemin(T)..typemax(T), # 3  World Vector UP z\n",
    "            typemin(T)..typemax(T), # 4  World Vector FRONT x\n",
    "            typemin(T)..typemax(T), # 5  World Vector FRONT y\n",
    "            typemin(T)..typemax(T), # 6  World Vector FRONT z\n",
    "            \n",
    "            typemin(T)..typemax(T), # 7  Body target velocity along x\n",
    "            typemin(T)..typemax(T), # 8  Body target velocity along y\n",
    "            typemin(T)..typemax(T), # 9  Body target velocity along z\n",
    "           \n",
    "            typemin(T)..typemax(T), # 10 Body velocity along x\n",
    "            typemin(T)..typemax(T), # 11 Body velocity along y\n",
    "            typemin(T)..typemax(T), # 12 Body velocity along z\n",
    "            \n",
    "            typemin(T)..typemax(T), # 13 Body rotational velocity around x\n",
    "            typemin(T)..typemax(T), # 14 Body rotational velocity around y\n",
    "            typemin(T)..typemax(T), # 15 Body rotational velocity around z\n",
    "            ], \n",
    "    )\n",
    "    \n",
    "    if visualization\n",
    "        create_Crazyflie(name, actuators = true);\n",
    "        set_Crazyflie_actuators(name, [0.0; 0.0; 0.0; 0.0]);\n",
    "        set_transform(name, [0.0; 0.0; 0.0] ,one(QuatRotation));\n",
    "        set_arrow(string(name, \"_vel\"), color_vec=[0.0; 1.0; 0.0; 1.0]);\n",
    "        transform_arrow(string(name, \"_vel\"), [0.0; 0.0; 0.0], [0.0; 0.0; 1.0], max_head_radius=0.05)\n",
    "        set_arrow(string(name, \"_vel_current\"), color_vec=[1.0; 0.0; 0.0; 1.0]);\n",
    "        transform_arrow(string(name, \"_vel_current\"), [0.0; 0.0; 0.0], [0.0; 0.0; 1.0], max_head_radius=0.02)                  \n",
    "    end\n",
    "    \n",
    "\n",
    "\n",
    "    environment = VtolEnv(\n",
    "        action_space,\n",
    "        state_space,\n",
    "        zeros(T, length(state_space)), # current state, needs to be extended.\n",
    "        [0.25; 0.25; 0.25; 0.25],#rand(action_space),\n",
    "        false, # episode done ?\n",
    "        0.0, # time\n",
    "        rng, # random number generator  \n",
    "        name,\n",
    "        visualization,\n",
    "        worldtime,\n",
    "        zeros(T, 3), # x_W\n",
    "        zeros(T, 3), # v_B\n",
    "        Matrix(one(QuatRotation)), # Float64... so T needs to be Float64\n",
    "        zeros(T, 3), # ω_B\n",
    "        zeros(T, 3), # wind_W\n",
    "        Δt, # Δt\n",
    "        zeros(T, 3), # v_W_Target\n",
    "        [0.25; 0.25; 0.25; 0.25], # current PWM (for reward)\n",
    "        [0.25; 0.25; 0.25; 0.25], # last PWM (for reward)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    RLBase.reset!(environment)\n",
    "    \n",
    "    return environment\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec660d5e",
   "metadata": {},
   "source": [
    "Just for explanation:\n",
    "\n",
    "1. A mutable Struct is created. A struct is a constructor and a constructor is a function that creates new objects.\n",
    "2. A outer keyword-based constructor method is added for the type declared in the mutable struct typedef before.\n",
    "\n",
    "So now we have a function with two methods. Julia will decide which method to call by multiple dispatch."
   ]
  },
  {
   "cell_type": "raw",
   "id": "23dd4047",
   "metadata": {},
   "source": [
    "methods(VtolEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806413d1",
   "metadata": {},
   "source": [
    "# Define the RL interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f822029",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: Random not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Random not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[8]:1"
     ]
    }
   ],
   "source": [
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7fb89c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "TypeError: in Type{...} expression, expected UnionAll, got a value of type typeof(VtolEnv)",
     "output_type": "error",
     "traceback": [
      "TypeError: in Type{...} expression, expected UnionAll, got a value of type typeof(VtolEnv)",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[9]:1"
     ]
    }
   ],
   "source": [
    "function computeReward(env::VtolEnv{A,T}) where {A,T}\n",
    "    \n",
    "    stay_alive = 10.0\n",
    "    \n",
    "    upright_orientation = env.state[3]*10.0 # World Vector UP z (1 = upright)\n",
    "    Body_velocity = norm(env.v_B .- transpose(env.R_W)*env.v_W_target)*20.0 # Body velocity \n",
    "    \n",
    "    \n",
    "    thrust_change = norm(env.current_action .- env.last_action)*20.0    \n",
    "    thrust_balance = std(env.current_action)*40.0\n",
    "\n",
    "    \n",
    "    return (stay_alive - Body_velocity-thrust_balance)/80.0\n",
    "end\n",
    "\n",
    "\n",
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = computeReward(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae45ec04",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: RLBase not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: RLBase not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[10]:1"
     ]
    }
   ],
   "source": [
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    \n",
    "    targetVel = [0.0; 0.0; 0.0];\n",
    "    initialVel = [0.0; 0.0; 0.0];\n",
    "    \n",
    "    env.v_W_target = targetVel;\n",
    "    v_B_target = transpose(env.R_W)*env.v_W_target\n",
    "    env.x_W = [0.0; 0.0; 0.0];\n",
    "    env.v_B = initialVel;\n",
    "    env.R_W = Matrix(one(QuatRotation)); # Identity matrix (no rotation)\n",
    "    env.ω_B = [0.0; 0.0; 0.0];\n",
    "    env.wind_W = [0.0; 0.0; 0.0];\n",
    "        \n",
    " \n",
    "    env.state = [env.R_W[1,3]; # 1  World Vector UP x\n",
    "                 env.R_W[2,3]; # 2  World Vector UP y\n",
    "                 env.R_W[3,3]; # 3  World Vector UP z\n",
    "                 env.R_W[1,1]; # 4  World Vector FRONT x\n",
    "                 env.R_W[2,1]; # 5  World Vector FRONT y\n",
    "                 env.R_W[3,1]; # 6  World Vector FRONT z\n",
    "                 v_B_target[1]; # 7  Body target velocity along x\n",
    "                 v_B_target[2]; # 8  Body target velocity along y\n",
    "                 v_B_target[3]; # 9  Body target velocity along z\n",
    "                 env.v_B[1]; #  10  Body velocity along x\n",
    "                 env.v_B[2]; #  11  Body velocity along y\n",
    "                 env.v_B[3]; #  12  Body velocity along z\n",
    "                 env.ω_B[1]; #  13  Body rotational velocity around x\n",
    "                 env.ω_B[2]; #  14  Body rotational velocity around y\n",
    "                 env.ω_B[3]] #  15  Body rotational velocity around z\n",
    "    \n",
    "    env.t = 0.0; # time 0s\n",
    "    env.action = [0.25; 0.25; 0.25; 0.25] # normalized\n",
    "    env.last_action = [0.255; 0.255; 0.255; 0.255] # normalized\n",
    "    env.current_action = [0.255; 0.255; 0.255; 0.255] # normalized\n",
    "\n",
    "    env.done = false # reset termination\n",
    "    \n",
    "    if env.visualization\n",
    "        # Visualize initial state\n",
    "        set_transform(env.name, env.x_W,QuatRotation(env.R_W));\n",
    "        set_Crazyflie_actuators(env.name, [0.0; 0.0; 0.0; 0.0]);\n",
    "        transform_arrow(string(env.name, \"_vel\"), env.x_W, env.v_W_target, max_head_radius=0.05) \n",
    "        transform_arrow(string(env.name, \"_vel_current\"), env.x_W, [0.0; 0.0; 0.0], max_head_radius=0.05) \n",
    "    end\n",
    "    \n",
    "    nothing # return nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf1a7b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "function type in method definition is not a type",
     "output_type": "error",
     "traceback": [
      "function type in method definition is not a type",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[11]:3"
     ]
    }
   ],
   "source": [
    "# defines a methods for a callable object.\n",
    "# So when a VtolEnv object is created, it has this method that can be called\n",
    "function (env::VtolEnv)(a)\n",
    "\n",
    "\n",
    "    # call the step on the environoment with the next action \n",
    "    _step!(env, a)\n",
    "        \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26a5a0da",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: Random not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Random not defined",
      "",
      "Stacktrace:",
      " [1] VtolEnv()",
      "   @ Main ./In[7]:3",
      " [2] top-level scope",
      "   @ In[12]:1"
     ]
    }
   ],
   "source": [
    "env = VtolEnv();"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff8f68a7",
   "metadata": {},
   "source": [
    "methods(env) # Just to explain which methods the object has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4d67302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scale_actions (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function scale_actions(next_action)\n",
    "    return next_action*22000.0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7d4727",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: invalid type for argument env in method definition for _step! at In[14]:1",
     "output_type": "error",
     "traceback": [
      "ArgumentError: invalid type for argument env in method definition for _step! at In[14]:1",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[14]:1"
     ]
    }
   ],
   "source": [
    "function _step!(env::VtolEnv, next_action)\n",
    "    \n",
    "\n",
    "    env.last_action = copy(env.current_action)\n",
    "    env.current_action[1] = next_action[1]\n",
    "    env.current_action[2] = next_action[2]\n",
    "    env.current_action[3] = next_action[3]\n",
    "    env.current_action[4] = next_action[4]\n",
    "    \n",
    "    \n",
    "    \n",
    "    scaled_actions = scale_actions.(next_action) # between 0 and 1 for neual network\n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(env.v_B, env.R_W, env.wind_W)\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = crazyflie_model(scaled_actions);\n",
    "    # integrate rigid body dynamics for Δt\n",
    "    env.x_W, env.v_B, _, env.R_W, env.ω_B, _, env.t = rigid_body_simple(torque_B, force_B, env.x_W, env.v_B, env.R_W, env.ω_B, env.t, env.Δt, crazyflie_param)\n",
    "\n",
    "    \n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W,QuatRotation(env.R_W));\n",
    "        set_Crazyflie_actuators(env.name, next_action[1:4])\n",
    "        transform_arrow(string(env.name, \"_vel\"), env.x_W, env.v_W_target, max_head_radius=0.05)               \n",
    "        transform_arrow(string(env.name, \"_vel_current\"), env.x_W, env.R_W*env.v_B, max_head_radius=0.05) \n",
    "    end\n",
    "    \n",
    "    if env.worldtime\n",
    "        sleep(env.Δt)\n",
    "    end\n",
    "    \n",
    "    v_B_target = transpose(env.R_W)*env.v_W_target\n",
    "    \n",
    "    \n",
    "    # State space\n",
    "    env.state = [env.R_W[1,3]; # 1  World Vector UP x\n",
    "                 env.R_W[2,3]; # 2  World Vector UP y\n",
    "                 env.R_W[3,3]; # 3  World Vector UP z\n",
    "                 env.R_W[1,1]; # 4  World Vector FRONT x\n",
    "                 env.R_W[2,1]; # 5  World Vector FRONT y\n",
    "                 env.R_W[3,1]; # 6  World Vector FRONT z\n",
    "                 v_B_target[1]; # 7  Body target velocity along x\n",
    "                 v_B_target[2]; # 8  Body target velocity along y\n",
    "                 v_B_target[3]; # 9  Body target velocity along z\n",
    "                 env.v_B[1]; # 10  Body velocity along x\n",
    "                 env.v_B[2]; # 11  Body velocity along y\n",
    "                 env.v_B[3]; # 12  Body velocity along z\n",
    "                 env.ω_B[1]; # 13 Body rotational velocity around x\n",
    "                 env.ω_B[2]; # 14 Body rotational velocity around y\n",
    "                 env.ω_B[3]] # 15 Body rotational velocity around z\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Termination criteria\n",
    "    env.done =\n",
    "        norm(env.v_B) > 20.0 || # m/sec stop if body is to fast\n",
    "        norm(env.ω_B) > 40.0 || # rad/sec stop if body rotatesto fast\n",
    "        env.R_W[3,3] < 0.7 || # Stop if the drone is pitched/rolled to muche\n",
    "        env.t > 4.0 # stop after 10s\n",
    "        \n",
    "    nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e1cd988",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: RLBase not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: RLBase not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[15]:1"
     ]
    }
   ],
   "source": [
    "RLBase.test_runnable!(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223a31f",
   "metadata": {},
   "source": [
    "Show an overview of the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6de74",
   "metadata": {},
   "source": [
    "# Setup of a reinforcement learning experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5683fe8",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: StableRNG not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: StableRNG not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[16]:2"
     ]
    }
   ],
   "source": [
    "seed = 123    \n",
    "rng = StableRNG(seed)\n",
    "N_ENV = 8\n",
    "UPDATE_FREQ = 1024\n",
    "EVALUATION_FREQ = 10_000\n",
    "SAVE_FREQ = 100_000\n",
    "\n",
    "    \n",
    "    \n",
    "    # define multiple environments for parallel training\n",
    "    env = MultiThreadEnv([\n",
    "        # use different names for the visualization\n",
    "        VtolEnv(; rng = StableRNG(hash(seed+i)), name = \"cf_PPO$i\") for i in 1:N_ENV\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1f128b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: env not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: env not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[17]:2"
     ]
    }
   ],
   "source": [
    "# Define the function approximator\n",
    "    ns, na = length(state(env[1])), length(action_space(env[1]))\n",
    "    approximator = ActorCritic(\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                    Dense(ns, 64, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(64, 32, relu; initW = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(Dense(32, na; initW = glorot_uniform(rng))),\n",
    "                    logσ = Chain(Dense(32, na; initW = glorot_uniform(rng))),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 64, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(64, 32, relu; initW = glorot_uniform(rng)),\n",
    "                    Dense(32, 1; initW = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(1e-4),\n",
    "            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ea4c37c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: approximator not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: approximator not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[18]:1"
     ]
    }
   ],
   "source": [
    "    agent = Agent( # A wrapper of an AbstractPolicy\n",
    "         \n",
    "\n",
    "        # AbstractPolicy: the policy to use\n",
    "        policy = PPOPolicy(;\n",
    "                    approximator = approximator |> cpu,\n",
    "                    update_freq=UPDATE_FREQ,\n",
    "                    dist = Normal,\n",
    "                    # For parameters visit the docu: https://juliareinforcementlearning.org/docs/rlzoo/#ReinforcementLearningZoo.PPOPolicy\n",
    "                    ),\n",
    "        \n",
    "        # AbstractTrajectory: used to store transitions between an agent and an environment source\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float64} => (ns, N_ENV),\n",
    "            action = Matrix{Float64} => (na, N_ENV),\n",
    "            action_log_prob = Vector{Float64} => (N_ENV,),\n",
    "            reward = Vector{Float64} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f158a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @save not defined\nin expression starting at In[19]:4",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @save not defined\nin expression starting at In[19]:4",
      ""
     ]
    }
   ],
   "source": [
    "function saveModel(t, agent, env)\n",
    "    model = cpu(agent.policy.approximator)   \n",
    "    f = joinpath(\"./\", \"cf_ppo_$t.bson\")\n",
    "    @save f model\n",
    "    println(\"parameters at step $t saved to $f\")\n",
    "end"
   ]
  },
  {
   "cell_type": "raw",
   "id": "301a9bd8",
   "metadata": {},
   "source": [
    "function loadModel()\n",
    "    f = joinpath(\"./\", \"model.bson\")\n",
    "    @load f model\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "raw",
   "id": "174f8124",
   "metadata": {},
   "source": [
    "agent.policy.approximator = loadModel();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7470f200",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: TotalRewardPerEpisode not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: TotalRewardPerEpisode not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[20]:20"
     ]
    }
   ],
   "source": [
    "function validate_policy(t, agent, env)\n",
    "    # for validation extract the policy from the agend\n",
    "    run(agent.policy, test_env, StopAfterEpisode(1), \n",
    "        ComposedHook(\n",
    "        episode_test_step_hook, \n",
    "        episode_test_reward_hook\n",
    "    ),\n",
    "        )\n",
    "    # the result of the hook\n",
    "    reward = round((episode_test_reward_hook.rewards[end]),digits = 3)\n",
    "    length = episode_test_step_hook.steps[end-1]\n",
    "    \n",
    "    println(\"step: \", t, \" reward : \",reward, \" length: \", length)\n",
    "\n",
    "    with_logger(logger) do\n",
    "        @info \"evaluating\" avg_length = length  avg_reward = reward  log_step_increment = 0\n",
    "    end\n",
    "    end;\n",
    "\n",
    "episode_test_reward_hook = TotalRewardPerEpisode( is_display_on_exit=false)\n",
    "episode_test_step_hook = StepsPerEpisode()\n",
    "# create a env only for reward test\n",
    "\n",
    "test_env = VtolEnv(;name = \"test_cf\", visualization = true, worldtime = true);\n",
    "#test_env = VtolEnv(;name = \"test_cf\", visualization = false, worldtime = false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6aadbfce",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: TotalBatchRewardPerEpisode not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: TotalBatchRewardPerEpisode not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[21]:2"
     ]
    }
   ],
   "source": [
    "# Define hook which is called during the training\n",
    "total_batch_reward_per_episode = TotalBatchRewardPerEpisode(N_ENV, is_display_on_exit = false)\n",
    "hook = ComposedHook(\n",
    "    total_batch_reward_per_episode,\n",
    "    DoEveryNStep(saveModel, n=SAVE_FREQ),\n",
    "    DoEveryNStep(validate_policy, n=EVALUATION_FREQ),\n",
    "    #=\n",
    "    DoEveryNStep() do t, agent, env\n",
    "        p = agent.policy\n",
    "        with_logger(logger) do\n",
    "            @info \"training\" loss = mean(p.loss)  actor_loss = mean(p.actor_loss)  critic_loss = mean(p.critic_loss)\n",
    "        end\n",
    "    end,\n",
    "    =#\n",
    "    DoEveryNStep() do t, agent, env\n",
    "        with_logger(logger) do\n",
    "            rewards = [\n",
    "                total_batch_reward_per_episode.rewards[i][end] for i in 1:length(env)  if is_terminated(env[i])\n",
    "                    ]\n",
    "            if length(rewards) > 0\n",
    "                @info \"training\" reward = mean(rewards)\n",
    "            end\n",
    "        end\n",
    "    end,\n",
    "    #=\n",
    "    DoEveryNStep() do t, agent, env\n",
    "        with_logger(logger) do\n",
    "            @info \"training\" action_thrust_1 = env[1].action[1]  action_thrust_2 = env[1].action[2] action_thrust_3 = env[1].action[3] action_thrust_4 = env[1].action[4]\n",
    "        end\n",
    "    end,\n",
    "    =#\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45dfdb68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: StopAfterStep not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: StopAfterStep not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[22]:1"
     ]
    }
   ],
   "source": [
    "run(agent,\n",
    "    env,\n",
    "    StopAfterStep(1_000_000),\n",
    "    hook\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21a5d7b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: episode_test_reward_hook not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: episode_test_reward_hook not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[23]:1"
     ]
    }
   ],
   "source": [
    "plot(episode_test_reward_hook.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41c1dc36",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: episode_test_step_hook not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: episode_test_step_hook not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[24]:1"
     ]
    }
   ],
   "source": [
    "plot(episode_test_step_hook.steps[1:2:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71e5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
