{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f85185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "if isfile(\"../Project.toml\") && isfile(\"../Manifest.toml\")\n",
    "    Pkg.activate(\".\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0649b76a",
   "metadata": {},
   "source": [
    "# Init Bionic VTOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96751412",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../Flyonic.jl\");\n",
    "using .Flyonic;\n",
    "\n",
    "using Rotations; # used for initial position\n",
    "\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Random;\n",
    "using IntervalSets;\n",
    "using LinearAlgebra;\n",
    "using Distributions;\n",
    "\n",
    "using Plots;\n",
    "using Statistics;\n",
    "\n",
    "using TensorBoardLogger\n",
    "using Logging\n",
    "\n",
    "using JLD;\n",
    "using BSON: @save, @load # save mode\n",
    "using BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "917bb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set as desired\n",
    "R_TOL = 0.5;\n",
    "N_WAYPOINTS = 4; # including startpoint, >= 2\n",
    "SLOW_MODE = true;\n",
    "TRAINING = true;\n",
    "EVALUATION = true;\n",
    "VIDEO = false;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9745c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of steps\n",
    "steps_slow = 80_000_000\n",
    "steps_fast = 80_000_000\n",
    "load_from_slow_step = 80_000_000 # TODO: choose slow model\n",
    "\n",
    "save_freq = 100_000\n",
    "validate_freq = 100_000\n",
    "\n",
    "steps = 0\n",
    "if SLOW_MODE\n",
    "    steps = steps_slow\n",
    "else\n",
    "    steps = steps_fast\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93c2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crazyflie_param[\"gravity\"] = 0.0; # debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e4ee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mhttp://127.0.0.1:8701\n"
     ]
    }
   ],
   "source": [
    "create_visualization();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e19cce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TBLogger:\n",
       "\t- Log level     : Info\n",
       "\t- Current step  : 0\n",
       "\t- Output        : /home/larissa/Documents/Projects/ADLR/ADLR_project/src/RL_3D_quadcopter_SAC/tensorboard_SAC\n",
       "\t- open files    : 1\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorBoard\n",
    "if TRAINING\n",
    "    logger = TBLogger(\"tensorboard_SAC\", tb_increment)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d9557df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indicates how many threads Julia was started with. This is important for the multi-threaded environment\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d945ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Δt = 0.025;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411db62",
   "metadata": {},
   "source": [
    "# Create Reinforcement Learning Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96af6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct VtolEnv{A,T,ACT,R<:AbstractRNG} <: AbstractEnv # Parametric Constructor for a subtype of AbstractEnv\n",
    "    action_space::A # All possible actions the agent can take\n",
    "    observation_space::Space{Vector{ClosedInterval{T}}} # All possible states that the agent can observe.\n",
    "    state::Vector{T} # Current state\n",
    "    action::ACT # next action the agent wants to apply in the environment.\n",
    "    done::Bool # shows whether a terminal condition has been reached.\n",
    "    t::T # time\n",
    "    rng::R # random number generator\n",
    "\n",
    "    name::String # for different naming of multible environoments\n",
    "    visualization::Bool # activate visualisation (Faster computation without visualisation)\n",
    "    realtime::Bool # visualization in \"real-world\" time (only for watching or filming).\n",
    "    \n",
    "    # Overall state of the environment. This does not correspond to the observation space of the agent but contains all states that describe the environment.\n",
    "    x_W::Vector{T} # Position in World frame\n",
    "    v_B::Vector{T} # Velocity in Body frame\n",
    "    R_W::Matrix{T} # Rotation (matrix) in World frame\n",
    "    ω_B::Vector{T} # Rotation velocity in Body frame\n",
    "    wind_W::Vector{T} # Externel linear velocity acting on the drone\n",
    "    Δt::T # Time step for physics simulation in seconds\n",
    "\n",
    "    ###NEW###\n",
    "    # Current Bonus / Target\n",
    "    num_waypoints::Int # includig start point\n",
    "    waypoints::Vector{Vector{T}}\n",
    "    reached_goal::BitVector\n",
    "    \n",
    "    norm_way::T\n",
    "    progress::T\n",
    "    progress_prev::T\n",
    "    current_point::Int\n",
    "    reached_goal_in_step::Bool\n",
    "    \n",
    "    r_tol::T\n",
    "    projected_position::Vector{T}\n",
    "\n",
    "    slow_mode::Bool\n",
    "    ######\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14a6873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a keyword-based constructor for the type declared in the mutable struct typedef. \n",
    "# It could also be done with the macro Base.@kwdef.\n",
    "function VtolEnv(;\n",
    "    rng = Random.GLOBAL_RNG, # Random number generation\n",
    "    name = \"Crazyflie\",\n",
    "    visualization = false,\n",
    "    realtime = false,\n",
    "    kwargs... # let the function take an arbitrary number of keyword arguments\n",
    ")\n",
    "    \n",
    "    T = Float64; # explicit type which is used e.g. in state. Cannot be altered due to the poor matrix defininon.\n",
    "    \n",
    "    # final PWM Values for Crazyflie. The interval definition has no effect in the current implementation.\n",
    "    action_space = Space(\n",
    "        ClosedInterval{T}[\n",
    "            0..1#0..65535, # motor 1\n",
    "            0..1#0..65535, # motor 2\n",
    "            0..1#0..65535, # motor 3\n",
    "            0..1#0..65535, # motor 4\n",
    "            ], \n",
    "    )\n",
    "\n",
    "    \n",
    "    state_space = Space( # Three continuous values in state space.\n",
    "        ClosedInterval{T}[\n",
    "            typemin(T)..typemax(T), # 1 x\n",
    "            typemin(T)..typemax(T), # 2 y\n",
    "            typemin(T)..typemax(T), # 3 z\n",
    "\n",
    "            typemin(T)..typemax(T), # 4  World Vector UP x\n",
    "            typemin(T)..typemax(T), # 5  World Vector UP y\n",
    "            typemin(T)..typemax(T), # 6  World Vector UP z\n",
    "\n",
    "            typemin(T)..typemax(T), # 7  World Vector FRONT x\n",
    "            typemin(T)..typemax(T), # 8  World Vector FRONT y\n",
    "            typemin(T)..typemax(T), # 9  World Vector FRONT z\n",
    "            \n",
    "            typemin(T)..typemax(T), # 10 Body velocity along x\n",
    "            typemin(T)..typemax(T), # 11 Body velocity along y\n",
    "            typemin(T)..typemax(T), # 12 Body velocity along z\n",
    "            \n",
    "            typemin(T)..typemax(T), # 13 Body rotational velocity around x\n",
    "            typemin(T)..typemax(T), # 14 Body rotational velocity around y\n",
    "            typemin(T)..typemax(T), # 15 Body rotational velocity around z\n",
    "            \n",
    "            typemin(T)..typemax(T), # 16 position error along x (next gate - current position)\n",
    "            typemin(T)..typemax(T), # 17 position error along y (next gate - current position)\n",
    "            typemin(T)..typemax(T), # 18 position error along z (next gate - current position)\n",
    "            \n",
    "            typemin(T)..typemax(T), # 19 way to next next gate x (next next gate - next gate)\n",
    "            typemin(T)..typemax(T), # 20 way to next next gate y (next next gate - next gate)\n",
    "            typemin(T)..typemax(T), # 21 way to next next gate z (next next gate - next gate)\n",
    "            ], \n",
    "    )\n",
    "\n",
    "    ###NEW###\n",
    "    num_waypoints = N_WAYPOINTS # number of waypoints, includig start point\n",
    "    waypoints = generate_trajectory(num_waypoints + 1) # trajectory with num_waypoints waypoints (+ start point), (with dummy points) \n",
    "    reached_goal = falses(num_waypoints)\n",
    "    \n",
    "    norm_way = 0.0 \n",
    "    for i in 1:(num_waypoints - 1)\n",
    "        norm_way += norm(waypoints[i] - waypoints[i + 1])\n",
    "    end\n",
    "    ######\n",
    "    \n",
    "    if visualization\n",
    "        create_Crazyflie(name, actuators = true);\n",
    "        visualize_waypoints(waypoints[1:num_waypoints], 0.05)\n",
    "\n",
    "        set_Crazyflie_actuators(name, [0.0; 0.0; 0.0; 0.0]);\n",
    "        set_transform(name, [0.0; 0.0; 0.0] ,one(QuatRotation));\n",
    "        set_arrow(string(name, \"vel\"), color_vec=[0.0; 1.0; 0.0; 1.0]);\n",
    "        transform_arrow(string(name, \"vel\"), [0.0; 0.0; 0.0], [0.0; 0.0; 1.0], max_head_radius=0.05)             \n",
    "    end\n",
    "    \n",
    "\n",
    "\n",
    "    environment = VtolEnv(\n",
    "        action_space,\n",
    "        state_space,\n",
    "        zeros(T, length(state_space)), # current state, needs to be extended.\n",
    "        [0.25; 0.25; 0.25; 0.25],#rand(action_space), \n",
    "        false, # episode done ?\n",
    "        0.0, # time\n",
    "        rng, # random number generator  \n",
    "\n",
    "        name,\n",
    "        visualization,\n",
    "        realtime,\n",
    "\n",
    "        zeros(T, 3), # x_W\n",
    "        zeros(T, 3), # v_B\n",
    "        Matrix(one(QuatRotation)), # Float64... so T needs to be Float64\n",
    "        zeros(T, 3), # ω_B\n",
    "        zeros(T, 3), # wind_W\n",
    "        Δt, # Δt\n",
    "\n",
    "        num_waypoints, # includig start point\n",
    "        waypoints, \n",
    "        reached_goal,\n",
    "\n",
    "        norm_way, # norm_way\n",
    "        0.0, # progress\n",
    "        0.0, # progress_prev\n",
    "        2, # current point\n",
    "        false, # reached_goal_in_step\n",
    "        \n",
    "        R_TOL, # r_tol\n",
    "        zeros(T, 3), # projected_position\n",
    "\n",
    "        SLOW_MODE # slow_mode\n",
    "        )\n",
    "    \n",
    "    \n",
    "    RLBase.reset!(environment)\n",
    "    \n",
    "    return environment\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec660d5e",
   "metadata": {},
   "source": [
    "Just for explanation:\n",
    "\n",
    "1. A mutable Struct is created. A struct is a constructor and a constructor is a function that creates new objects.\n",
    "2. A outer keyword-based constructor method is added for the type declared in the mutable struct typedef before.\n",
    "\n",
    "So now we have a function with two methods. Julia will decide which method to call by multiple dispatch."
   ]
  },
  {
   "cell_type": "raw",
   "id": "23dd4047",
   "metadata": {},
   "source": [
    "methods(VtolEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806413d1",
   "metadata": {},
   "source": [
    "# Define the RL interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f822029",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(env::VtolEnv, seed) = Random.seed!(env.rng, seed)\n",
    "RLBase.action_space(env::VtolEnv) = env.action_space\n",
    "RLBase.state_space(env::VtolEnv) = env.observation_space\n",
    "RLBase.is_terminated(env::VtolEnv) = env.done\n",
    "RLBase.state(env::VtolEnv) = env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aad040d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function scale_for_slowmode(slow_mode::Bool, v_min::T, v_max::T, d_max::T, x_W::Vector{T}, projected_position::Vector{T}, v_B::Vector{T}) where T\n",
    "    \n",
    "    if slow_mode == false\n",
    "        return 1\n",
    "    else\n",
    "        if norm(v_B) > v_max\n",
    "            s_vmax = 10^(v_max - norm(v_B))\n",
    "        else\n",
    "            s_vmax = 1\n",
    "        end\n",
    "\n",
    "        if norm(v_B) < v_min\n",
    "            s_vmin = 10^(norm(v_B) - v_min)\n",
    "        else\n",
    "            s_vmin = 1\n",
    "        end\n",
    "\n",
    "        if norm(x_W - projected_position) > d_max\n",
    "            s_gd = exp(-norm(x_W - projected_position) + d_max)\n",
    "        else\n",
    "            s_gd = 1\n",
    "        end\n",
    "        s = s_vmax * s_vmin * s_gd\n",
    "    end\n",
    "    return s\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f7fb89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function computeReward(env::VtolEnv{A,T}) where {A,T}\n",
    "    \n",
    "    \n",
    "    if env.slow_mode\n",
    "        v_min = 1.0 # min velocity\n",
    "        v_max = 3.0 # max velocity\n",
    "        d_max = 0.5 \n",
    "    else\n",
    "        v_min = 4.0 # min velocity\n",
    "        v_max = 50.0 # max velocity\n",
    "        d_max = 1.0 \n",
    "    end\n",
    "\n",
    "\n",
    "    s = scale_for_slowmode(true, v_min, v_max, d_max, env.x_W, env.projected_position, env.v_B)\n",
    "    \n",
    "    k_p = 5.0 * s #/ env.norm_way # factor for progress (between current position and last position) reward \n",
    "    r_p = (env.progress - env.progress_prev); # reward for progress (between current position and last position)\n",
    "\n",
    "    k_s = s * (2 * v_max * env.Δt) / env.norm_way # factor for reached distance (overall) reward\n",
    "    r_s = env.progress # reward for reached distance (overall)\n",
    "    \n",
    "    k_wp = 50.0 # factor for reached gate reward\n",
    "    r_wp = 0.0 # reward for reached gate\n",
    "    if env.reached_goal_in_step\n",
    "        r_wp = exp(-norm(env.x_W - env.waypoints[env.current_point - 1])/env.r_tol)\n",
    "    end \n",
    "\n",
    "    # factor for too high body rate penalty\n",
    "    if env.slow_mode\n",
    "        k_ω = 0.01\n",
    "    else\n",
    "        k_ω = 0.001\n",
    "    end\n",
    "   \n",
    "    norm_ω = norm(env.ω_B) # penalty for body rate\n",
    "\n",
    "    if env.x_W[3] < 0\n",
    "        fall = 1\n",
    "    else\n",
    "        fall = 0\n",
    "    end\n",
    "    \n",
    "    if !env.slow_mode\n",
    "        k_s /= env.norm_way\n",
    "        k_p /= env.norm_way\n",
    "    end\n",
    "    \n",
    "    return k_p * r_p + k_s * r_s + k_wp * r_wp - k_ω * norm_ω - fall\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "RLBase.reward(env::VtolEnv{A,T}) where {A,T} = computeReward(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae45ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "function RLBase.reset!(env::VtolEnv{A,T}) where {A,T}\n",
    "    \n",
    "    env.x_W = [0.0; 0.0; 0.0];\n",
    "    env.v_B = [0.0; 0.0; 0.0];\n",
    "    env.R_W = Matrix(one(QuatRotation)); # Identity matrix (no rotation)\n",
    "    env.ω_B = [0.0; 0.0; 0.0];\n",
    "    env.wind_W = [0.0; 0.0; 0.0];\n",
    "\n",
    "\n",
    "    env.waypoints = generate_trajectory(env.num_waypoints + 1); # Dummy points\n",
    "    env.reached_goal = falses(env.num_waypoints);\n",
    "    env.reached_goal[1] = true; # set first point to reached (start point)\n",
    "    \n",
    "    env.current_point = 2;\n",
    "    env.reached_goal_in_step = false;\n",
    "    \n",
    "    if env.visualization\n",
    "        visualize_waypoints(env.waypoints[1:env.num_waypoints], 0.05); \n",
    "    end\n",
    "    \n",
    "    norm_way = 0.0 \n",
    "    for i in 1:(env.num_waypoints - 1)\n",
    "        norm_way += norm(env.waypoints[i] - env.waypoints[i + 1])\n",
    "    end\n",
    "    \n",
    "    env.norm_way = norm_way\n",
    "    env.progress = 0.0;\n",
    "    env.progress_prev = 0.0;\n",
    "        \n",
    "\n",
    "   # TODO optional: add all rotation and delete position\n",
    "    env.state = [env.x_W[1]; # 1 position along x\n",
    "                 env.x_W[2]; # 2 position along y\n",
    "                 env.x_W[3]; # 3 position along z\n",
    "\n",
    "                 env.R_W[1,1];\n",
    "                 env.R_W[2,1];\n",
    "                 env.R_W[3,1];\n",
    "        \n",
    "                 env.R_W[1,3]; # 4  World Vector UP x\n",
    "                 env.R_W[2,3]; # 5  World Vector UP y\n",
    "                 env.R_W[3,3]; # 6  World Vector UP z\n",
    "\n",
    "                 env.v_B[1]; #  10 Body velocity along x\n",
    "                 env.v_B[2]; #  11 Body velocity along y\n",
    "                 env.v_B[3]; #  12 Body velocity along z\n",
    "\n",
    "                 env.ω_B[1]; #  13  Body rotational velocity around x\n",
    "                 env.ω_B[2]; #  14  Body rotational velocity around y\n",
    "                 env.ω_B[3]; #  15  Body rotational velocity around z\n",
    "\n",
    "                 env.waypoints[2][1] - env.x_W[1]; # 16 position error to next gate along x\n",
    "                 env.waypoints[2][2] - env.x_W[2]; # 17 position error to next gate along z\n",
    "                 env.waypoints[2][3] - env.x_W[3]; # 18 position error to next gate along z\n",
    "                 \n",
    "                 env.waypoints[3][1] - env.waypoints[2][1]; # 19 way to next next gate x \n",
    "                 env.waypoints[3][2] - env.waypoints[2][2]; # 20 way to next next gate y\n",
    "                 env.waypoints[3][3] - env.waypoints[2][3]]  # 21 way to next next gate z \n",
    "    \n",
    "\n",
    "    env.t = 0.0; # time 0s\n",
    "    \n",
    "    env.action = [0.25; 0.25; 0.25; 0.25] # normalized \n",
    "\n",
    "    env.done = false # reset termination\n",
    "\n",
    "    env.projected_position = [0; 0; 0]\n",
    "    \n",
    "    if env.visualization\n",
    "        # Visualize initial state\n",
    "        set_transform(env.name, env.x_W,QuatRotation(env.R_W));\n",
    "        set_Crazyflie_actuators(env.name, [0.0; 0.0; 0.0; 0.0]);\n",
    "        transform_arrow(string(env.name, \"vel\"), env.x_W, [0.0; 0.0; 0.0], max_head_radius=0.05) \n",
    "    end\n",
    "    \n",
    "    nothing # return nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cf1a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a methods for a callable object.\n",
    "# So when a VtolEnv object is created, it has this method that can be called\n",
    "function (env::VtolEnv)(a)\n",
    "    # call the step on the environoment with the next action \n",
    "    _step!(env, a)    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26a5a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VtolEnv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fa04886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "# 3 methods for callable object:<ul><li> (env::<b>VtolEnv</b>)(a) in Main at In[16]:3</li> <li> (env::<b>AbstractEnv</b>)(action) in ReinforcementLearningBase</li> <li> (env::<b>AbstractEnv</b>)(action, player) in ReinforcementLearningBase</li> </ul>"
      ],
      "text/plain": [
       "# 3 methods for callable object:\n",
       "[1] (env::VtolEnv)(a) in Main at In[16]:3\n",
       "[2] (env::AbstractEnv)(action) in ReinforcementLearningBase\n",
       "[3] (env::AbstractEnv)(action, player) in ReinforcementLearningBase"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(env) # Just to explain which methods the object has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4d67302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scale_actions (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function scale_actions(next_action)\n",
    "    return next_action*22_000.0 #debug\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e7d4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "function _step!(env::VtolEnv, next_action)\n",
    "    \n",
    "    scaled_actions = scale_actions.(next_action) # between 0 and 1 for neual network\n",
    "    # caluclate wind impact\n",
    "    v_in_wind_B = vtol_add_wind(env.v_B, env.R_W, env.wind_W)\n",
    "    # caluclate aerodynamic forces\n",
    "    torque_B, force_B = crazyflie_model(scaled_actions);\n",
    "    # integrate rigid body dynamics for Δt\n",
    "    env.x_W, env.v_B, env.R_W, env.ω_B, env.t = rigid_body_simple(torque_B, force_B, env.x_W, env.v_B, env.R_W, env.ω_B, env.t, env.Δt, crazyflie_param)\n",
    "\n",
    "    \n",
    "    env.reached_goal_in_step = false;\n",
    "    if norm(env.x_W - env.waypoints[env.current_point]) < env.r_tol\n",
    "        env.reached_goal_in_step = true;\n",
    "        env.reached_goal[env.current_point] = true;\n",
    "        env.current_point += 1;\n",
    "    end\n",
    "        \n",
    "            \n",
    "    # calculate progress on trajectory\n",
    "    env.progress_prev = env.progress\n",
    "    \n",
    "    current_progress = 0.0\n",
    "    line_segment, env.projected_position = calculate_progress(env.waypoints, env.x_W)\n",
    "    \n",
    "\n",
    "    for i in 2:(line_segment)\n",
    "       current_progress +=  norm(env.waypoints[i] - env.waypoints[i - 1])  \n",
    "    end\n",
    "    current_progress += norm(env.waypoints[line_segment] - env.projected_position)\n",
    "    \n",
    "    env.progress = current_progress\n",
    "    \n",
    "\n",
    "    if env.realtime\n",
    "        sleep(env.Δt) # TODO: just a dirty hack. this is of course slower than real time.\n",
    "    end\n",
    "\n",
    "\n",
    "    if env.visualization\n",
    "        set_transform(env.name, env.x_W,QuatRotation(env.R_W));\n",
    "        set_Crazyflie_actuators(env.name, next_action[1:4])\n",
    "        #transform_arrow(string(env.name, \"_vel\"), env.x_W, env.v_W_target, max_head_radius=0.05)               \n",
    "        transform_arrow(string(env.name, \"vel\"), env.x_W, env.R_W*env.v_B, max_head_radius=0.05) \n",
    "    \n",
    "        for i in eachindex(env.reached_goal)\n",
    "            if env.reached_goal[i]\n",
    "                create_sphere(\"fixgoal_$i\", 0.05, color=RGBA{Float32}(1.0, 0.0, 0.0, 1.0));\n",
    "                set_transform(\"fixgoal_$i\", env.waypoints[i]);\n",
    "            end\n",
    "        end\n",
    "\n",
    "    end\n",
    "    \n",
    "    \n",
    "    env.state = [\n",
    "                 env.x_W[1]; # 1 position along x\n",
    "                 env.x_W[2]; # 2 position along y\n",
    "                 env.x_W[3]; # 3 position along z\n",
    "\n",
    "                 env.R_W[1,1];\n",
    "                 env.R_W[2,1];\n",
    "                 env.R_W[3,1];\n",
    "        \n",
    "                 env.R_W[1,3]; # 4  World Vector UP x\n",
    "                 env.R_W[2,3]; # 5  World Vector UP y\n",
    "                 env.R_W[3,3]; # 6  World Vector UP z\n",
    "\n",
    "                 env.v_B[1]; #  10 Body velocity along x\n",
    "                 env.v_B[2]; #  11 Body velocity along y\n",
    "                 env.v_B[3]; #  12 Body velocity along z\n",
    "\n",
    "                 env.ω_B[1]; #  13  Body rotational velocity around x\n",
    "                 env.ω_B[2]; #  14  Body rotational velocity around y\n",
    "                 env.ω_B[3]; #  15  Body rotational velocity around z\n",
    "\n",
    "                 env.waypoints[env.current_point][1] - env.x_W[1]; # 16 position error to next gate along x\n",
    "                 env.waypoints[env.current_point][2] - env.x_W[2]; # 17 position error to next gate along z\n",
    "                 env.waypoints[env.current_point][3] - env.x_W[3]; # 18 position error to next gate along z\n",
    "                 \n",
    "                 0; # 19 way to next next gate x \n",
    "                 0; # 20 way to next next gate y\n",
    "                 0] \n",
    "    \n",
    "    if env.current_point <= env.num_waypoints\n",
    "        env.state[19] = env.waypoints[env.current_point + 1][1] - env.waypoints[env.current_point][1]; # 16 way to next next gate x (next next gate - next gate), dummy integriert\n",
    "        env.state[20] = env.waypoints[env.current_point + 1][2] - env.waypoints[env.current_point][2]; # 17 way to next next gate y (next next gate - next gate), dummy integriert\n",
    "        env.state[21] = env.waypoints[env.current_point + 1][3] - env.waypoints[env.current_point][3]; # 18 way to next next gate z (next next gate - next gate), dummy integriert\n",
    "    end\n",
    "\n",
    "    \n",
    "    \n",
    "    # Termination criteria\n",
    "    env.done = \n",
    "        # After time... How fast is drone+Range of desired point\n",
    "        # After reaching position (circle of r_tol)\n",
    "        norm(env.ω_B) > 100.0 || \n",
    "        norm(env.v_B) > 100.0 || # stop if body is too fast_point \n",
    "        env.x_W[3] < -1.0 || # stop if body is below -5m\n",
    "        env.t > env.num_waypoints * 3.0 ||# stop after 3s per point \n",
    "        norm(env.x_W - env.projected_position) > 1.0 || # too far off the path 1 m \n",
    "        env.reached_goal == trues(env.num_waypoints)\n",
    "\n",
    "    nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e1cd988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:              | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "random policy with VtolEnv | \u001b[32m2000  \u001b[39m\u001b[36m 2000  \u001b[39m\u001b[0m2.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"random policy with VtolEnv\", Any[], 2000, false, false, true, 1.677578356806056e9, 1.677578359023864e9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RLBase.test_runnable!(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223a31f",
   "metadata": {},
   "source": [
    "Show an overview of the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6de74",
   "metadata": {},
   "source": [
    "# Setup of a reinforcement learning experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5683fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# VtolEnv\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                  Value |\n",
       "|:----------------- | ----------------------:|\n",
       "| NumAgentStyle     |          SingleAgent() |\n",
       "| DynamicStyle      |           Sequential() |\n",
       "| InformationStyle  | ImperfectInformation() |\n",
       "| ChanceStyle       |           Stochastic() |\n",
       "| RewardStyle       |           StepReward() |\n",
       "| UtilityStyle      |           GeneralSum() |\n",
       "| ActionStyle       |     MinimalActionSet() |\n",
       "| StateStyle        |     Observation{Any}() |\n",
       "| DefaultStateStyle |     Observation{Any}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Space{Vector{ClosedInterval{Float64}}}(ClosedInterval{Float64}[-Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf])`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Space{Vector{ClosedInterval{Float64}}}(ClosedInterval{Float64}[0.0..1.0, 0.0..1.0, 0.0..1.0, 0.0..1.0])`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -3.103591486005619, 4.003008630394852, 1.7647696667164254, -3.9530703802234872, -0.10251728638944968, -3.1952741277286876]\n",
       "```\n"
      ],
      "text/plain": [
       "# VtolEnv\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                  Value |\n",
       "|:----------------- | ----------------------:|\n",
       "| NumAgentStyle     |          SingleAgent() |\n",
       "| DynamicStyle      |           Sequential() |\n",
       "| InformationStyle  | ImperfectInformation() |\n",
       "| ChanceStyle       |           Stochastic() |\n",
       "| RewardStyle       |           StepReward() |\n",
       "| UtilityStyle      |           GeneralSum() |\n",
       "| ActionStyle       |     MinimalActionSet() |\n",
       "| StateStyle        |     Observation{Any}() |\n",
       "| DefaultStateStyle |     Observation{Any}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Space{Vector{ClosedInterval{Float64}}}(ClosedInterval{Float64}[-Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf, -Inf..Inf])`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Space{Vector{ClosedInterval{Float64}}}(ClosedInterval{Float64}[0.0..1.0, 0.0..1.0, 0.0..1.0, 0.0..1.0])`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -3.103591486005619, 4.003008630394852, 1.7647696667164254, -3.9530703802234872, -0.10251728638944968, -3.1952741277286876]\n",
       "```\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123    \n",
    "rng = StableRNG(seed)\n",
    "UPDATE_FREQ = 1024\n",
    "\n",
    "# define multiple environments for parallel training\n",
    "env = VtolEnv(; rng = StableRNG(hash(seed)), name = \"cf_SAC\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1f128b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_q_net (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function approximator\n",
    "# TODO ?\n",
    "    ns, na = length(state(env)), length(action_space(env))\n",
    "\n",
    "create_policy_net() = NeuralNetworkApproximator(\n",
    "        model = GaussianNetwork(\n",
    "            pre = Chain(\n",
    "                Dense(ns, 256, Flux.relu, init = glorot_uniform(rng)),\n",
    "                Dense(256, 256, Flux.relu, init = glorot_uniform(rng)),\n",
    "            ),\n",
    "            μ = Chain(Dense(256, na, Flux.identity; init = glorot_uniform(rng))),\n",
    "            logσ = Chain(Dense(256, na, Flux.identity; init = glorot_uniform(rng))),\n",
    "        ),\n",
    "        optimizer = ADAM(1e-2),\n",
    "    )\n",
    "\n",
    "create_q_net() = NeuralNetworkApproximator(\n",
    "        model = Chain(\n",
    "            Dense(ns + na, 256, Flux.relu; init = glorot_uniform(rng)),\n",
    "            Dense(256, 256, Flux.relu; init = glorot_uniform(rng)),\n",
    "            Dense(256, 1, Flux.identity; init = glorot_uniform(rng)),\n",
    "        ),\n",
    "        optimizer = ADAM(1e-2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05ab2a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = 1_000_000\n",
    "start_steps = 10_000 # puffer size\n",
    "update_after = 1_000\n",
    "#trajectory_num = dataset_size\n",
    "#TODO ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ea4c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    agent = Agent( # A wrapper of an AbstractPolicy\n",
    "     # TODO ?    \n",
    "    \n",
    "    policy = SACPolicy(\n",
    "            policy = create_policy_net(),\n",
    "            qnetwork1 = create_q_net(),\n",
    "            qnetwork2 = create_q_net(),\n",
    "            #target_qnetwork1 = create_q_net(),\n",
    "            #target_qnetwork2 = create_q_net(),\n",
    "            γ = 0.99f0,\n",
    "            τ = 0.005f0,\n",
    "            α = 0.2f0,\n",
    "            batch_size = 256,\n",
    "            start_steps = start_steps,\n",
    "            start_policy = RandomPolicy(Space([0.0..1.0 for _ in 1:na]); rng = rng),\n",
    "            update_after = update_after,\n",
    "            update_freq = UPDATE_FREQ,\n",
    "            automatic_entropy_tuning = true,\n",
    "            lr_alpha = 0.003f0,\n",
    "            action_dims = na,\n",
    "            rng = rng,\n",
    "        ),\n",
    "        trajectory = CircularArraySARTTrajectory(\n",
    "            capacity = dataset_size + 1,\n",
    "            state = Vector{Float32} => (ns,),\n",
    "            action = Vector{Float32} => (na,),\n",
    "        ),\n",
    "\n",
    "    \n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aafcb113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "saveModel (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function saveModel(t, agent, env) \n",
    "    policy = cpu(agent.policy.policy)\n",
    "    qnetwork1 = cpu(agent.policy.qnetwork1)\n",
    "    qnetwork2 = cpu(agent.policy.qnetwork2)\n",
    "    if SLOW_MODE\n",
    "        f = joinpath(\"./RL_models_slow/\", \"cf_sac_$(t).bson\")\n",
    "    else\n",
    "        f = joinpath(\"./RL_models_fast/\", \"cf_sac_$(t).bson\")\n",
    "    end;\n",
    "    @save f policy qnetwork1 qnetwork2\n",
    "    println(\"parameters at step $t saved to $f\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50638c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadModel (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loadModel() \n",
    "    f = joinpath(\"./RL_models_slow/\", \"cf_sac_$(load_from_slow_step).bson\")\n",
    "        \n",
    "    @load f policy qnetwork1 qnetwork2\n",
    "    \n",
    "    println(\"load model $f\")\n",
    "    return policy, qnetwork1, qnetwork2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7470f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validate_policy(t, agent, env)\n",
    "    # for validation extract the policy from the agend\n",
    "    run(agent.policy, test_env, StopAfterEpisode(1), \n",
    "        ComposedHook(\n",
    "        episode_test_step_hook, \n",
    "        episode_test_reward_hook\n",
    "    ),\n",
    "        )\n",
    "    # the result of the hook\n",
    "    reward = round((episode_test_reward_hook.rewards[end]),digits = 3)\n",
    "    length = episode_test_step_hook.steps[end-1]\n",
    "    \n",
    "    println(\"step: \", t, \" reward : \",reward, \" length: \", length)\n",
    "\n",
    "    with_logger(logger) do\n",
    "        @info \"evaluating\" avg_length = length  avg_reward = reward  log_step_increment = 0;\n",
    "    end\n",
    "end;\n",
    "\n",
    "episode_test_reward_hook = TotalRewardPerEpisode( is_display_on_exit=false)\n",
    "episode_test_step_hook = StepsPerEpisode()\n",
    "# create a env only for reward test\n",
    "\n",
    "test_env = VtolEnv(;name = \"test_cf\", visualization = true, realtime = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6aadbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hook which is called during the training\n",
    "total_reward_per_episode = TotalRewardPerEpisode(is_display_on_exit = false)\n",
    "hook = ComposedHook(\n",
    "    total_reward_per_episode,\n",
    "    DoEveryNStep(saveModel, n=save_freq),\n",
    "    DoEveryNStep(validate_policy, n=validate_freq),\n",
    "\n",
    "    DoEveryNStep() do t, agent, env\n",
    "        with_logger(logger) do\n",
    "            if length(total_reward_per_episode.rewards) > 0\n",
    "                @info \"training\" total_reward_per_episode.rewards[end];\n",
    "            end\n",
    "        end\n",
    "    end;\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d479e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo load model\n",
    "if !SLOW_MODE\n",
    "    agent.policy.policy, agent.policy.qnetwork1, agent.policy.qnetwork2 = loadModel(); # todo \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dfdb68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   0%|                                         |  ETA: 1 days, 0:00:50\u001b[39mm"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 100000 saved to ./RL_models_slow/cf_sac_100000.bson\n",
      "step: 100000 reward : 1.973 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   0%|▏                                        |  ETA: 14:33:57\u001b[39m25\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 200000 saved to ./RL_models_slow/cf_sac_200000.bson\n",
      "step: 200000 reward : 2.103 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   0%|▏                                        |  ETA: 11:14:26\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 300000 saved to ./RL_models_slow/cf_sac_300000.bson\n",
      "step: 300000 reward : 1.972 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   0%|▎                                        |  ETA: 9:31:17\u001b[39mm"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 400000 saved to ./RL_models_slow/cf_sac_400000.bson\n",
      "step: 400000 reward : 1.942 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▎                                        |  ETA: 8:36:35\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 500000 saved to ./RL_models_slow/cf_sac_500000.bson\n",
      "step: 500000 reward : 1.972 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▎                                        |  ETA: 7:58:08\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 600000 saved to ./RL_models_slow/cf_sac_600000.bson\n",
      "step: 600000 reward : Inf length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▍                                        |  ETA: 7:32:08\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 700000 saved to ./RL_models_slow/cf_sac_700000.bson\n",
      "step: 700000 reward : 2.038 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▍                                        |  ETA: 7:13:44\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 800000 saved to ./RL_models_slow/cf_sac_800000.bson\n",
      "step: 800000 reward : 3.829 length: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▌                                        |  ETA: 6:59:11\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 900000 saved to ./RL_models_slow/cf_sac_900000.bson\n",
      "step: 900000 reward : 2.556 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▌                                        |  ETA: 6:47:30\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1000000 saved to ./RL_models_slow/cf_sac_1000000.bson\n",
      "step: 1000000 reward : 1.957 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▋                                        |  ETA: 6:36:27\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1100000 saved to ./RL_models_slow/cf_sac_1100000.bson\n",
      "step: 1100000 reward : 3.459 length: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▋                                        |  ETA: 6:28:21\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1200000 saved to ./RL_models_slow/cf_sac_1200000.bson\n",
      "step: 1200000 reward : 1.961 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|▋                                        |  ETA: 6:20:47\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1300000 saved to ./RL_models_slow/cf_sac_1300000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[32mProgress:   2%|▋                                        |  ETA: 6:20:58\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1300000 reward : 1.928 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|▊                                        |  ETA: 6:13:53\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1400000 saved to ./RL_models_slow/cf_sac_1400000.bson\n",
      "step: 1400000 reward : 1.92 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|▊                                        |  ETA: 6:07:53\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1500000 saved to ./RL_models_slow/cf_sac_1500000.bson\n",
      "step: 1500000 reward : 3.812 length: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|▉                                        |  ETA: 6:02:53\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1600000 saved to ./RL_models_slow/cf_sac_1600000.bson\n",
      "step: 1600000 reward : 1.94 length: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|▉                                        |  ETA: 5:58:07\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1700000 saved to ./RL_models_slow/cf_sac_1700000.bson\n",
      "step: 1700000 reward : 1.952 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|▉                                        |  ETA: 5:53:59\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1800000 saved to ./RL_models_slow/cf_sac_1800000.bson\n",
      "step: 1800000 reward : Inf length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|█                                        |  ETA: 5:49:48\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 1900000 saved to ./RL_models_slow/cf_sac_1900000.bson\n",
      "step: 1900000 reward : 1.984 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   2%|█                                        |  ETA: 5:45:59\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 2000000 saved to ./RL_models_slow/cf_sac_2000000.bson\n",
      "step: 2000000 reward : Inf length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▏                                       |  ETA: 5:42:35\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 2100000 saved to ./RL_models_slow/cf_sac_2100000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[32mProgress:   3%|█▏                                       |  ETA: 5:42:45\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2100000 reward : 1.917 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▏                                       |  ETA: 5:39:15\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 2200000 saved to ./RL_models_slow/cf_sac_2200000.bson\n",
      "step: 2200000 reward : 1.893 length: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▏                                       |  ETA: 5:36:42\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 2300000 saved to ./RL_models_slow/cf_sac_2300000.bson\n",
      "step: 2300000 reward : 4.303 length: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▎                                       |  ETA: 5:36:41\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 2400000 saved to ./RL_models_slow/cf_sac_2400000.bson\n",
      "step: 2400000 reward : 1.982 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▎                                       |  ETA: 5:34:40\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 2500000 saved to ./RL_models_slow/cf_sac_2500000.bson\n",
      "step: 2500000 reward : 1.997 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▍                                       |  ETA: 5:32:02\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 2600000 saved to ./RL_models_slow/cf_sac_2600000.bson\n",
      "step: 2600000 reward : 1.937 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▍                                       |  ETA: 5:29:36\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 2700000 saved to ./RL_models_slow/cf_sac_2700000.bson\n",
      "step: 2700000 reward : 27.781 length: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   3%|█▍                                       |  ETA: 5:28:06\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 2800000 saved to ./RL_models_slow/cf_sac_2800000.bson\n",
      "step: 2800000 reward : 4.827 length: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▌                                       |  ETA: 5:26:31\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 2900000 saved to ./RL_models_slow/cf_sac_2900000.bson\n",
      "step: 2900000 reward : 80.162 length: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▌                                       |  ETA: 5:25:02\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 3000000 saved to ./RL_models_slow/cf_sac_3000000.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[32mProgress:   4%|█▌                                       |  ETA: 5:25:10\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3000000 reward : 1.935 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▋                                       |  ETA: 5:23:32\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 3100000 saved to ./RL_models_slow/cf_sac_3100000.bson\n",
      "step: 3100000 reward : 2.066 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▋                                       |  ETA: 5:21:48\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 3200000 saved to ./RL_models_slow/cf_sac_3200000.bson\n",
      "step: 3200000 reward : 6.354 length: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▊                                       |  ETA: 5:20:37\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 3300000 saved to ./RL_models_slow/cf_sac_3300000.bson\n",
      "step: 3300000 reward : 5.083 length: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▊                                       |  ETA: 5:19:26\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 3400000 saved to ./RL_models_slow/cf_sac_3400000.bson\n",
      "step: 3400000 reward : 2.004 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▊                                       |  ETA: 5:18:04\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 3500000 saved to ./RL_models_slow/cf_sac_3500000.bson\n",
      "step: 3500000 reward : 1.939 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   4%|█▉                                       |  ETA: 5:16:45\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 3600000 saved to ./RL_models_slow/cf_sac_3600000.bson\n",
      "step: 3600000 reward : 3.39 length: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|█▉                                       |  ETA: 5:15:33\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 3700000 saved to ./RL_models_slow/cf_sac_3700000.bson\n",
      "step: 3700000 reward : 3.524 length: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██                                       |  ETA: 5:14:22\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 3800000 saved to ./RL_models_slow/cf_sac_3800000.bson\n",
      "step: 3800000 reward : 1.968 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██                                       |  ETA: 5:13:23\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 3900000 saved to ./RL_models_slow/cf_sac_3900000.bson\n",
      "step: 3900000 reward : 26.992 length: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██                                       |  ETA: 5:12:30\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 4000000 saved to ./RL_models_slow/cf_sac_4000000.bson\n",
      "step: 4000000 reward : 2.29 length: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██▏                                      |  ETA: 5:11:24\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 4100000 saved to ./RL_models_slow/cf_sac_4100000.bson\n",
      "step: 4100000 reward : 3.194 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██▏                                      |  ETA: 5:10:22\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 4200000 saved to ./RL_models_slow/cf_sac_4200000.bson\n",
      "step: 4200000 reward : Inf length: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██▎                                      |  ETA: 5:09:22\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 4300000 saved to ./RL_models_slow/cf_sac_4300000.bson\n",
      "step: 4300000 reward : 2.073 length: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██▎                                      |  ETA: 5:08:39\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 4400000 saved to ./RL_models_slow/cf_sac_4400000.bson\n",
      "step: 4400000 reward : 3.943 length: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▎                                      |  ETA: 5:07:52\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 4500000 saved to ./RL_models_slow/cf_sac_4500000.bson\n",
      "step: 4500000 reward : 1.921 length: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▍                                      |  ETA: 5:06:54\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 4600000 saved to ./RL_models_slow/cf_sac_4600000.bson\n",
      "step: 4600000 reward : 1.955 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▍                                      |  ETA: 5:06:13\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 4700000 saved to ./RL_models_slow/cf_sac_4700000.bson\n",
      "step: 4700000 reward : 2.017 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▌                                      |  ETA: 5:05:18\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 4800000 saved to ./RL_models_slow/cf_sac_4800000.bson\n",
      "step: 4800000 reward : 2.058 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▌                                      |  ETA: 5:04:32\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 4900000 saved to ./RL_models_slow/cf_sac_4900000.bson\n",
      "step: 4900000 reward : 3.35 length: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▌                                      |  ETA: 5:04:43\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters at step 5000000 saved to ./RL_models_slow/cf_sac_5000000.bson\n",
      "step: 5000000 reward : 3.442 length: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   6%|██▋                                      |  ETA: 5:04:42\u001b[39m"
     ]
    }
   ],
   "source": [
    "if TRAINING\n",
    "    ReinforcementLearning.run(\n",
    "        agent,\n",
    "        env,\n",
    "        StopAfterStep(steps),\n",
    "        hook\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING\n",
    "    plot(episode_test_reward_hook.rewards)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41c1dc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip050\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip050)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip051\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip050)\" d=\"\n",
       "M141.853 1486.45 L2352.76 1486.45 L2352.76 47.2441 L141.853 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip052\">\n",
       "    <rect x=\"141\" y=\"47\" width=\"2212\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  161.859,1486.45 161.859,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  587.524,1486.45 587.524,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1013.19,1486.45 1013.19,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1438.85,1486.45 1438.85,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1864.52,1486.45 1864.52,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2290.18,1486.45 2290.18,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  161.859,1486.45 161.859,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  587.524,1486.45 587.524,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1013.19,1486.45 1013.19,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1438.85,1486.45 1438.85,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1864.52,1486.45 1864.52,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2290.18,1486.45 2290.18,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip050)\" d=\"M161.859 1517.37 Q158.248 1517.37 156.419 1520.93 Q154.614 1524.47 154.614 1531.6 Q154.614 1538.71 156.419 1542.27 Q158.248 1545.82 161.859 1545.82 Q165.493 1545.82 167.299 1542.27 Q169.128 1538.71 169.128 1531.6 Q169.128 1524.47 167.299 1520.93 Q165.493 1517.37 161.859 1517.37 M161.859 1513.66 Q167.669 1513.66 170.725 1518.27 Q173.804 1522.85 173.804 1531.6 Q173.804 1540.33 170.725 1544.94 Q167.669 1549.52 161.859 1549.52 Q156.049 1549.52 152.97 1544.94 Q149.915 1540.33 149.915 1531.6 Q149.915 1522.85 152.97 1518.27 Q156.049 1513.66 161.859 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M562.212 1544.91 L569.85 1544.91 L569.85 1518.55 L561.54 1520.21 L561.54 1515.95 L569.804 1514.29 L574.48 1514.29 L574.48 1544.91 L582.119 1544.91 L582.119 1548.85 L562.212 1548.85 L562.212 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M601.563 1517.37 Q597.952 1517.37 596.123 1520.93 Q594.318 1524.47 594.318 1531.6 Q594.318 1538.71 596.123 1542.27 Q597.952 1545.82 601.563 1545.82 Q605.198 1545.82 607.003 1542.27 Q608.832 1538.71 608.832 1531.6 Q608.832 1524.47 607.003 1520.93 Q605.198 1517.37 601.563 1517.37 M601.563 1513.66 Q607.373 1513.66 610.429 1518.27 Q613.508 1522.85 613.508 1531.6 Q613.508 1540.33 610.429 1544.94 Q607.373 1549.52 601.563 1549.52 Q595.753 1549.52 592.674 1544.94 Q589.619 1540.33 589.619 1531.6 Q589.619 1522.85 592.674 1518.27 Q595.753 1513.66 601.563 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M991.962 1544.91 L1008.28 1544.91 L1008.28 1548.85 L986.337 1548.85 L986.337 1544.91 Q988.999 1542.16 993.582 1537.53 Q998.189 1532.88 999.369 1531.53 Q1001.61 1529.01 1002.49 1527.27 Q1003.4 1525.51 1003.4 1523.82 Q1003.4 1521.07 1001.45 1519.33 Q999.531 1517.6 996.43 1517.6 Q994.231 1517.6 991.777 1518.36 Q989.346 1519.13 986.569 1520.68 L986.569 1515.95 Q989.393 1514.82 991.846 1514.24 Q994.3 1513.66 996.337 1513.66 Q1001.71 1513.66 1004.9 1516.35 Q1008.1 1519.03 1008.1 1523.52 Q1008.1 1525.65 1007.29 1527.57 Q1006.5 1529.47 1004.39 1532.07 Q1003.81 1532.74 1000.71 1535.95 Q997.61 1539.15 991.962 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M1028.1 1517.37 Q1024.49 1517.37 1022.66 1520.93 Q1020.85 1524.47 1020.85 1531.6 Q1020.85 1538.71 1022.66 1542.27 Q1024.49 1545.82 1028.1 1545.82 Q1031.73 1545.82 1033.54 1542.27 Q1035.36 1538.71 1035.36 1531.6 Q1035.36 1524.47 1033.54 1520.93 Q1031.73 1517.37 1028.1 1517.37 M1028.1 1513.66 Q1033.91 1513.66 1036.96 1518.27 Q1040.04 1522.85 1040.04 1531.6 Q1040.04 1540.33 1036.96 1544.94 Q1033.91 1549.52 1028.1 1549.52 Q1022.29 1549.52 1019.21 1544.94 Q1016.15 1540.33 1016.15 1531.6 Q1016.15 1522.85 1019.21 1518.27 Q1022.29 1513.66 1028.1 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M1427.7 1530.21 Q1431.05 1530.93 1432.93 1533.2 Q1434.83 1535.47 1434.83 1538.8 Q1434.83 1543.92 1431.31 1546.72 Q1427.79 1549.52 1421.31 1549.52 Q1419.13 1549.52 1416.82 1549.08 Q1414.53 1548.66 1412.07 1547.81 L1412.07 1543.29 Q1414.02 1544.43 1416.33 1545.01 Q1418.65 1545.58 1421.17 1545.58 Q1425.57 1545.58 1427.86 1543.85 Q1430.17 1542.11 1430.17 1538.8 Q1430.17 1535.75 1428.02 1534.03 Q1425.89 1532.3 1422.07 1532.3 L1418.04 1532.3 L1418.04 1528.45 L1422.26 1528.45 Q1425.71 1528.45 1427.53 1527.09 Q1429.36 1525.7 1429.36 1523.11 Q1429.36 1520.45 1427.46 1519.03 Q1425.59 1517.6 1422.07 1517.6 Q1420.15 1517.6 1417.95 1518.01 Q1415.75 1518.43 1413.11 1519.31 L1413.11 1515.14 Q1415.78 1514.4 1418.09 1514.03 Q1420.43 1513.66 1422.49 1513.66 Q1427.81 1513.66 1430.91 1516.09 Q1434.02 1518.5 1434.02 1522.62 Q1434.02 1525.49 1432.37 1527.48 Q1430.73 1529.45 1427.7 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M1453.69 1517.37 Q1450.08 1517.37 1448.25 1520.93 Q1446.45 1524.47 1446.45 1531.6 Q1446.45 1538.71 1448.25 1542.27 Q1450.08 1545.82 1453.69 1545.82 Q1457.33 1545.82 1459.13 1542.27 Q1460.96 1538.71 1460.96 1531.6 Q1460.96 1524.47 1459.13 1520.93 Q1457.33 1517.37 1453.69 1517.37 M1453.69 1513.66 Q1459.5 1513.66 1462.56 1518.27 Q1465.64 1522.85 1465.64 1531.6 Q1465.64 1540.33 1462.56 1544.94 Q1459.5 1549.52 1453.69 1549.52 Q1447.88 1549.52 1444.8 1544.94 Q1441.75 1540.33 1441.75 1531.6 Q1441.75 1522.85 1444.8 1518.27 Q1447.88 1513.66 1453.69 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M1852.69 1518.36 L1840.88 1536.81 L1852.69 1536.81 L1852.69 1518.36 M1851.46 1514.29 L1857.34 1514.29 L1857.34 1536.81 L1862.27 1536.81 L1862.27 1540.7 L1857.34 1540.7 L1857.34 1548.85 L1852.69 1548.85 L1852.69 1540.7 L1837.09 1540.7 L1837.09 1536.19 L1851.46 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M1880 1517.37 Q1876.39 1517.37 1874.56 1520.93 Q1872.76 1524.47 1872.76 1531.6 Q1872.76 1538.71 1874.56 1542.27 Q1876.39 1545.82 1880 1545.82 Q1883.64 1545.82 1885.44 1542.27 Q1887.27 1538.71 1887.27 1531.6 Q1887.27 1524.47 1885.44 1520.93 Q1883.64 1517.37 1880 1517.37 M1880 1513.66 Q1885.81 1513.66 1888.87 1518.27 Q1891.95 1522.85 1891.95 1531.6 Q1891.95 1540.33 1888.87 1544.94 Q1885.81 1549.52 1880 1549.52 Q1874.19 1549.52 1871.12 1544.94 Q1868.06 1540.33 1868.06 1531.6 Q1868.06 1522.85 1871.12 1518.27 Q1874.19 1513.66 1880 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M2264.88 1514.29 L2283.24 1514.29 L2283.24 1518.22 L2269.16 1518.22 L2269.16 1526.7 Q2270.18 1526.35 2271.2 1526.19 Q2272.22 1526 2273.24 1526 Q2279.03 1526 2282.41 1529.17 Q2285.79 1532.34 2285.79 1537.76 Q2285.79 1543.34 2282.31 1546.44 Q2278.84 1549.52 2272.52 1549.52 Q2270.35 1549.52 2268.08 1549.15 Q2265.83 1548.78 2263.42 1548.04 L2263.42 1543.34 Q2265.51 1544.47 2267.73 1545.03 Q2269.95 1545.58 2272.43 1545.58 Q2276.43 1545.58 2278.77 1543.48 Q2281.11 1541.37 2281.11 1537.76 Q2281.11 1534.15 2278.77 1532.04 Q2276.43 1529.94 2272.43 1529.94 Q2270.55 1529.94 2268.68 1530.35 Q2266.83 1530.77 2264.88 1531.65 L2264.88 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M2305 1517.37 Q2301.39 1517.37 2299.56 1520.93 Q2297.75 1524.47 2297.75 1531.6 Q2297.75 1538.71 2299.56 1542.27 Q2301.39 1545.82 2305 1545.82 Q2308.63 1545.82 2310.44 1542.27 Q2312.27 1538.71 2312.27 1531.6 Q2312.27 1524.47 2310.44 1520.93 Q2308.63 1517.37 2305 1517.37 M2305 1513.66 Q2310.81 1513.66 2313.86 1518.27 Q2316.94 1522.85 2316.94 1531.6 Q2316.94 1540.33 2313.86 1544.94 Q2310.81 1549.52 2305 1549.52 Q2299.19 1549.52 2296.11 1544.94 Q2293.05 1540.33 2293.05 1531.6 Q2293.05 1522.85 2296.11 1518.27 Q2299.19 1513.66 2305 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,1341.27 2352.76,1341.27 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,1080.17 2352.76,1080.17 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,819.067 2352.76,819.067 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,557.963 2352.76,557.963 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip052)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  141.853,296.859 2352.76,296.859 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1486.45 141.853,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1341.27 160.751,1341.27 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,1080.17 160.751,1080.17 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,819.067 160.751,819.067 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,557.963 160.751,557.963 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  141.853,296.859 160.751,296.859 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip050)\" d=\"M57.7745 1354.62 L74.0939 1354.62 L74.0939 1358.55 L52.1495 1358.55 L52.1495 1354.62 Q54.8115 1351.86 59.3949 1347.23 Q64.0013 1342.58 65.1819 1341.24 Q67.4272 1338.72 68.3068 1336.98 Q69.2096 1335.22 69.2096 1333.53 Q69.2096 1330.78 67.2652 1329.04 Q65.3439 1327.3 62.2421 1327.3 Q60.043 1327.3 57.5893 1328.07 Q55.1588 1328.83 52.381 1330.38 L52.381 1325.66 Q55.2051 1324.53 57.6588 1323.95 Q60.1124 1323.37 62.1495 1323.37 Q67.5198 1323.37 70.7142 1326.05 Q73.9087 1328.74 73.9087 1333.23 Q73.9087 1335.36 73.0985 1337.28 Q72.3115 1339.18 70.205 1341.77 Q69.6263 1342.44 66.5245 1345.66 Q63.4226 1348.86 57.7745 1354.62 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M93.9086 1327.07 Q90.2975 1327.07 88.4688 1330.64 Q86.6632 1334.18 86.6632 1341.31 Q86.6632 1348.42 88.4688 1351.98 Q90.2975 1355.52 93.9086 1355.52 Q97.5428 1355.52 99.3483 1351.98 Q101.177 1348.42 101.177 1341.31 Q101.177 1334.18 99.3483 1330.64 Q97.5428 1327.07 93.9086 1327.07 M93.9086 1323.37 Q99.7187 1323.37 102.774 1327.98 Q105.853 1332.56 105.853 1341.31 Q105.853 1350.04 102.774 1354.64 Q99.7187 1359.23 93.9086 1359.23 Q88.0984 1359.23 85.0197 1354.64 Q81.9642 1350.04 81.9642 1341.31 Q81.9642 1332.56 85.0197 1327.98 Q88.0984 1323.37 93.9086 1323.37 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M58.7699 1093.52 L75.0892 1093.52 L75.0892 1097.45 L53.1449 1097.45 L53.1449 1093.52 Q55.8069 1090.76 60.3902 1086.13 Q64.9967 1081.48 66.1772 1080.14 Q68.4226 1077.61 69.3022 1075.88 Q70.205 1074.12 70.205 1072.43 Q70.205 1069.67 68.2606 1067.94 Q66.3393 1066.2 63.2374 1066.2 Q61.0384 1066.2 58.5847 1066.96 Q56.1541 1067.73 53.3764 1069.28 L53.3764 1064.56 Q56.2004 1063.42 58.6541 1062.84 Q61.1078 1062.27 63.1448 1062.27 Q68.5152 1062.27 71.7096 1064.95 Q74.904 1067.64 74.904 1072.13 Q74.904 1074.26 74.0939 1076.18 Q73.3068 1078.08 71.2004 1080.67 Q70.6217 1081.34 67.5198 1084.56 Q64.418 1087.75 58.7699 1093.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M84.9503 1062.89 L103.307 1062.89 L103.307 1066.83 L89.2327 1066.83 L89.2327 1075.3 Q90.2512 1074.95 91.2697 1074.79 Q92.2882 1074.6 93.3067 1074.6 Q99.0937 1074.6 102.473 1077.77 Q105.853 1080.95 105.853 1086.36 Q105.853 1091.94 102.381 1095.04 Q98.9085 1098.12 92.5891 1098.12 Q90.4132 1098.12 88.1447 1097.75 Q85.8993 1097.38 83.492 1096.64 L83.492 1091.94 Q85.5753 1093.08 87.7975 1093.63 Q90.0197 1094.19 92.4965 1094.19 Q96.5011 1094.19 98.8391 1092.08 Q101.177 1089.97 101.177 1086.36 Q101.177 1082.75 98.8391 1080.64 Q96.5011 1078.54 92.4965 1078.54 Q90.6215 1078.54 88.7466 1078.96 Q86.8947 1079.37 84.9503 1080.25 L84.9503 1062.89 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M67.9133 817.713 Q71.2698 818.43 73.1448 820.699 Q75.0429 822.967 75.0429 826.3 Q75.0429 831.416 71.5244 834.217 Q68.0059 837.018 61.5245 837.018 Q59.3486 837.018 57.0338 836.578 Q54.7421 836.162 52.2884 835.305 L52.2884 830.791 Q54.2328 831.925 56.5477 832.504 Q58.8625 833.083 61.3856 833.083 Q65.7837 833.083 68.0754 831.347 Q70.3902 829.611 70.3902 826.3 Q70.3902 823.245 68.2374 821.532 Q66.1078 819.796 62.2884 819.796 L58.2606 819.796 L58.2606 815.953 L62.4735 815.953 Q65.9226 815.953 67.7513 814.588 Q69.58 813.199 69.58 810.606 Q69.58 807.944 67.6819 806.532 Q65.8069 805.097 62.2884 805.097 Q60.3671 805.097 58.168 805.514 Q55.969 805.93 53.3301 806.81 L53.3301 802.643 Q55.9921 801.902 58.3069 801.532 Q60.6449 801.162 62.705 801.162 Q68.0291 801.162 71.1309 803.592 Q74.2327 806 74.2327 810.12 Q74.2327 812.99 72.5892 814.981 Q70.9457 816.949 67.9133 817.713 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M93.9086 804.865 Q90.2975 804.865 88.4688 808.43 Q86.6632 811.972 86.6632 819.101 Q86.6632 826.208 88.4688 829.773 Q90.2975 833.314 93.9086 833.314 Q97.5428 833.314 99.3483 829.773 Q101.177 826.208 101.177 819.101 Q101.177 811.972 99.3483 808.43 Q97.5428 804.865 93.9086 804.865 M93.9086 801.162 Q99.7187 801.162 102.774 805.768 Q105.853 810.351 105.853 819.101 Q105.853 827.828 102.774 832.435 Q99.7187 837.018 93.9086 837.018 Q88.0984 837.018 85.0197 832.435 Q81.9642 827.828 81.9642 819.101 Q81.9642 810.351 85.0197 805.768 Q88.0984 801.162 93.9086 801.162 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M68.9087 556.609 Q72.2652 557.326 74.1402 559.595 Q76.0383 561.863 76.0383 565.197 Q76.0383 570.312 72.5198 573.113 Q69.0013 575.914 62.5198 575.914 Q60.3439 575.914 58.0291 575.474 Q55.7375 575.058 53.2838 574.201 L53.2838 569.687 Q55.2282 570.822 57.543 571.4 Q59.8578 571.979 62.381 571.979 Q66.7791 571.979 69.0707 570.243 Q71.3855 568.507 71.3855 565.197 Q71.3855 562.141 69.2328 560.428 Q67.1032 558.692 63.2837 558.692 L59.256 558.692 L59.256 554.85 L63.4689 554.85 Q66.918 554.85 68.7467 553.484 Q70.5754 552.095 70.5754 549.502 Q70.5754 546.84 68.6772 545.428 Q66.8022 543.993 63.2837 543.993 Q61.3624 543.993 59.1634 544.41 Q56.9643 544.826 54.3254 545.706 L54.3254 541.539 Q56.9875 540.799 59.3023 540.428 Q61.6402 540.058 63.7004 540.058 Q69.0244 540.058 72.1263 542.489 Q75.2281 544.896 75.2281 549.016 Q75.2281 551.887 73.5846 553.877 Q71.9411 555.845 68.9087 556.609 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M84.9503 540.683 L103.307 540.683 L103.307 544.618 L89.2327 544.618 L89.2327 553.09 Q90.2512 552.743 91.2697 552.581 Q92.2882 552.396 93.3067 552.396 Q99.0937 552.396 102.473 555.567 Q105.853 558.738 105.853 564.155 Q105.853 569.734 102.381 572.836 Q98.9085 575.914 92.5891 575.914 Q90.4132 575.914 88.1447 575.544 Q85.8993 575.174 83.492 574.433 L83.492 569.734 Q85.5753 570.868 87.7975 571.424 Q90.0197 571.979 92.4965 571.979 Q96.5011 571.979 98.8391 569.873 Q101.177 567.766 101.177 564.155 Q101.177 560.544 98.8391 558.438 Q96.5011 556.331 92.4965 556.331 Q90.6215 556.331 88.7466 556.748 Q86.8947 557.164 84.9503 558.044 L84.9503 540.683 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M66.5939 283.653 L54.7884 302.102 L66.5939 302.102 L66.5939 283.653 M65.367 279.579 L71.2466 279.579 L71.2466 302.102 L76.1772 302.102 L76.1772 305.991 L71.2466 305.991 L71.2466 314.139 L66.5939 314.139 L66.5939 305.991 L50.9921 305.991 L50.9921 301.477 L65.367 279.579 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M93.9086 282.658 Q90.2975 282.658 88.4688 286.223 Q86.6632 289.764 86.6632 296.894 Q86.6632 304 88.4688 307.565 Q90.2975 311.107 93.9086 311.107 Q97.5428 311.107 99.3483 307.565 Q101.177 304 101.177 296.894 Q101.177 289.764 99.3483 286.223 Q97.5428 282.658 93.9086 282.658 M93.9086 278.954 Q99.7187 278.954 102.774 283.561 Q105.853 288.144 105.853 296.894 Q105.853 305.621 102.774 310.227 Q99.7187 314.811 93.9086 314.811 Q88.0984 314.811 85.0197 310.227 Q81.9642 305.621 81.9642 296.894 Q81.9642 288.144 85.0197 283.561 Q88.0984 278.954 93.9086 278.954 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip052)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  204.426,1393.49 246.992,1393.49 289.559,1393.49 332.125,1393.49 374.692,1393.49 417.258,1393.49 459.825,1393.49 502.391,1289.05 544.958,1393.49 587.524,1393.49 \n",
       "  630.09,1341.27 672.657,1393.49 715.223,1393.49 757.79,1393.49 800.356,1289.05 842.923,1445.72 885.489,1393.49 928.056,1393.49 970.622,1393.49 1013.19,1393.49 \n",
       "  1055.76,1393.49 1098.32,1445.72 1140.89,1236.83 1183.45,1393.49 1226.02,1393.49 1268.59,1393.49 1311.15,349.08 1353.72,1132.39 1396.29,1027.95 1438.85,1393.49 \n",
       "  1481.42,1393.49 1523.99,610.184 1566.55,1080.17 1609.12,1393.49 1651.69,1393.49 1694.25,1341.27 1736.82,1341.27 1779.39,1393.49 1821.95,87.9763 1864.52,1445.72 \n",
       "  1907.08,1393.49 1949.65,1445.72 1992.22,1445.72 2034.78,1289.05 2077.35,1445.72 2119.92,1393.49 2162.48,1393.49 2205.05,1393.49 2247.62,1393.49 2290.18,1341.27 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip050)\" d=\"\n",
       "M215.55 198.898 L489.07 198.898 L489.07 95.2176 L215.55 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  215.55,198.898 489.07,198.898 489.07,95.2176 215.55,95.2176 215.55,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip050)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  240.115,147.058 387.509,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip050)\" d=\"M425.917 166.745 Q424.111 171.375 422.398 172.787 Q420.685 174.199 417.815 174.199 L414.412 174.199 L414.412 170.634 L416.912 170.634 Q418.672 170.634 419.644 169.8 Q420.616 168.967 421.797 165.865 L422.56 163.921 L412.074 138.412 L416.588 138.412 L424.69 158.689 L432.792 138.412 L437.306 138.412 L425.917 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip050)\" d=\"M444.597 160.402 L452.236 160.402 L452.236 134.037 L443.926 135.703 L443.926 131.444 L452.19 129.778 L456.866 129.778 L456.866 160.402 L464.505 160.402 L464.505 164.338 L444.597 164.338 L444.597 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if TRAINING\n",
    "    plot(episode_test_step_hook.steps[1:2:end])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2c89b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_visualization(); # closes the MeshCat visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be7fc6",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a39200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = VtolEnv(;name = \"test_cf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "345f65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "function loadModel(path, num)\n",
    "    f = joinpath(path, \"cf_sac_$num.bson\")\n",
    "    \n",
    "    policy = create_policy_net();\n",
    "    qnetwork1 = create_q_net();\n",
    "    qnetwork2 = create_q_net();\n",
    "    \n",
    "    #@load f policy qnetwork1 qnetwork2\n",
    "    policy = BSON.load(f)[:policy]\n",
    "    qnetwork1 = BSON.load(f)[:qnetwork1]\n",
    "    qnetwork2 = BSON.load(f)[:qnetwork2]\n",
    "    \n",
    "    #println(\"load model $f\")\n",
    "    return policy, qnetwork1, qnetwork2\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed379703",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validate(num_models, num_test)\n",
    "    episode_test_reward_hook = TotalRewardPerEpisode(is_display_on_exit=false)\n",
    "    # create a env only for reward test\n",
    "    for i in 1:num_models\n",
    "          \n",
    "        sum_rewards_model = 0;\n",
    "        sum_successes_model = 0;\n",
    "        sum_avg_vel_model = 0;\n",
    "        sum_compl_time = 0;\n",
    "        n_success = 0;\n",
    "        \n",
    "        for exp in 1:num_test\n",
    "            if SLOW_MODE\n",
    "                path = \"./RL_models_slow/\"\n",
    "            else\n",
    "                path = \"./RL_models_fast/\"\n",
    "            end\n",
    "            agent.policy.policy, agent.policy.qnetwork1, agent.policy.qnetwork2 = loadModel(path, i * save_freq); \n",
    "            RLBase.reset!(test_env)\n",
    "            run(agent.policy, test_env, StopAfterEpisode(1), episode_test_reward_hook)\n",
    "            # the result of the hook\n",
    "            sum_rewards_model += episode_test_reward_hook.rewards[end];\n",
    "            \n",
    "            if test_env.reached_goal == trues(test_env.num_waypoints)\n",
    "                n_success += 1\n",
    "                sum_avg_vel_model += test_env.norm_way / test_env.t\n",
    "                sum_compl_time += test_env.t\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        rewards[i] = sum_rewards_model / num_test;\n",
    "        success_rate[i] = n_success / num_test;\n",
    "        if n_success > 0\n",
    "            avg_velocity[i] = sum_avg_vel_model / n_success;\n",
    "            avg_compl_time[i] = sum_compl_time / n_success;\n",
    "        else\n",
    "            avg_velocity[i] = NaN\n",
    "            avg_compl_time[i] = NaN\n",
    "        end\n",
    "        percent = percent = round(i * 100 / num_models, digits=2)\n",
    "        print(\"progress: $(percent)%   \\r\")\n",
    "        flush(stdout)\n",
    "        \n",
    "    end\n",
    "    \n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21a98dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 0.62%   \r"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] (::BSON.var\"#47#48\")(d::Dict{Symbol, Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/extensions.jl:159",
      "  [2] _raise_recursive(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:82",
      "  [3] (::BSON.var\"#49#50\")(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/extensions.jl:168",
      "  [4] raise_recursive(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:92",
      "  [5] (::BSON.var\"#23#24\"{IdDict{Any, Any}, Module})(x::Dict{Symbol, Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:98",
      "  [6] applychildren!(f::BSON.var\"#23#24\"{IdDict{Any, Any}, Module}, x::Vector{Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/BSON.jl:26",
      "  [7] raise_recursive",
      "    @ ~/.julia/packages/BSON/73cTU/src/read.jl:98 [inlined]",
      "  [8] (::BSON.var\"#18#21\"{IdDict{Any, Any}, Module})(x::Vector{Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:82",
      "  [9] applychildren!(f::BSON.var\"#18#21\"{IdDict{Any, Any}, Module}, x::Dict{Symbol, Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/BSON.jl:19",
      " [10] _raise_recursive(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:82",
      " [11] raise_recursive(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:93",
      " [12] (::BSON.var\"#23#24\"{IdDict{Any, Any}, Module})(x::Dict{Symbol, Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:98",
      " [13] applychildren!(f::BSON.var\"#23#24\"{IdDict{Any, Any}, Module}, x::Vector{Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/BSON.jl:26",
      " [14] raise_recursive",
      "    @ ~/.julia/packages/BSON/73cTU/src/read.jl:98 [inlined]",
      " [15] (::BSON.var\"#18#21\"{IdDict{Any, Any}, Module})(x::Vector{Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:82",
      " [16] applychildren!(f::BSON.var\"#18#21\"{IdDict{Any, Any}, Module}, x::Dict{Symbol, Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/BSON.jl:19",
      " [17] _raise_recursive(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:82",
      " [18] (::BSON.var\"#49#50\")(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/extensions.jl:168",
      " [19] raise_recursive(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:92",
      " [20] (::BSON.var\"#23#24\"{IdDict{Any, Any}, Module})(x::Dict{Symbol, Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:98",
      " [21] applychildren!(f::BSON.var\"#23#24\"{IdDict{Any, Any}, Module}, x::Vector{Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/BSON.jl:26",
      " [22] raise_recursive",
      "    @ ~/.julia/packages/BSON/73cTU/src/read.jl:98 [inlined]",
      " [23] (::BSON.var\"#18#21\"{IdDict{Any, Any}, Module})(x::Vector{Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:82",
      " [24] applychildren!(f::BSON.var\"#18#21\"{IdDict{Any, Any}, Module}, x::Dict{Symbol, Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/BSON.jl:19",
      " [25] _raise_recursive(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:82",
      " [26] (::BSON.var\"#49#50\")(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/extensions.jl:168",
      " [27] raise_recursive(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:92",
      " [28] (::BSON.var\"#19#22\"{IdDict{Any, Any}, Module})(x::Dict{Symbol, Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:86",
      " [29] applychildren!(f::BSON.var\"#19#22\"{IdDict{Any, Any}, Module}, x::Dict{Symbol, Any})",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/BSON.jl:19",
      " [30] _raise_recursive(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:86",
      " [31] raise_recursive(d::Dict{Symbol, Any}, cache::IdDict{Any, Any}, init::Module)",
      "    @ BSON ~/.julia/packages/BSON/73cTU/src/read.jl:93",
      " [32] raise_recursive",
      "    @ ~/.julia/packages/BSON/73cTU/src/read.jl:103 [inlined]",
      " [33] load (repeats 2 times)",
      "    @ ~/.julia/packages/BSON/73cTU/src/read.jl:108 [inlined]",
      " [34] loadModel(path::String, num::Int64)",
      "    @ Main ./In[36]:11",
      " [35] validate(num_models::Int64, num_test::Int64)",
      "    @ Main ./In[37]:18",
      " [36] top-level scope",
      "    @ In[38]:11"
     ]
    }
   ],
   "source": [
    "if EVALUATION\n",
    "    \n",
    "    NUM_MODELS = Int(steps / save_freq);  \n",
    "    NUM_TEST = 100; # TODO: change as desired \n",
    "\n",
    "    rewards = zeros(NUM_MODELS, 1);\n",
    "    success_rate = zeros(NUM_MODELS, 1);\n",
    "    avg_velocity = zeros(NUM_MODELS, 1);\n",
    "    avg_compl_time = zeros(NUM_MODELS, 1);\n",
    "    \n",
    "    validate(NUM_MODELS, NUM_TEST);\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab909865",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVALUATION\n",
    "    results_path = pwd() * \"/plots/\";\n",
    "    if SLOW_MODE\n",
    "        results_path = results_path * \"slow/\"\n",
    "    else\n",
    "        results_path = results_path * \"fast/\"\n",
    "    end\n",
    "    \n",
    "    save(results_path * \"iterations.jld\", \"data\", [1:NUM_MODELS] * save_freq) \n",
    "    \n",
    "    save(results_path * \"avg_comp_time.jld\", \"data\", avg_compl_time)\n",
    "    \n",
    "    save(results_path * \"avg_velocity.jld\", \"data\", avg_velocity)\n",
    "    \n",
    "    save(results_path * \"reward.jld\", \"data\", rewards) \n",
    "        \n",
    "    save(results_path * \"success_rate.jld\", \"data\", success_rate)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ea2a032",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[40]:8"
     ]
    }
   ],
   "source": [
    "results_path = pwd() * \"/plots/\";\n",
    "if SLOW_MODE\n",
    "    results_path = results_path * \"slow/\"\n",
    "else\n",
    "    results_path = results_path * \"fast/\"\n",
    "end\n",
    "\n",
    "iterations = load(results_path * \"iterations.jld\")[\"data\"];\n",
    "avg_compl_time = load(results_path * \"avg_comp_time.jld\")[\"data\"];\n",
    "avg_velocity = load(results_path * \"avg_velocity.jld\")[\"data\"];\n",
    "rewards = load(results_path * \"reward.jld\")[\"data\"];\n",
    "success_rate = load(results_path * \"success_rate.jld\")[\"data\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26466af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/larissa/Documents/Projects/ADLR/ADLR_project/src/RL_3D_quadcopter_SAC/plots/slow/\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_path = pwd() * \"/plots/\";\n",
    "if SLOW_MODE\n",
    "    fig_path = fig_path * \"slow/\"\n",
    "else\n",
    "    fig_path = fig_path * \"fast/\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4cc649e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: iterations not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: iterations not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[42]:1"
     ]
    }
   ],
   "source": [
    "plot(iterations, rewards, xlabel=\"Iterations\", ylabel=\"Reward\", legend = false, xformatter = :scientific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "405bd6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/larissa/Documents/Projects/ADLR/ADLR_project/src/RL_3D_quadcopter_SAC/plots/slow/reward.svg\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savefig(fig_path * \"reward.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9535a7a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: iterations not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: iterations not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[44]:1"
     ]
    }
   ],
   "source": [
    "plot(iterations, success_rate, xlabel=\"Iterations\", ylabel=\"Success Rate\", legend = false, xformatter = :scientific, ylims=(-0.05,1.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e57d828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/larissa/Documents/Projects/ADLR/ADLR_project/src/RL_3D_quadcopter_SAC/plots/slow/success_rate.svg\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savefig(fig_path * \"success_rate.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "480d67d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: iterations not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: iterations not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[46]:1"
     ]
    }
   ],
   "source": [
    "plot(iterations, avg_velocity, xlabel=\"Iterations\", ylabel=\"Average Velocity\", legend = false, xformatter = :scientific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3113dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/larissa/Documents/Projects/ADLR/ADLR_project/src/RL_3D_quadcopter_SAC/plots/slow/avg_velocity.svg\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savefig(fig_path * \"avg_velocity.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b4de56f",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: iterations not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: iterations not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[48]:1"
     ]
    }
   ],
   "source": [
    "plot(iterations, avg_compl_time, xlabel=\"Iterations\", ylabel=\"Average Completion Time\", legend = false, xformatter = :scientific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4739f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/larissa/Documents/Projects/ADLR/ADLR_project/src/RL_3D_quadcopter_SAC/plots/slow/avg_comp_time.svg\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savefig(fig_path * \"avg_comp_time.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed305f8e",
   "metadata": {},
   "source": [
    "# Create Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f30d98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mMeshCat server started. You can open the visualizer by visiting the following URL in your browser:\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mhttp://127.0.0.1:8702\n"
     ]
    }
   ],
   "source": [
    "create_visualization();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "260d79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VIDEO  \n",
    "  # TODO: load_model as desired\n",
    "    vid_env = VtolEnv(;name = \"testVTOL\", visualization = true, realtime = true);\n",
    "\n",
    "    if SLOW_MODE\n",
    "        path = \"./RL_models_slow/\"\n",
    "        load_model = 30_000_000 # TODO: load model\n",
    "        println(\"slow mode\")\n",
    "    else\n",
    "        path = \"./RL_models_fast/\"\n",
    "        load_model = 30_000_000 # TODO: load model\n",
    "        println(\"fast mode\")\n",
    "    end\n",
    "    agent.policy.policy, agent.policy.qnetwork1, agent.policy.qnetwork2 = loadModel(path,load_model); \n",
    "    \n",
    "    for i in 1:10\n",
    "        sleep(5)\n",
    "        RLBase.reset!(vid_env)\n",
    "        run(agent.policy, vid_env, StopAfterEpisode(1))\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bebf7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_visualization();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57443b44",
   "metadata": {},
   "source": [
    "done"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
